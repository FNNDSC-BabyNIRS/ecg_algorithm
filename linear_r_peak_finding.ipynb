{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "290aa860-d2a1-492d-82ec-2d9d127c735e",
   "metadata": {},
   "source": [
    "# Document's Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35d6c0c-3f2a-405d-8553-ef34b88ec6e6",
   "metadata": {},
   "source": [
    "#### · Display raw data from cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb031946-3161-493e-9ec1-04a4741f9e49",
   "metadata": {},
   "source": [
    "#### · Display raw data and located peaks recorded in cluster "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fc7aa9-0dc4-4215-9abf-097d9c171732",
   "metadata": {},
   "source": [
    "#### · Find peaks of recorder raw data with the most updated version of the algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1829aa45-9481-4062-8469-8fa2a67fd1d5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b991332-290e-4327-83ab-27b2d45b062a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pymongo==3.13.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f41072d9-9310-4bd7-a3c8-3dbdd8295ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1be889b9-72ff-482f-ada7-345a782889d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_name = 'braulio.ramirez'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf36577a-f81f-42b0-a956-ec62464acdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger('jhub')\n",
    "hostname = 'mongos.mongo.svc.cluster.local:27017'\n",
    "pemkeyfile = '/etc/mongo/jhub-keypem.pem'\n",
    "sslca = '/etc/mongo/root-ca.pem'\n",
    "\n",
    "nirscloud_util_meta.init(logger, 'meta', hostname=hostname, ssl=True, cert=pemkeyfile, ca=sslca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "784166a8-3bb9-4462-bdec-d9255df1654c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-05 18:31:53 [INFO ] cfg#_init_hdfs_kinit@79: after hdfs_kinit: the_stdout: b'' the_stderr: b''\n",
      "2023-07-05 18:31:53 [INFO ] client#__init__@192: Instantiated <KerberosClient(url='https://hdfs2.babynirs.org:9870;https://hdfs1.babynirs.org:9870;https://hdfs4.babynirs.org:9870')>.\n"
     ]
    }
   ],
   "source": [
    "spark_kerberos_principal = my_name + '@BABYNIRS.ORG'\n",
    "\n",
    "params = {\n",
    "    'spark_kerberos_principal': spark_kerberos_principal,\n",
    "}\n",
    "nirscloud_util_hdfs.init('/etc/jhub/conf/production.ini', params=params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9682083-9c01-4a9d-bc69-34bb8224669e",
   "metadata": {},
   "source": [
    "### Pulling the recorded peaks from the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "829c37dc-48bc-4c72-a51f-47f6488b4a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdfs_path = '_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=01/_patient_id=5984929'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "5848ff80-2731-4aff-b3bd-0e26d800f5ed",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "kafka_topics = 'nk_rpeak2_NICU'\n",
    "hdfs_prefix = '/kafka/topics/%s'% (kafka_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "9443025f-cfe8-4370-879b-797b1a25bf86",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _get_df(hdfs_path, the_id):\n",
    "    hdfs_path = hdfs_path\n",
    "    full_path = nirscloud_util_hdfs.full_path(hdfs_prefix, hdfs_path)\n",
    "    err, df = nirscloud_util_hdfs.from_hdfs_path(full_path)\n",
    "    print(err, df)\n",
    "    is_valid = df['id'] == the_id\n",
    "    df = df[is_valid]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "fbc7b90a-c015-4b49-9375-b1d854cc8744",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-06 20:29:47 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-06 20:29:47 [INFO ] client#status@320: Fetching status for '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929'.\n",
      "2023-07-06 20:29:47 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-06 20:29:47 [INFO ] client#status@320: Fetching status for '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929'.\n",
      "2023-07-06 20:29:47 [INFO ] client#list@1123: Listing '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929'.\n",
      "2023-07-06 20:29:47 [INFO ] client#list@1123: Listing '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929'.\n",
      "2023-07-06 20:29:47 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-06 20:29:47 [INFO ] client#status@320: Fetching status for '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929/part-00000-3dc1ad61-1e54-40f7-bf0c-9dd31613338c.c000.snappy.parquet'.\n",
      "2023-07-06 20:29:47 [INFO ] client#read@731: Reading file '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929/part-00000-3dc1ad61-1e54-40f7-bf0c-9dd31613338c.c000.snappy.parquet'.\n",
      "2023-07-06 20:29:47 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-06 20:29:47 [INFO ] client#status@320: Fetching status for '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929/part-00000-a7de3d7b-e862-44e6-92e4-3c5f614da7c3.c000.snappy.parquet'.\n",
      "2023-07-06 20:29:47 [INFO ] client#read@731: Reading file '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929/part-00000-a7de3d7b-e862-44e6-92e4-3c5f614da7c3.c000.snappy.parquet'.\n",
      "2023-07-06 20:29:47 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-06 20:29:47 [INFO ] client#status@320: Fetching status for '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929/part-00001-5c9b6e80-d106-4e98-8785-30fac20ce5d9.c000.snappy.parquet'.\n",
      "2023-07-06 20:29:47 [INFO ] client#read@731: Reading file '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929/part-00001-5c9b6e80-d106-4e98-8785-30fac20ce5d9.c000.snappy.parquet'.\n",
      "2023-07-06 20:29:47 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-06 20:29:47 [INFO ] client#status@320: Fetching status for '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929/part-00001-7d8f0b76-fb44-42de-b9b2-c872825e306e.c000.snappy.parquet'.\n",
      "2023-07-06 20:29:47 [INFO ] client#read@731: Reading file '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929/part-00001-7d8f0b76-fb44-42de-b9b2-c872825e306e.c000.snappy.parquet'.\n",
      "2023-07-06 20:29:47 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-06 20:29:47 [INFO ] client#status@320: Fetching status for '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929/part-00001-ffd4be5c-52ca-4aa1-a4e7-ae7835c7b982.c000.snappy.parquet'.\n",
      "2023-07-06 20:29:47 [INFO ] client#read@731: Reading file '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929/part-00001-ffd4be5c-52ca-4aa1-a4e7-ae7835c7b982.c000.snappy.parquet'.\n",
      "2023-07-06 20:29:47 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-06 20:29:47 [INFO ] client#status@320: Fetching status for '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929/part-00002-b1b22d74-6344-4835-a54d-e4f13c127cc5.c000.snappy.parquet'.\n",
      "2023-07-06 20:29:47 [INFO ] client#read@731: Reading file '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929/part-00002-b1b22d74-6344-4835-a54d-e4f13c127cc5.c000.snappy.parquet'.\n",
      "2023-07-06 20:29:48 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-06 20:29:48 [INFO ] client#status@320: Fetching status for '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929/part-00002-d984a888-fd97-424c-ad25-24edaf49eb1f.c000.snappy.parquet'.\n",
      "2023-07-06 20:29:48 [INFO ] client#read@731: Reading file '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929/part-00002-d984a888-fd97-424c-ad25-24edaf49eb1f.c000.snappy.parquet'.\n",
      "2023-07-06 20:29:48 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-06 20:29:48 [INFO ] client#status@320: Fetching status for '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929/part-00003-a9d4f8c2-0090-480d-9297-dbda0f436f70.c000.snappy.parquet'.\n",
      "2023-07-06 20:29:48 [INFO ] client#read@731: Reading file '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929/part-00003-a9d4f8c2-0090-480d-9297-dbda0f436f70.c000.snappy.parquet'.\n",
      "2023-07-06 20:29:48 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-06 20:29:48 [INFO ] client#status@320: Fetching status for '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929/part-00003-f3cdcf06-7be1-43a9-a32a-c6e9decbf73d.c000.snappy.parquet'.\n",
      "2023-07-06 20:29:48 [INFO ] client#read@731: Reading file '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929/part-00003-f3cdcf06-7be1-43a9-a32a-c6e9decbf73d.c000.snappy.parquet'.\n",
      "2023-07-06 20:29:48 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-06 20:29:48 [INFO ] client#status@320: Fetching status for '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929/part-00004-17d15225-8719-4953-ad45-73ed1dd42460.c000.snappy.parquet'.\n",
      "2023-07-06 20:29:48 [INFO ] client#read@731: Reading file '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929/part-00004-17d15225-8719-4953-ad45-73ed1dd42460.c000.snappy.parquet'.\n",
      "2023-07-06 20:29:48 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-06 20:29:48 [INFO ] client#status@320: Fetching status for '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929/part-00004-b112fd52-76d1-4ffd-b27c-fa89fb2c521d.c000.snappy.parquet'.\n",
      "2023-07-06 20:29:48 [INFO ] client#read@731: Reading file '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929/part-00004-b112fd52-76d1-4ffd-b27c-fa89fb2c521d.c000.snappy.parquet'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None       id             start_ns          rec_nano_ts       val      ver  \\\n",
      "0     II  1686372038314000000  1686372039283320820  1.149853  v0.0.23   \n",
      "1     II  1686372038826000000  1686372039623391041  0.070611  v0.0.23   \n",
      "2     II  1686372038826000000  1686372039963980267  0.471633  v0.0.23   \n",
      "3     II  1686372039338000000  1686372040304866902  0.387760  v0.0.23   \n",
      "4     II  1686372039850000000  1686372040645622712  0.322574  v0.0.23   \n",
      "...   ..                  ...                  ...       ...      ...   \n",
      "3476  II  1686373175978000000  1686373176977949007 -0.491993  v0.0.23   \n",
      "3477  II  1686373176490000000  1686373177586859349  0.641429  v0.0.23   \n",
      "3478  II  1686373177002000000  1686373178182592895  0.716261  v0.0.23   \n",
      "3479  II  1686373177514000000  1686373178621707140  0.550078  v0.0.23   \n",
      "3480  II  1686373178026000000  1686373179078254610  2.296289  v0.0.23   \n",
      "\n",
      "     _device_id  _bed_id   _the_date _hr _patient_id  \n",
      "0       Procyon  HA11-01  2023-06-10  00     5984929  \n",
      "1       Procyon  HA11-01  2023-06-10  00     5984929  \n",
      "2       Procyon  HA11-01  2023-06-10  00     5984929  \n",
      "3       Procyon  HA11-01  2023-06-10  00     5984929  \n",
      "4       Procyon  HA11-01  2023-06-10  00     5984929  \n",
      "...         ...      ...         ...  ..         ...  \n",
      "3476    Procyon  HA11-01  2023-06-10  00     5984929  \n",
      "3477    Procyon  HA11-01  2023-06-10  00     5984929  \n",
      "3478    Procyon  HA11-01  2023-06-10  00     5984929  \n",
      "3479    Procyon  HA11-01  2023-06-10  00     5984929  \n",
      "3480    Procyon  HA11-01  2023-06-10  00     5984929  \n",
      "\n",
      "[3481 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "df_II_peaks = _get_df(hdfs_path, 'II')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "0a745a74-9e1b-4c14-a126-7c116801485d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_II_peaks.sort_values(by=['rec_nano_ts'], inplace=True)\n",
    "df_II_peaks.reset_index(drop=True, inplace=True)\n",
    "df_II_peaks['shift_rec_nano_ts'] = df_II_peaks['rec_nano_ts'].shift(-1)\n",
    "df_II_peaks['dif_rec_nano_ts'] = df_II_peaks['shift_rec_nano_ts'] - df_II_peaks['rec_nano_ts']\n",
    "df_II_peaks;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "a5bc05c0-5f80-49c0-82f5-954c40710c6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "values_p = np.asarray(df_II_peaks['val'].to_numpy())\n",
    "raw_time_p = np.asarray(df_II_peaks['rec_nano_ts'].to_numpy(), dtype = 'int')\n",
    "time_p = [np.datetime64(int(t),'ns') for t in raw_time_p]\n",
    "time_pks = np.array([(pd.Timestamp(t).hour*60*60*1000) + (pd.Timestamp(t).minute*60*1000) + (pd.Timestamp(t).second*1000) + (pd.Timestamp(t).microsecond/1000) for t in time_p]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "470ad255-978b-484c-b696-300861add7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "kafka_topics_cs = 'nk_waves_NICU'\n",
    "hdfs_prefix_cs = '/nirscloud/agg_by_hr3/%s'% (kafka_topics_cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "e3983926-1996-4999-b07f-25754dcae52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_df_cs(hdfs_path, the_id):\n",
    "    hdfs_path = hdfs_path + '/id=%s' % (the_id)\n",
    "    full_path = nirscloud_util_hdfs.full_path(hdfs_prefix_cs, hdfs_path)\n",
    "    err, df = nirscloud_util_hdfs.from_hdfs_path(full_path)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e6399e94-2bcc-4ece-95b0-2d117375cb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time series need to be concatenated accoording to the amount of time that is going to be analyzed "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8ba35c-8863-41a4-885c-61f31f7afa7d",
   "metadata": {},
   "source": [
    "# Getting a sample from raw data in cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6412c05d-fb3b-4d03-b603-a9338e7dd2f5",
   "metadata": {},
   "source": [
    "##### When getting a sample the first thing to be considered is the amount of time, and this is determined by the stats that are to be done afterwards.\n",
    "##### We cacn think in terms of how many windows do we want to analyze or how much time, the length of the window and their overlap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "fb7aa59b-5e05-44d7-a644-ed6372d960f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time length can be in intervals of 15 minutes starting from 30\n",
      "\n",
      "You can either choose the amount of windows or the total amount of time\n"
     ]
    }
   ],
   "source": [
    "# The total time of the interval will be defined by the amount of windows one chooses, the overlap and the length of the windows.\n",
    "time_wind_length = 30; overlap_window = 0.5; \n",
    "print('Total time length can be in intervals of ' +str(int(time_wind_length*overlap_window))+ ' minutes starting from '+str(time_wind_length))\n",
    "print('')\n",
    "print('You can either choose the amount of windows or the total amount of time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "c0aff925-5c96-473c-af1a-87e4b859f3c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of time is 180 minutes and the amount of windows is 11\n"
     ]
    }
   ],
   "source": [
    "#In this block you can enter the total amount of time to analyze or the amount of windows\n",
    "\n",
    "by_time = True; total_time = 180; windows = 12;\n",
    "\n",
    "\n",
    "if by_time: \n",
    "    by_windows = False\n",
    "else: by_windows = True\n",
    "\n",
    "if by_time: \n",
    "    total_time = 180\n",
    "    if total_time%15 != 0: \n",
    "        print('The amount of time entered is not divisible by '+str(time_wind_length*overlap_window))\n",
    "    windows = int(total_time/(time_wind_length*overlap_window)) - 1 \n",
    "    print('The amount of time is '+str(int(total_time))+' minutes and the amount of windows is '+str(windows))\n",
    "\n",
    "    \n",
    "if by_windows: \n",
    "    windows = 12\n",
    "    total_time = (1-overlap_window)*time_wind_length*(windows) + 15\n",
    "    print('The amount of time is '+str(int(total_time))+' minutes and the amount of windows is '+str(windows))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "16126927-ea07-4ccc-91e6-89f62004944f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This line is important because it establishes what will be the first hour \n",
    "first_hour = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "94387886-a8a2-4d91-b3ec-0cdb4f24528c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-07 19:17:51 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-07 19:17:51 [INFO ] client#status@320: Fetching status for '/nirscloud/agg_by_hr3/nk_waves_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929/id=MDC_ECG_ELEC_POTL_II'.\n",
      "2023-07-07 19:17:51 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-07 19:17:51 [INFO ] client#status@320: Fetching status for '/nirscloud/agg_by_hr3/nk_waves_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929/id=MDC_ECG_ELEC_POTL_II'.\n",
      "2023-07-07 19:17:51 [INFO ] client#list@1123: Listing '/nirscloud/agg_by_hr3/nk_waves_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929/id=MDC_ECG_ELEC_POTL_II'.\n",
      "2023-07-07 19:17:51 [INFO ] client#status@320: Fetching status for '/nirscloud/agg_by_hr3/nk_waves_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929/id=MDC_ECG_ELEC_POTL_II'.\n",
      "2023-07-07 19:17:51 [INFO ] client#list@1123: Listing '/nirscloud/agg_by_hr3/nk_waves_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929/id=MDC_ECG_ELEC_POTL_II'.\n",
      "2023-07-07 19:17:51 [INFO ] client#status@320: Fetching status for '/nirscloud/agg_by_hr3/nk_waves_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929/id=MDC_ECG_ELEC_POTL_II'.\n",
      "2023-07-07 19:17:51 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-07 19:17:51 [INFO ] client#status@320: Fetching status for '/nirscloud/agg_by_hr3/nk_waves_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929/id=MDC_ECG_ELEC_POTL_II/part-00000-1f75843e-e8df-43ac-84d1-1c5b94653a8c.c000.snappy.parquet'.\n",
      "2023-07-07 19:17:51 [INFO ] client#read@731: Reading file '/nirscloud/agg_by_hr3/nk_waves_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929/id=MDC_ECG_ELEC_POTL_II/part-00000-1f75843e-e8df-43ac-84d1-1c5b94653a8c.c000.snappy.parquet'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting 3 hours\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-07 19:17:51 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-07 19:17:51 [INFO ] client#status@320: Fetching status for '/nirscloud/agg_by_hr3/nk_waves_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=01/_patient_id=5984929/id=MDC_ECG_ELEC_POTL_II'.\n",
      "2023-07-07 19:17:51 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-07 19:17:51 [INFO ] client#status@320: Fetching status for '/nirscloud/agg_by_hr3/nk_waves_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=01/_patient_id=5984929/id=MDC_ECG_ELEC_POTL_II'.\n",
      "2023-07-07 19:17:51 [INFO ] client#list@1123: Listing '/nirscloud/agg_by_hr3/nk_waves_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=01/_patient_id=5984929/id=MDC_ECG_ELEC_POTL_II'.\n",
      "2023-07-07 19:17:51 [INFO ] client#status@320: Fetching status for '/nirscloud/agg_by_hr3/nk_waves_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=01/_patient_id=5984929/id=MDC_ECG_ELEC_POTL_II'.\n",
      "2023-07-07 19:17:51 [INFO ] client#list@1123: Listing '/nirscloud/agg_by_hr3/nk_waves_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=01/_patient_id=5984929/id=MDC_ECG_ELEC_POTL_II'.\n",
      "2023-07-07 19:17:51 [INFO ] client#status@320: Fetching status for '/nirscloud/agg_by_hr3/nk_waves_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=01/_patient_id=5984929/id=MDC_ECG_ELEC_POTL_II'.\n",
      "2023-07-07 19:17:51 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-07 19:17:51 [INFO ] client#status@320: Fetching status for '/nirscloud/agg_by_hr3/nk_waves_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=01/_patient_id=5984929/id=MDC_ECG_ELEC_POTL_II/part-00001-ac0d3d20-be26-431f-94d2-7fc3a5c37dac.c000.snappy.parquet'.\n",
      "2023-07-07 19:17:51 [INFO ] client#read@731: Reading file '/nirscloud/agg_by_hr3/nk_waves_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=01/_patient_id=5984929/id=MDC_ECG_ELEC_POTL_II/part-00001-ac0d3d20-be26-431f-94d2-7fc3a5c37dac.c000.snappy.parquet'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted hour: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-07 19:17:51 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-07 19:17:51 [INFO ] client#status@320: Fetching status for '/nirscloud/agg_by_hr3/nk_waves_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=02/_patient_id=5984929/id=MDC_ECG_ELEC_POTL_II'.\n",
      "2023-07-07 19:17:51 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-07 19:17:51 [INFO ] client#status@320: Fetching status for '/nirscloud/agg_by_hr3/nk_waves_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=02/_patient_id=5984929/id=MDC_ECG_ELEC_POTL_II'.\n",
      "2023-07-07 19:17:51 [INFO ] client#list@1123: Listing '/nirscloud/agg_by_hr3/nk_waves_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=02/_patient_id=5984929/id=MDC_ECG_ELEC_POTL_II'.\n",
      "2023-07-07 19:17:51 [INFO ] client#status@320: Fetching status for '/nirscloud/agg_by_hr3/nk_waves_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=02/_patient_id=5984929/id=MDC_ECG_ELEC_POTL_II'.\n",
      "2023-07-07 19:17:51 [INFO ] client#list@1123: Listing '/nirscloud/agg_by_hr3/nk_waves_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=02/_patient_id=5984929/id=MDC_ECG_ELEC_POTL_II'.\n",
      "2023-07-07 19:17:51 [INFO ] client#status@320: Fetching status for '/nirscloud/agg_by_hr3/nk_waves_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=02/_patient_id=5984929/id=MDC_ECG_ELEC_POTL_II'.\n",
      "2023-07-07 19:17:51 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-07 19:17:52 [INFO ] client#status@320: Fetching status for '/nirscloud/agg_by_hr3/nk_waves_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=02/_patient_id=5984929/id=MDC_ECG_ELEC_POTL_II/part-00000-443b5b26-14c4-4b57-9524-e9fd72427ce1.c000.snappy.parquet'.\n",
      "2023-07-07 19:17:52 [INFO ] client#read@731: Reading file '/nirscloud/agg_by_hr3/nk_waves_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=02/_patient_id=5984929/id=MDC_ECG_ELEC_POTL_II/part-00000-443b5b26-14c4-4b57-9524-e9fd72427ce1.c000.snappy.parquet'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted hour: 1\n",
      "Extracted hour: 2\n",
      "\n",
      "There is missing data in the following indices\n",
      "\n",
      "Time 96.8, Index 1452031 is missing 260.0 milliseconds ahead\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "# Extracting and concatenating dataframes according to time. \n",
    "\n",
    "if total_time%60 == 0: \n",
    "    amount_hours = int(total_time/60)\n",
    "else:\n",
    "    amount_hours = int((total_time - total_time%60)/60) + 1 \n",
    "\n",
    "print('Extracting '+str(int(amount_hours))+' hours')\n",
    "\n",
    "df_dict = {}; time_cts =[]; values_cs = [];\n",
    "hours = np.arange(first_hour,first_hour + amount_hours)\n",
    "lead = 'MDC_ECG_ELEC_POTL_II'\n",
    "\n",
    "for h in hours:\n",
    "    if len(str(h)) == 1:\n",
    "        hdfs_path = '_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=0' + str(h)+'/_patient_id=5984929'\n",
    "    else: \n",
    "        hdfs_path = '_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=' + str(h)+'/_patient_id=5984929'\n",
    "\n",
    "    df_cs = _get_df_cs(hdfs_path, lead)\n",
    "    print('Extracted hour: '+str(h))\n",
    "    df_dict['hour '+str(h)] = df_cs\n",
    "    \n",
    "final_df_cs = pd.concat(df_dict)\n",
    "\n",
    "\n",
    "final_df_cs.sort_values(by=['_milli_ts'], inplace=True)\n",
    "final_df_cs.reset_index(drop=True, inplace=True)\n",
    "final_df_cs['shift_milli_ts'] = final_df_cs['_milli_ts'].shift(-1)\n",
    "final_df_cs['diff_milli_ts'] = final_df_cs['shift_milli_ts'] - final_df_cs['_milli_ts']\n",
    "\n",
    "values_cs = np.asarray(final_df_cs['val'].to_numpy())\n",
    "raw_time_cs = np.asarray(final_df_cs['_milli_ts'].to_numpy(), dtype = 'int')\n",
    "time_cs = [np.datetime64(int(t),'ms') for t in raw_time_cs]\n",
    "time_cts = np.concatenate([time_cts, np.array([(pd.Timestamp(t).hour*60*60*1000) + (pd.Timestamp(t).minute*60*1000) + \n",
    "                 (pd.Timestamp(t).second*1000) + (pd.Timestamp(t).microsecond/1000) for t in time_cs])]);\n",
    "\n",
    "\n",
    "missing_info = final_df_cs[final_df_cs['diff_milli_ts']>4]\n",
    "missing_ids = missing_info.index.to_list()\n",
    "\n",
    "if len(missing_ids)>0:\n",
    "    print('')\n",
    "    print('There is missing data in the following indices')\n",
    "for missing_idx in missing_ids: \n",
    "    print('')\n",
    "    print('Time '+str(round((missing_idx*4/1000)/60,2))+', Index '+str(missing_idx)+' is missing '+str(final_df_cs['diff_milli_ts'][missing_idx])+' milliseconds ahead')\n",
    "    zeros = np.zeros(int(final_df_cs['diff_milli_ts'][missing_idx]/4))\n",
    "    missing_time = np.arange(time_cts[missing_idx]+4,time_cts[missing_idx+1],4)\n",
    "    time_cts = np.insert(time_cts,missing_idx+1,missing_time)\n",
    "    values_cs = np.insert(values_cs,missing_idx,zeros)\n",
    "    \n",
    "time_cts = time_cts - time_cts[0]\n",
    "\n",
    "print('Finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0551947f-9752-4262-a7e8-73b8fdb639d6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "e22ee5ee-b8d1-494d-96bf-09888f117a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_pks = time_pks - time_cts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c71380b0-934a-495f-8516-cba2ce8850a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class raw_sample_():\n",
    "    \n",
    "    def __init__(self,min_min,min_sec,max_min,max_sec,seconds_per_label):\n",
    "        \n",
    "        self.min_min = min_min\n",
    "        self.min_sec = min_sec\n",
    "        self.max_min = max_min\n",
    "        self.max_sec = max_sec\n",
    "        self.seconds_per_label = seconds_per_label\n",
    "\n",
    "        self.min_time = int((self.min_min*60*1000)/4) + int(self.min_sec*1000/4)\n",
    "        self.max_time = int((self.max_min*60*1000)/4) + int(self.max_sec*1000/4) + 1\n",
    "        self.pks_time_min = (self.min_min*60*1000) + (self.min_sec*1000)\n",
    "        self.pks_time_max = (self.max_min*60*1000) + (self.max_sec*1000)\n",
    "        self.pks_time = time_pks[(self.pks_time_min > time_pks).argmin():(time_pks < self.pks_time_max).argmin()]\n",
    "        self.pks_values = values_p[(self.pks_time_min > time_pks).argmin():(time_pks < self.pks_time_max).argmin()]\n",
    "        \n",
    "        self.time = time_cts[self.min_time:self.max_time]\n",
    "        self.values = df_II_cs['val'].to_numpy()[self.min_time:self.max_time]\n",
    "\n",
    "        self.fig = go.Figure()\n",
    "        self.fig.add_trace(go.Scatter(line= dict(color='blue'),x=self.time, y=self.values,showlegend=False))\n",
    "        self.fig.add_trace(go.Scatter(mode='markers', marker= dict(color='red'),x=self.pks_time, y=self.pks_values,showlegend=False))\n",
    "\n",
    "        self.ticks_values = []\n",
    "        x = self.time[0]\n",
    "        while x < self.time[-1]:\n",
    "            self.ticks_values = np.append(self.ticks_values,x)\n",
    "            x = 1000*self.seconds_per_label + x\n",
    "\n",
    "        self.time_format_axis = time_f(self.ticks_values)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "7c788685-be82-487a-812f-85f74f012b85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class sample_():\n",
    "    \n",
    "    def __init__(self,min_min,min_sec,max_min,max_sec,seconds_per_label,find_the_peaks,inverted):\n",
    "        \n",
    "        self.min_min = min_min\n",
    "        self.min_sec = min_sec\n",
    "        self.max_min = max_min\n",
    "        self.max_sec = max_sec\n",
    "        self.seconds_per_label = seconds_per_label\n",
    "\n",
    "        self.min_time = int((self.min_min*60*1000)/4 + int(self.min_sec*1000)/4) \n",
    "        self.max_time = int((self.max_min*60*1000)/4 + int(self.max_sec*1000)/4) + 1\n",
    "\n",
    "        \n",
    "        time_zero = raw_time_cs[0]\n",
    "        self.time = raw_time_cs[self.min_time:self.max_time] - time_zero\n",
    "        if inverted:\n",
    "            self.values = - values_cs[self.min_time:self.max_time]\n",
    "        else: \n",
    "            self.values = values_cs[self.min_time:self.max_time]\n",
    "\n",
    "        self.fig = go.Figure()\n",
    "        self.fig.add_trace(\n",
    "                      go.Scatter(line= dict(color='blue'),x=self.time, y=self.values,showlegend=False))\n",
    "\n",
    "        self.ticks_values = []\n",
    "        x = self.time[0]\n",
    "        while x < self.time[-1]:\n",
    "            self.ticks_values = np.append(self.ticks_values,x)\n",
    "            x = 1000*self.seconds_per_label + x\n",
    "\n",
    "        self.time_format_axis = time_f(self.ticks_values)\n",
    "        \n",
    "        if find_the_peaks:\n",
    "            self.peaks, _ = find_peaks(self.values, distance=100)\n",
    "            self.fig.add_trace(\n",
    "                      go.Scatter(mode='markers',x=self.time[self.peaks], y=self.values[self.peaks],showlegend=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "91fa0b40-1348-477d-88b8-e33a550e5a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample1 = sample_(95,0,98,0,10,False,False)\n",
    "fig = sample1.fig\n",
    "fig.update_layout(xaxis = dict(tickmode = 'array', tickvals = sample1.ticks_values, ticktext = sample1.time_format_axis),autosize=False,width=1250,\n",
    "                  height=600,showlegend=False,title=\"Raw Data \", xaxis_title=\"Time\", yaxis_title= 'Signal', \n",
    "                  font=dict(family=\"Avenir\",size=14,color=\"Black\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "b7dad340-f694-4386-92a8-1e5c520f5d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f291d6-6da2-49be-bec9-407803f6a196",
   "metadata": {},
   "source": [
    "# Pre processing, baseline wander removal through moving average subtraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadfdde5-640c-4a88-b740-00baed0be8dc",
   "metadata": {},
   "source": [
    "$$y[n]_{Moving Average} = \\frac{1}{M_2 + 1}(x[n]-x[n-M_2-1]) + y[n-1]$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9ed82be5-58d7-45fd-8795-79f92da621b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block proves that the difference equation has the same result with the convolution, data has been preprocessed \n",
    "# and pan tompkins algorithm can take place now. \n",
    "\n",
    "upper_limit = 10000\n",
    "w = 15\n",
    "mean = average_filter(w,sample1.values)\n",
    "yn, cut_pts = moving_average(w,sample1.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4a79cf4a-c143-4988-9318-450d2fc565aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing different window lengths for pre processing stage\n",
    "\n",
    "fig_pre_p = go.Figure()\n",
    "\n",
    "baseline_removal = {}\n",
    "prepro_data = {}\n",
    "cut_pts ={}\n",
    "x = sample1.time\n",
    "for i in range(5,20):    \n",
    "    #print(i)\n",
    "    baseline_removal['Window '+str(i)], cut_pts['Window '+str(i)] = moving_average(i,sample1.values)\n",
    "    prepro_data['Window '+str(i)] =  sample1.values[0:len(x)-cut_pts['Window '+str(i)]] - baseline_removal['Window '+str(i)]\n",
    "    fig_pre_p.add_trace(go.Scatter(line= dict(color='#e65400'), x=x[0:len(x)-cut_pts['Window '+str(i)]], y = prepro_data['Window '+str(i)],\n",
    "                                   name = 'Baseline Removal Window '+str(i), showlegend=False, visible = False))\n",
    "    #fig_pre_p.add_trace(go.Scatter(line= dict(color='blue'),    x=sample1.time, y=sample1.values,name='Raw Data',showlegend=False, visible = False))\n",
    "\n",
    "    \n",
    "fig_pre_p.data[5].visible = True\n",
    "\n",
    "\n",
    "steps = []\n",
    "start = 0\n",
    "for t in range(5,20):\n",
    "    step = dict(\n",
    "        method=\"update\",\n",
    "        args=[{\"visible\": [False] * len(fig_pre_p.data)},\n",
    "              {\"title\":  'Baseline Wander Removal      Moving Average Window: '+str(t)}],  # layout attribute\n",
    "    )\n",
    "    \n",
    "    step[\"args\"][0][\"visible\"][start] = True  # Toggle i'th trace to \"visible\"\n",
    "    #step[\"args\"][0][\"visible\"][start+1] = True\n",
    "\n",
    "    \n",
    "    start = start+1\n",
    "    steps.append(step)\n",
    "\n",
    "    \n",
    "sliders = [dict(active=5, currentvalue={\"prefix\": \"n: \"}, pad={\"t\": 50}, steps=steps)]\n",
    "fig_pre_p.update_layout(sliders=sliders);\n",
    "fig_pre_p.update_layout(xaxis = dict(tickmode = 'array', tickvals = sample1.ticks_values, ticktext = sample1.time_format_axis),autosize=False,width=1200,height=600);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7e4828e4-75a6-4eb3-a815-1eaf60fdd786",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig_pre_p.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "02f40133-eef2-41f3-a528-c123c9e37d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparing the Raw data and Pre processed data in subplots\n",
    "\n",
    "i =  10\n",
    "fig3 = make_subplots(\n",
    "    rows=2, cols=1,\n",
    "    subplot_titles=(\"Raw Data\",\" Mean Subtraction Filter \"))\n",
    "\n",
    "fig3.add_trace(go.Scatter(line = dict(color='blue'), x=sample1.time, y=sample1.values,name='Raw Data',showlegend=False),row=1, col=1)\n",
    "fig3.add_trace(go.Scatter(x=x[0:len(x)-cut_pts['Window '+str(i)]], y= prepro_data['Window '+str(i)],\n",
    "                                   name = 'Baseline Removal Window '+str(i), showlegend=False,),row=2, col=1)\n",
    "\n",
    "\n",
    "\n",
    "fig3.update_layout(xaxis_range=[79000,85000], xaxis2_range=[79000,85000],yaxis_range=[-0.6,0.65])\n",
    "fig3.update_layout(xaxis = dict(tickmode = 'array', tickvals = sample1.ticks_values, ticktext = sample1.time_format_axis),autosize=False,width=1200,height=600);\n",
    "fig3.update_layout(xaxis2 = dict(tickmode = 'array', tickvals = sample1.ticks_values, ticktext = sample1.time_format_axis),autosize=False,width=1200,height=600);\n",
    "fig3.update_layout(height=700,width = 1300);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4eb1ef2-3fc2-41d6-8cf5-0a6549ee3f8d",
   "metadata": {},
   "source": [
    "#### A window of 10 is chosen for the mean subtraction, based oon high noise intervals, need too look deeper into this"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da63f0a8-ad47-4cdd-a3e4-5562c446829a",
   "metadata": {},
   "source": [
    "## Pan Tompkins starts here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f82cf286-f3f5-4c4c-982d-22e146ba99ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling Frequency: 250.0Hz\n"
     ]
    }
   ],
   "source": [
    "#time_dif = np.unique(np.diff(sample1.time))/np.timedelta64(1, \"ms\")\n",
    "time_dif = 4/1000\n",
    "sampling_freq = 1/time_dif\n",
    "print('Sampling Frequency: '+str(sampling_freq)+'Hz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ca2b5b2a-00c4-40a9-9f41-78ee3231f6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "lowcut = 3; highcut = 100;\n",
    "nyquist_freq = 0.5 * sampling_freq\n",
    "low = lowcut / nyquist_freq\n",
    "high = highcut / nyquist_freq\n",
    "b, a = butter(2, [low, high], btype=\"band\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6a17f361-b48e-4ea8-85bc-5e241896fffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = lfilter(b, a, prepro_data['Window '+str(6)])\n",
    "x = np.append(sample1.values,np.zeros(len(b)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60245f04-5aa0-408b-af4a-c8837b77e2c9",
   "metadata": {},
   "source": [
    "## Bandpass Filter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2169a124-fd08-41d6-b902-d958960b6917",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfr_r = go.Figure()\\nfs = 250\\ntrans_width = 2.88\\nband = [3, 18]  # Desired pass band, Hz\\nfilter_size= np.arange(100,200,1)\\nedges = [0, band[0] - trans_width, band[0], band[1],\\n         band[1] + trans_width, 0.5*fs]\\ntrans_width = 2.8    # Width of transition from pass to stop, Hz\\ntaps = {}\\n\\nfor i in range(0,len(filter_size)):\\n\\n    numtaps=filter_size[i]      # Size of the FIR filter.\\n\\n    taps[\\'size: \\'+str(filter_size[i])] = signal.remez(numtaps, edges, [0, 1, 0], fs=fs)\\n    w, h = signal.freqz(taps[\\'size: \\'+str(filter_size[i])], [1], worN=2000, fs=fs)\\n    fr_r.add_trace(go.Scatter(x=w,y=20*np.log10(np.abs(h))))\\n    \\nfr_r.data[5].visible = True\\n\\nsteps = []\\nfor tw in range(0,len(filter_size)):\\n    step = dict(\\n        method=\"update\",\\n        args=[{\"visible\": [False] * len(fr_r.data)},\\n              {\"title\": \\'Size of Filter: \\'+ str(filter_size[tw])}],  # layout attribute\\n    )\\n    step[\"args\"][0][\"visible\"][tw] = True  # Toggle i\\'th trace to \"visible\"\\n    steps.append(step)\\n    \\nsliders = [dict(active=5, currentvalue={\"prefix\": \"n: \"}, pad={\"t\": 50}, steps=steps)]\\nfr_r.update_layout(sliders=sliders);\\n\\n\\nfr_r.update_layout(\\n    xaxis = dict(tickmode = \\'array\\',tickvals = [np.log10(1),np.log10(2),np.log10(3),np.log10(4),np.log10(5),np.log10(6),np.log10(7),np.log10(8),np.log10(9),\\n                    np.log10(10),np.log10(15),np.log10(20)],\\n        ticktext = [\\'1\\', \\'2\\', \\'3\\', \\'4\\', \\'5\\', \\'6\\',\\'7\\',\\'8\\',\\'9\\',\\'10\\',\\'15\\',\\'20\\']))\\n\\nfr_r.update_layout(autosize=False,width=1200, height=600, xaxis_title=\"w\", yaxis_title= \\'20log( |H(s)| ) (dB)\\' ,\\n                      font=dict(family=\"Avenir\",size=16,color=\"Black\"))\\n\\nfr_r.update_layout(xaxis_range=[0,150], yaxis_range=[-50,10]);\\n\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "fr_r = go.Figure()\n",
    "fs = 250\n",
    "trans_width = 2.88\n",
    "band = [3, 18]  # Desired pass band, Hz\n",
    "filter_size= np.arange(100,200,1)\n",
    "edges = [0, band[0] - trans_width, band[0], band[1],\n",
    "         band[1] + trans_width, 0.5*fs]\n",
    "trans_width = 2.8    # Width of transition from pass to stop, Hz\n",
    "taps = {}\n",
    "\n",
    "for i in range(0,len(filter_size)):\n",
    "\n",
    "    numtaps=filter_size[i]      # Size of the FIR filter.\n",
    "\n",
    "    taps['size: '+str(filter_size[i])] = signal.remez(numtaps, edges, [0, 1, 0], fs=fs)\n",
    "    w, h = signal.freqz(taps['size: '+str(filter_size[i])], [1], worN=2000, fs=fs)\n",
    "    fr_r.add_trace(go.Scatter(x=w,y=20*np.log10(np.abs(h))))\n",
    "    \n",
    "fr_r.data[5].visible = True\n",
    "\n",
    "steps = []\n",
    "for tw in range(0,len(filter_size)):\n",
    "    step = dict(\n",
    "        method=\"update\",\n",
    "        args=[{\"visible\": [False] * len(fr_r.data)},\n",
    "              {\"title\": 'Size of Filter: '+ str(filter_size[tw])}],  # layout attribute\n",
    "    )\n",
    "    step[\"args\"][0][\"visible\"][tw] = True  # Toggle i'th trace to \"visible\"\n",
    "    steps.append(step)\n",
    "    \n",
    "sliders = [dict(active=5, currentvalue={\"prefix\": \"n: \"}, pad={\"t\": 50}, steps=steps)]\n",
    "fr_r.update_layout(sliders=sliders);\n",
    "\n",
    "\n",
    "fr_r.update_layout(\n",
    "    xaxis = dict(tickmode = 'array',tickvals = [np.log10(1),np.log10(2),np.log10(3),np.log10(4),np.log10(5),np.log10(6),np.log10(7),np.log10(8),np.log10(9),\n",
    "                    np.log10(10),np.log10(15),np.log10(20)],\n",
    "        ticktext = ['1', '2', '3', '4', '5', '6','7','8','9','10','15','20']))\n",
    "\n",
    "fr_r.update_layout(autosize=False,width=1200, height=600, xaxis_title=\"w\", yaxis_title= '20log( |H(s)| ) (dB)' ,\n",
    "                      font=dict(family=\"Avenir\",size=16,color=\"Black\"))\n",
    "\n",
    "fr_r.update_layout(xaxis_range=[0,150], yaxis_range=[-50,10]);\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "88514b7d-4852-46bb-bf3e-739f8aa34014",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig_bp = go.Figure()\n",
    "i = 10\n",
    "bandstop = np.arange(3,10)\n",
    "fs = 250\n",
    "trans_width = 2.88\n",
    "taps = {}\n",
    "numtaps = 152\n",
    "\n",
    "for bs in bandstop:\n",
    "    band = [bs, 100]\n",
    "    edges = [0, band[0] - trans_width, band[0], band[1],\n",
    "             band[1] + trans_width, 0.5*fs]\n",
    "    \n",
    "    taps['Bandstart: '+str(bs)] = signal.remez(numtaps, edges, [0, 1, 0], fs=fs)\n",
    "    \n",
    "    \n",
    "    x = np.append(prepro_data['Window '+str(i)],np.zeros(len(taps['Bandstart: '+str(bs)])))\n",
    "    y_bp = np.zeros(len(prepro_data['Window '+str(i)])+len(taps['Bandstart: '+str(bs)]))\n",
    "\n",
    "    for j in range(0,len(prepro_data['Window '+str(i)])+len(taps['Bandstart: '+str(bs)])): \n",
    "        sum = 0\n",
    "        for k in range(0,len(taps['Bandstart: '+str(bs)])):\n",
    "            sum = (x[j-k]*taps['Bandstart: '+str(bs)][k]) + sum\n",
    "        y_bp[j] = sum\n",
    "\n",
    "    y_bp=np.delete(y_bp,[np.arange(0,int(len(taps['Bandstart: '+str(bs)])/2))])\n",
    "    fig_bp.add_trace(go.Scatter(x=sample1.time, y=y_bp,visible=False))\n",
    "\n",
    "fig_bp.data[5].visible = True\n",
    "\n",
    "steps = []\n",
    "for bps in range(0,len(bandstop)):\n",
    "    step = dict(\n",
    "        method=\"update\",\n",
    "        args=[{\"visible\": [False] * len(fig_bp.data)},\n",
    "              {\"title\": ' Mean Removal Windoow: '+str(i)+'      Bandstart: '+ str(bandstop[bps])}],  # layout attribute\n",
    "    )\n",
    "    step[\"args\"][0][\"visible\"][bps] = True  # Toggle i'th trace to \"visible\"\n",
    "    steps.append(step)\n",
    "    \n",
    "sliders = [dict(active=5, currentvalue={\"prefix\": \"n: \"}, pad={\"t\": 50}, steps=steps)]\n",
    "\n",
    "fig_bp.update_layout(sliders=sliders);\n",
    "fig_bp.update_layout(xaxis = dict(tickmode = 'array', tickvals = sample1.ticks_values, ticktext = sample1.time_format_axis)); \n",
    "fig_bp.update_layout(autosize=False,width=1200, height=600, xaxis_title=\"Time\", yaxis_title= 'Signal' ,\n",
    "                      font=dict(family=\"Avenir\",size=16,color=\"Black\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9b2e7aaa-9d41-43ba-97a9-6ad8ccaa577c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig_bp.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4654610c-2847-4e08-a9f9-abfe0f440d3b",
   "metadata": {},
   "source": [
    "#### Chosen FIR Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a892dc7f-335f-4d63-b9b9-66d6c998b687",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 10\n",
    "x = np.append(prepro_data['Window '+str(i)],np.zeros(len(taps['Bandstart: 3'])))\n",
    "y_bp = np.zeros(len(prepro_data['Window '+str(i)])+len(taps['Bandstart: 3']))\n",
    "\n",
    "for j in range(0,len(prepro_data['Window '+str(i)])+len(taps['Bandstart: 3'])): \n",
    "    sum = 0\n",
    "    for k in range(0,len(taps['Bandstart: 3'])):\n",
    "        sum = (x[j-k]*taps['Bandstart: 3'][k]) + sum\n",
    "    y_bp[j] = sum\n",
    "    \n",
    "y_bp=np.delete(y_bp,[np.arange(0,int(len(taps['Bandstart: 3'])/2))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9d2c14fe-b03b-4dcb-a4ed-e80289a73b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparing the Mean Subtraction and Bandpass in subplots\n",
    "\n",
    "i = 10\n",
    "fig3 = make_subplots(\n",
    "    rows=2, cols=1,\n",
    "    subplot_titles=(\" Mean Subtraction Filter \",\" Bandpass \"))\n",
    "\n",
    "fig3.add_trace(go.Scatter(line=dict(color = 'red'),x=sample1.time, y = y_bp,name='Raw Data',showlegend=False),row=2, col=1)\n",
    "fig3.add_trace(go.Scatter(x=x[0:len(x)-cut_pts['Window '+str(i)]], y= prepro_data['Window '+str(i)],\n",
    "                                   name = 'Baseline Removal Window '+str(i), showlegend=False,),row=1, col=1)\n",
    "\n",
    "\n",
    "\n",
    "fig3.update_layout(xaxis_range=[79000,85000], xaxis2_range=[79000,85000])\n",
    "fig3.update_layout(xaxis = dict(tickmode = 'array', tickvals = sample1.ticks_values, ticktext = sample1.time_format_axis),autosize=False,width=1200,height=600);\n",
    "fig3.update_layout(xaxis2 = dict(tickmode = 'array', tickvals = sample1.ticks_values, ticktext = sample1.time_format_axis),autosize=False,width=1200,height=600)\n",
    "fig3.update_layout(height=700,width = 1300);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "89baf68e-b882-49b9-9bda-182a69d1b3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4829e49d-fba3-4ca8-b8c5-c7307578ed4c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nx0 =np.append(prepro_data['Window '+str(6)],np.zeros(len(b)))\\ndif_y = np.zeros(len(x0))\\n\\nfor i in range(0,len(prepro_data['Window 15'])):\\n    dif_y[i] = (1/a[0]) * (b[0]*x[i] + b[1]*x[i-1] + b[2]*x[i-2] + b[3]*x[i-3] + b[4]*x[i-4] - \\n                       (a[1]*dif_y[i-1] + a[2]*dif_y[i-2] + a[3]*dif_y[i-3] + a[4]*dif_y[i-4]))\\n    \\n\\ndif_y = np.delete(dif_y,np.arange(len(dif_y)-len(b),len(dif_y),1))\\n\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Transfer Function for IIR\n",
    "\"\"\"\n",
    "x0 =np.append(prepro_data['Window '+str(6)],np.zeros(len(b)))\n",
    "dif_y = np.zeros(len(x0))\n",
    "\n",
    "for i in range(0,len(prepro_data['Window 15'])):\n",
    "    dif_y[i] = (1/a[0]) * (b[0]*x[i] + b[1]*x[i-1] + b[2]*x[i-2] + b[3]*x[i-3] + b[4]*x[i-4] - \n",
    "                       (a[1]*dif_y[i-1] + a[2]*dif_y[i-2] + a[3]*dif_y[i-3] + a[4]*dif_y[i-4]))\n",
    "    \n",
    "\n",
    "dif_y = np.delete(dif_y,np.arange(len(dif_y)-len(b),len(dif_y),1))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cceb4c-c8a7-46b5-af08-7d1ee9856fc1",
   "metadata": {},
   "source": [
    "### AN FIR FILTER WAS MADE WITH NUMBER OF TAPS 152"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189b6129-cde0-47bc-87ab-86835bfb4d33",
   "metadata": {},
   "source": [
    "#### FROM NOW ON THE DATA HAS BEEN FILTERED WITH AN FIR BANDPASS AND CAN CONTINUE WITH THE REST OF THE STEPS IN PAN TOMPKINS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4e4a6e73-b82e-4d4c-8d06-0fea62361fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = str(10)\n",
    "fig2 = go.Figure()\n",
    "fig2.add_trace(go.Scatter(line= dict(color='blue', width =2),x=sample1.time, y = sample1.values,name='Raw Data',showlegend=True))\n",
    "fig2.add_trace(go.Scatter(line= dict(width = 2),x=sample1.time, y = prepro_data['Window '+i],name='Preprocessed Data',showlegend=True))\n",
    "fig2.add_trace(go.Scatter(line= dict(width = 2),x=sample1.time, y = y_bp,name='FIR Filter',showlegend=True))\n",
    "fig2.update_layout(xaxis_range=[79000,85000],xaxis = dict(tickmode = 'array', tickvals = sample1.ticks_values, ticktext = sample1.time_format_axis), \n",
    "                    autosize=False,width=1200, height=600, title='Band Pass Filtered and Raw Data', \n",
    "                    xaxis_title=\"Time\", yaxis_title= 'Signal');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c5593a45-b306-45fa-af3f-4913ad9d7318",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#fig2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da39ba1b-262d-4b95-a062-d89787f15a62",
   "metadata": {},
   "source": [
    "### Difference Equation for derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e375c05-a109-4733-b7b4-0d3c5bb79581",
   "metadata": {},
   "source": [
    "#### y[n] = (1/8T) (-x[n-2] - 2x[n-1] + 2x[n+1] + x[n+2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "69b8ea8c-66dd-4849-b1fa-b86f1defafd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Difference Equation\n",
    "\n",
    "der1 = np.zeros(len(y_bp))\n",
    "\n",
    "x = np.append(y_bp,np.zeros(2))\n",
    "\n",
    "for i in range(0,len(y_bp)):\n",
    "    der1[i] = (1/8) * (-(x[i-2]) - (2*x[i-1]) + (2*x[i+1]) + (x[i+2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4cba611b-928a-4e00-b0e9-78757c6bf519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bandpass and Derivative\n",
    "\n",
    "fig3 = make_subplots(\n",
    "    rows=2, cols=1,\n",
    "    subplot_titles=(\"Bandpass Filter\",'Derivative Filter '))\n",
    "\n",
    "#fig3.add_trace(go.Scatter(line= dict(color='green'),x=sample1.time, y = der1,name='Derivative Filter',showlegend=False),row=1, col=1)\n",
    "\n",
    "fig3.add_trace(go.Scatter(line= dict(color='red'),x=sample1.time, y = y_bp,name='Bandpass',showlegend=False),row=1, col=1)\n",
    "fig3.add_trace(go.Scatter(line= dict(color='Green'),x=sample1.time, y = der1,name='Derivative',showlegend=False),row=2, col=1)\n",
    "#fig3.add_trace(go.Scatter(line= dict(color='Blue'),x=sample1.time, y = der2,name='Derivative',showlegend=False),row=3, col=1)\n",
    "\n",
    "fig3.update_layout(xaxis = dict(tickmode = 'array', tickvals = sample1.ticks_values, ticktext = sample1.time_format_axis),\n",
    "                    xaxis2 = dict(tickmode = 'array', tickvals = sample1.ticks_values, ticktext = sample1.time_format_axis),\n",
    "                    xaxis3 = dict(tickmode = 'array', tickvals = sample1.ticks_values, ticktext = sample1.time_format_axis))\n",
    "\n",
    "#fig3.update_layout(xaxis_range=[0,1000], xaxis2_range=[0,85000])\n",
    "fig3.update_layout(height=750,width = 1300);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9378589-8880-4672-8ec2-40645fa5fab4",
   "metadata": {},
   "source": [
    "### Squaring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7f990f90-61bd-49b4-b700-a63a0d4643f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "squared = (der1) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f658de98-090a-4602-93be-8c0520421574",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Derivative and Squared\n",
    "\n",
    "\n",
    "fig4 = make_subplots(\n",
    "    rows=2, cols=1,\n",
    "    subplot_titles=(\"Derivative Filter     Average Window: 6      Bandstart: 22\",\" Squared        Average Window: 6         Bandstart: 22 \"))\n",
    "\n",
    "#fig4.add_trace(go.Scatter(line= dict(color='orange'),x=sample1.time, y = squared,name='Squared',showlegend=False),row=1, col=1)\n",
    "\n",
    "fig4.add_trace(go.Scatter(line= dict(color='green'),x=sample1.time, y = der1,name='Derivative',showlegend=False),row=1, col=1)\n",
    "fig4.add_trace(go.Scatter(line= dict(color='orange'),x=sample1.time, y = squared,name='Squared',showlegend=False),row=2, col=1)\n",
    "\n",
    "fig4.update_layout(xaxis = dict(tickmode = 'array', tickvals = sample1.ticks_values, ticktext = sample1.time_format_axis),\n",
    "                    xaxis2 = dict(tickmode = 'array', tickvals = sample1.ticks_values, ticktext = sample1.time_format_axis))\n",
    "\n",
    "fig4.update_layout(xaxis_range=[79000,85000], xaxis2_range=[79000,85000], yaxis2_range=[-0.001,0.016])\n",
    "fig4.update_layout(height=700,width = 1300);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba78441-b29d-4852-a461-de575cfcc0b9",
   "metadata": {},
   "source": [
    "## Moving Integration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75671d1b-d6ff-49f7-8bcf-edfcf89b4a32",
   "metadata": {},
   "source": [
    "#### The moving window integration difference equation is given by \n",
    "#### $$y[n] = (x[n-(N-1)] + x[n-(N-2)] + .... + x[n])$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1073446-5365-4ef2-b9e2-b4eb8771d64d",
   "metadata": {},
   "source": [
    "##### The following is the moving integration difference equation implemented through a loop just to test and compare later on with a constructed function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6048bb14-71ac-4df2-8603-f2d35b19de88",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ma = np.zeros(len(squared))\n",
    "y_mi = np.zeros(len(squared))\n",
    "\n",
    "# N = window_length\n",
    "N = 11\n",
    "squared_y = np.append(squared,np.zeros(N-1))\n",
    "for n in range(0,len(y_ma)):\n",
    "    y_ma[n] = (1/N) * (squared_y[n-(N-1)] + squared_y[n-(N-2)] + squared_y[n-(N-3)] + squared_y[n-(N-4)] + squared_y[n-(N-5)] + squared_y[n-(N-6)] + \n",
    "                       squared_y[n-(N-7)] + squared_y[n-(N-8)] + squared_y[n-(N-9)] + squared_y[n-(N-10)] + squared_y[n])\n",
    "    y_mi[n] = (squared_y[n-(N-1)] + squared_y[n-(N-2)] + squared_y[n-(N-3)] + squared_y[n-(N-4)] + squared_y[n-(N-5)] + squared_y[n-(N-6)] + \n",
    "                       squared_y[n-(N-7)] + squared_y[n-(N-8)] + squared_y[n-(N-9)] + squared_y[n-(N-10)] + squared_y[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2acb71e9-82f4-4a92-b27b-ea8e1881ef7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The constructed function\n",
    "prueba = dif_eq_window_integration(squared,11,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4d573c8d-3a31-41eb-b199-ea9f411916d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This just doublechecks that the function works\n",
    "\n",
    "fig5 = go.Figure()\n",
    "\n",
    "fig5.add_trace(go.Scatter(mode = 'lines', line= dict(color='green'),x=sample1.time, y=squared,name='Squared',showlegend=True))\n",
    "fig5.add_trace(go.Scatter(mode = 'lines', line= dict(color='blue',width = 4),x=sample1.time, y=y_ma,name='Moving Window Average',showlegend=True))\n",
    "fig5.add_trace(go.Scatter(mode = 'lines', line= dict(color='red',width = 4),x=sample1.time, y=prueba, name='Prueba',showlegend=True))\n",
    "fig5.add_trace(go.Scatter(mode = 'lines', x=sample1.time, y=y_mi,name='Moving Window Integration',showlegend=True))\n",
    "\n",
    "\n",
    "fig5.update_layout(xaxis_range=[79000,85000],xaxis = dict(tickmode = 'array', tickvals = sample1.ticks_values, ticktext = sample1.time_format_axis), \n",
    "                    autosize=False,width=1250, height=600, title=\"Squared and Moving Window Integration WL: \" + str(N), \n",
    "                    xaxis_title=\"Time\", yaxis_title= 'Signal', font=dict(family=\"Avenir\",size=14,color=\"Black\"));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d83e46-0034-4510-85df-8fa0f3f05a44",
   "metadata": {},
   "source": [
    "## Looking to different window lengths in the window integration difference equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "778d6910-5480-4c9e-8e5d-2aa6bbf6999d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving Window Integration\n",
    "\n",
    "fig6 = go.Figure()\n",
    "\n",
    "y_mw_dict ={}\n",
    "lengths = np.arange(10,35,1)\n",
    "peaks_trial = {}\n",
    "\n",
    "for N in lengths: \n",
    "    y_mw_dict['MW Integration W: '+str(N)] = dif_eq_window_integration(squared,N,False)\n",
    "    #peaks_trial['MWI W peaks: '+str(N)], _ = find_peaks(y_mw_dict['MW Integration W: '+str(N)],distance = 100)\n",
    "    fig6.add_trace(go.Scatter(mode = 'lines', line= dict(color='blue'),x=sample1.time, y=y_mw_dict['MW Integration W: '+str(N)],\n",
    "                               name = 'Differece Equation',showlegend=False, visible =False))\n",
    "    \n",
    "fig6.data[5].visible = True\n",
    "\n",
    "steps = []\n",
    "start = 0\n",
    "for i in range(0,len(lengths)):\n",
    "    step = dict(\n",
    "        method=\"update\",\n",
    "        args=[{\"visible\": [False] * len(fig6.data)},\n",
    "              {\"title\": 'Moving Window Integration           Window Length: ' + str(lengths[i])}],  # layout attribute\n",
    "    )\n",
    "    step[\"args\"][0][\"visible\"][i] = True # Toggle i'th trace to \"visible\"\n",
    "    #step[\"args\"][0][\"visible\"][start + 1] = True # Toggle i'th trace to \"visible\"\n",
    "    #start = start +2\n",
    "\n",
    "    steps.append(step)\n",
    "    \n",
    "sliders = [dict(active=5, currentvalue={\"prefix\": \"n: \"}, pad={\"t\": 50}, steps=steps)]\n",
    "fig6.update_layout(sliders=sliders);\n",
    "fig6.update_layout(xaxis_range=[79000,85000]);\n",
    "fig6.update_layout(xaxis = dict(tickmode = 'array', tickvals = sample1.ticks_values, ticktext = sample1.time_format_axis),autosize=False,width=1200,height=600); \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "adc38639-72ab-423d-aa36-9d04d4f7c315",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig6.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2962e092-dcd0-404d-8190-8fe7a782c118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving Window Integration and Squared THIS IS BASICALLY THE SAME AS THE ABOVE BUT WITH THE SQUARED\n",
    "\n",
    "fig7 = go.Figure()\n",
    "\n",
    "y_mw_dict ={};\n",
    "\n",
    "\n",
    "for N in lengths: \n",
    "    y_mw_dict['MW Integration W: '+str(N)] = dif_eq_window_integration(squared,N,False)\n",
    "    fig7.add_trace(go.Scatter(mode = 'lines', line= dict(color='orange'),x=sample1.time, y=squared,\n",
    "                               name = 'Squared',showlegend=True,visible=False))\n",
    "    fig7.add_trace(go.Scatter(mode = 'lines', line= dict(color='blue',width=3),x=sample1.time, y=y_mw_dict['MW Integration W: '+str(N)],\n",
    "                               name = 'Differece Equation',showlegend=True,visible=False))\n",
    "    \n",
    "fig7.data[5].visible = True\n",
    "\n",
    "steps = []\n",
    "start = 0\n",
    "for i in range(0,len(lengths)):\n",
    "    step = dict(\n",
    "        method=\"update\",\n",
    "        args=[{\"visible\": [False] * len(fig7.data)},\n",
    "              {\"title\": 'Moving Window Integration           Window Length: ' + str(lengths[i])}],  # layout attribute\n",
    "    )\n",
    "    step[\"args\"][0][\"visible\"][start] = True # Toggle i'th trace to \"visible\"\n",
    "    step[\"args\"][0][\"visible\"][start+1] = True # Toggle i'th trace to \"visible\"\n",
    "    start = start + 2\n",
    "    steps.append(step)\n",
    "    \n",
    "sliders = [dict(active=5, currentvalue={\"prefix\": \"n: \"}, pad={\"t\": 50}, steps=steps)]\n",
    "fig7.update_layout(sliders=sliders);\n",
    "fig7.update_layout(xaxis_range=[79000,85000],yaxis_range = [0,0.014]);\n",
    "fig7.update_layout(xaxis = dict(tickmode = 'array', tickvals = sample1.ticks_values, ticktext = sample1.time_format_axis),autosize=False,width=1250,height=650); \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c23b1f2b-dd40-4da3-87b7-bbae548334dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig7.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4ad0476c-7783-4693-8805-1b6825c76be1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Squared and Moving Window Integration\n",
    "\n",
    "fig4 = make_subplots(\n",
    "    rows=2, cols=1,\n",
    "    subplot_titles=(\"Squared\",\" Moving Window Integration \"))\n",
    "\n",
    "#fig4.add_trace(go.Scatter(line= dict(color='orange'),x=sample1.time, y = squared,name='Squared',showlegend=False),row=1, col=1)\n",
    "\n",
    "fig4.add_trace(go.Scatter(line= dict(color='#0a4345'),x=sample1.time, y = y_mw_dict['MW Integration W: 25'],name='MWI',showlegend=False),row=2, col=1)\n",
    "fig4.add_trace(go.Scatter(line= dict(color='orange'),x=sample1.time, y = squared,name='Squared',showlegend=False),row=1, col=1)\n",
    "\n",
    "fig4.update_layout(xaxis = dict(tickmode = 'array', tickvals = sample1.ticks_values, ticktext = sample1.time_format_axis),\n",
    "                    xaxis2 = dict(tickmode = 'array', tickvals = sample1.ticks_values, ticktext = sample1.time_format_axis))\n",
    "\n",
    "fig4.update_layout(xaxis_range=[79000,85000], xaxis2_range=[79000,85000], yaxis_range=[-0.001,0.0155], yaxis2_range=[-0.001,0.085])\n",
    "fig4.update_layout(height=800,width = 1300);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "09c229b7-5f9f-40df-bf29-e9f7420273a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Finding the fiducial point\n",
    "\n",
    "x = sample1.time\n",
    "fiducial_point_dict = {}\n",
    "\n",
    "\n",
    "for length in lengths: \n",
    "    \n",
    "    #In live version we would let 10 peaks go by\n",
    "    test_segments = 3\n",
    "    peak_average, first_peaks = first_peaks_height_av(y_mw_dict['MW Integration W: '+str(length)],test_segments,0.8)\n",
    "    \n",
    "    y =  y_mw_dict['MW Integration W: '+str(length)]\n",
    "    fiducial_point = []\n",
    "    peak = 0\n",
    "    found_p = False\n",
    "    mwi_peak = []\n",
    "    look_for_peaks = True\n",
    "    counter = 0\n",
    "\n",
    "    for i in range(1,len(x)-1):\n",
    "        if look_for_peaks:\n",
    "            #print(i)\n",
    "            #print('found_p: '+str(found_p))    \n",
    "            f_derivative = (y[i+1]-y[i])/(x[i+1]-x[i])\n",
    "\n",
    "            if found_p:\n",
    "                if f_derivative > 0: \n",
    "                    found_p = False\n",
    "                    if (y[i]<(0.9)*peak) : \n",
    "                        found_p = True\n",
    "\n",
    "                if (peak/2>y[i]) :\n",
    "                    fiducial_point = np.append(fiducial_point,i-length)\n",
    "                    mwi_peak = np.append(mwi_peak,y[i])\n",
    "                    found_p = False\n",
    "                    peak = 0\n",
    "                    look_for_peaks = False\n",
    "                    if len(fiducial_point)>test_segments:\n",
    "                        peak_average = np.average(mwi_peak)\n",
    "\n",
    "\n",
    "            else: \n",
    "                b_derivative = (y[i]-y[i-1])/(x[i]-x[i-1])\n",
    "                if (f_derivative < 0) and (b_derivative > 0) and y[i]>0.5*peak_average: \n",
    "                    peak = y[i]\n",
    "                    found_p = True\n",
    "        else: \n",
    "            counter = counter + 1\n",
    "            if counter==45 :\n",
    "                counter = 0 \n",
    "                look_for_peaks = True\n",
    "            \n",
    "\n",
    "    fiducial_point = np.asarray(fiducial_point, dtype = 'int')\n",
    "    fiducial_point_dict['Window Length: '+str(length)] = fiducial_point\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3d02d8d9-d206-46db-b059-1dad303539e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving Window Integration and its peaks\n",
    "\n",
    "fig8 = go.Figure()\n",
    "\n",
    "\n",
    "for N in lengths: \n",
    "    fig8.add_trace(go.Scatter(mode = 'lines', line= dict(color='blue'),x=sample1.time, y=y_mw_dict['MW Integration W: '+str(N)],\n",
    "                               name = 'MWI length: '+str(N),showlegend=False,visible=False))\n",
    "    \n",
    "    fps = find_fiducial_point(y_mw_dict['MW Integration W: '+str(N)],sample1.time,3,0.8,N)\n",
    "\n",
    "    fig8.add_trace(go.Scatter(mode = 'markers', marker= dict(size = 10, color='red'),x=sample1.time[fps],\n",
    "                              y=y_mw_dict['MW Integration W: '+str(N)][fps],\n",
    "                               name = 'Peaks_function',showlegend=False,visible=False))\n",
    "    \n",
    "fig8.data[5].visible = True\n",
    "\n",
    "steps = []\n",
    "start = 0\n",
    "for length in lengths:\n",
    "    step = dict(\n",
    "        method=\"update\",\n",
    "        args=[{\"visible\": [False] * len(fig8.data)},\n",
    "              {\"title\": 'Moving Window Integration           Window Length: ' + str(length) + '         Peaks Found: '+str(len(fiducial_point_dict['Window Length: '+str(length)]))}],  # layout attribute\n",
    "    )\n",
    "    step[\"args\"][0][\"visible\"][start] = True # Toggle i'th trace to \"visible\"\n",
    "    step[\"args\"][0][\"visible\"][start+1] = True # Toggle i'th trace to \"visible\"\n",
    "\n",
    "    start = start + 2\n",
    "    steps.append(step)\n",
    "    \n",
    "sliders = [dict(active=5, currentvalue={\"prefix\": \"n: \"}, pad={\"t\": 50}, steps=steps)]\n",
    "fig8.update_layout(sliders=sliders);\n",
    "fig8.update_layout(xaxis_range=[79000,85000]);\n",
    "fig8.update_layout(xaxis = dict(tickmode = 'array', tickvals = sample1.ticks_values, ticktext = sample1.time_format_axis),autosize=False,width=1200,height=600); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5685eb3f-05a1-4e51-bae6-18bea820180c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig8.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a9ae9f18-d640-4d0c-bdaa-248e56a9b5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The algorithm needs to store maybe 5 peaks to learn whats a good height to be consider a peak in the moving window integration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "edd1fef0-c041-45be-b242-c4752464b2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A very simple strategy is to allow for 3 segments of one second or maybe 0.7 seconds to go by and get the maximum value of each segment in \n",
    "# that way we have a sample of what a maximum looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a10d0c09-7d6b-476f-ad6e-7b2dc110bb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving Window Integration and Raw Peaks\n",
    "spline = 4\n",
    "res = 1000\n",
    "max_x, max_y, peaks_x, peaks_y, interpolated_peak_x, interpolated_peak_y,max_ids = interpolation_spline(fiducial_point_dict['Window Length: 25'], \n",
    "                                                                                               sample1.time, sample1.values, spline, res)\n",
    "i = 6\n",
    "fig4 = make_subplots(\n",
    "    rows=3, cols=1,\n",
    "    subplot_titles=(\"Moving Window Integration\",\" Raw Peaks \", 'Mean Subtraction'))\n",
    "\n",
    "#fig4.add_trace(go.Scatter(line= dict(color='orange'),x=sample1.time, y = squared,name='Squared',showlegend=False),row=1, col=1)\n",
    "\n",
    "fig4.add_trace(go.Scatter(line= dict(color='#0a4345'),x=sample1.time, y = y_mw_dict['MW Integration W: 25'],name='MWI',showlegend=False),row=1, col=1)\n",
    "fig4.add_trace(go.Scatter(mode = 'markers',x=sample1.time[fiducial_point_dict['Window Length: 25']], \n",
    "                          y = y_mw_dict['MW Integration W: 25'][fiducial_point_dict['Window Length: 25']],\n",
    "                          name='MWI',showlegend=False),row=1, col=1)\n",
    "fig4.add_trace(go.Scatter(x=x[0:len(x)-cut_pts['Window '+str(i)]], y= prepro_data['Window '+str(i)],\n",
    "                                   name = 'Baseline Removal Window '+str(i), showlegend=False,),row=3, col=1)\n",
    "\n",
    "\n",
    "fig4.add_trace(go.Scatter(line= dict(color='blue'),x=sample1.time, y = sample1.values,name='Peaks in MWI',showlegend=False),row=2, col=1)\n",
    "fig4.add_trace(go.Scatter(mode='markers',marker=dict(color='red'), x=peaks_x, y = peaks_y, name='Peaks In Raw Data',showlegend=False),row=2, col=1)\n",
    "\n",
    "fig4.update_layout(xaxis = dict(tickmode = 'array', tickvals = sample1.ticks_values, ticktext = sample1.time_format_axis),\n",
    "                    xaxis2 = dict(tickmode = 'array', tickvals = sample1.ticks_values, ticktext = sample1.time_format_axis),\n",
    "                    xaxis3 = dict(tickmode = 'array', tickvals = sample1.ticks_values, ticktext = sample1.time_format_axis))\n",
    "\n",
    "fig4.update_layout(xaxis_range=[79000,85000], xaxis2_range=[79000,85000],xaxis3_range=[79000,85000], yaxis_range=[-0.001,0.085], yaxis2_range=[-0.5,0.68])\n",
    "fig4.update_layout(height=1200,width = 1300);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5db523-74b3-4c74-aa62-51e016d8cc78",
   "metadata": {},
   "source": [
    "# Analytical Solution for peaks in interpolation method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a2d27091-ce5a-4bb3-be10-72a54123e13f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nf = go.Figure()\\n\\nf.add_trace(go.Scatter(line = dict(color = \\'blue\\'), x=sample1.time,y=sample1.values, name=\\'Raw Data\\'))\\nf.add_trace(go.Scatter(mode=\\'markers\\',marker=dict(color = \\'#26E31A\\', size = 8), x = max_x,y=max_y,name=\\'Analytical Solution\\'))\\nf.add_trace(go.Scatter(mode=\\'markers\\',marker=dict(color = \\'green\\' ,size = 6), x = peaks_x, y=peaks_y, name=\\' Collected Peak Interpolation \\'+str(res)+\\'Hz\\'))\\n\\nfor h in range(0,len(max_x)):\\n    f.add_trace(go.Scatter(mode=\\'lines\\',line=dict(color=\\'#FE4384\\'), x = interpolated_peak_x[\\'peak: \\'+str(h)], \\n                               y = interpolated_peak_y[\\'peak: \\'+str(h)], showlegend= False))\\n\\n\\nf.update_layout(xaxis = dict(tickmode = \\'array\\', tickvals = sample1.ticks_values, ticktext = sample1.time_format_axis),autosize=False,\\n                     width=1250,height=600)\\n\\nf.update_layout(title=\"Pan Tompkins Interpolated Peaks       Moving Average Window = 14 samples     Analytical Solution \", \\n                         xaxis_title=\"Time\", yaxis_title= \\'Signal\\', font=dict(family=\"Avenir\",size=16,color=\"Black\"));\\n                         '"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "f = go.Figure()\n",
    "\n",
    "f.add_trace(go.Scatter(line = dict(color = 'blue'), x=sample1.time,y=sample1.values, name='Raw Data'))\n",
    "f.add_trace(go.Scatter(mode='markers',marker=dict(color = '#26E31A', size = 8), x = max_x,y=max_y,name='Analytical Solution'))\n",
    "f.add_trace(go.Scatter(mode='markers',marker=dict(color = 'green' ,size = 6), x = peaks_x, y=peaks_y, name=' Collected Peak Interpolation '+str(res)+'Hz'))\n",
    "\n",
    "for h in range(0,len(max_x)):\n",
    "    f.add_trace(go.Scatter(mode='lines',line=dict(color='#FE4384'), x = interpolated_peak_x['peak: '+str(h)], \n",
    "                               y = interpolated_peak_y['peak: '+str(h)], showlegend= False))\n",
    "\n",
    "\n",
    "f.update_layout(xaxis = dict(tickmode = 'array', tickvals = sample1.ticks_values, ticktext = sample1.time_format_axis),autosize=False,\n",
    "                     width=1250,height=600)\n",
    "\n",
    "f.update_layout(title=\"Pan Tompkins Interpolated Peaks       Moving Average Window = 14 samples     Analytical Solution \", \n",
    "                         xaxis_title=\"Time\", yaxis_title= 'Signal', font=dict(family=\"Avenir\",size=16,color=\"Black\"));\n",
    "                         \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "41509f73-a478-4909-bfa2-d129fac2000b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#f.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e0e8e1dd-7eef-4198-b53c-7c791c623988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw Peaks and Third Order Spline Peaks \n",
    "max_x, max_y, peaks_x, peaks_y, interpolated_peak_x, interpolated_peak_y, max_idxs = interpolation_spline(fiducial_point_dict['Window Length: 25'], \n",
    "                                                                                               sample1.time, sample1.values, spline, res)\n",
    "\n",
    "#fig4 = make_subplots(\n",
    "#    rows=2, cols=1,\n",
    "#    subplot_titles=(\"Raw Peaks\",\" Analytical Solution \"))\n",
    "\n",
    "fig4 = go.Figure()\n",
    "\n",
    "#fig4.add_trace(go.Scatter(line= dict(color='orange'),x=sample1.time, y = squared,name='Squared',showlegend=False),row=1, col=1)\n",
    "#fig4.add_trace(go.Scatter(line= dict(color='blue'), x=sample1.time, y = sample1.values,name='Peaks in Raw Data',showlegend=False),row=2, col=1)\n",
    "#fig4.add_trace(go.Scatter(mode='markers',marker=dict(color='red', size=9), x= sample1.time[max_idxs], y = sample1.values[max_idxs], name='Peaks In Raw Data',showlegend=False),row=2, col=1)\n",
    "\n",
    "fig4.add_trace(go.Scatter(line= dict(color='blue'), x=sample1.time, y = sample1.values,name='Peaks in MWI',showlegend=False))\n",
    "\n",
    "\n",
    "for j in range(0,len(interpolated_peak_x)):\n",
    "    fig4.add_trace(go.Scatter(line= dict(color='green'), x=interpolated_peak_x['peak: '+str(j)], y = interpolated_peak_y['peak: '+str(j)], name='Peaks in MWI',showlegend=False))\n",
    "\n",
    "    \n",
    "fig4.add_trace(go.Scatter(mode='markers',marker=dict(color='red', size=9), x=max_x, y = max_y, name='Peaks In Raw Data',showlegend=False))\n",
    "fig4.add_trace(go.Scatter(mode='markers',marker=dict(color='orange', size=7), x=sample1.time[max_idxs], y = sample1.values[max_idxs], name='Raw Peaks',showlegend=False))\n",
    "\n",
    "fig4.update_layout(xaxis = dict(tickmode = 'array', tickvals = sample1.ticks_values, ticktext = sample1.time_format_axis),\n",
    "                    xaxis2 = dict(tickmode = 'array', tickvals = sample1.ticks_values, ticktext = sample1.time_format_axis));\n",
    "fig4.update_layout(xaxis_range=[79000,85000], yaxis_range=[-0.5,0.68])\n",
    "fig4.update_layout(height=600,width = 1300);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a16a6056-1aee-4975-a356-69245d7591c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig4.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5503b0a-e42f-4937-8767-cbfa494fe012",
   "metadata": {},
   "source": [
    "#### Time Differences with different amount of control points and re sampling frequency "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8002ceb-f694-42d8-819c-768cd3248e3d",
   "metadata": {},
   "source": [
    "## Interpolation with different window lenghts in the moving window integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5dcc9537-4d99-4d69-8c14-a1aa5ff0c638",
   "metadata": {},
   "outputs": [],
   "source": [
    "interp = go.Figure()\n",
    "spline = 4\n",
    "max_x_dict= {};max_y_dict= {}\n",
    "res = 1000 \n",
    "\n",
    "\n",
    "for N in lengths: \n",
    "    \n",
    "    max_x_dict['Window: '+str(N)], max_y_dict['Window: '+str(N)], peaks_x, peaks_y, interpolated_peak_x, interpolated_peak_y, max_idx = interpolation_spline(\n",
    "        fiducial_point_dict['Window Length: '+str(N)], sample1.time, sample1.values, spline, res)\n",
    "    \n",
    "    interp.add_trace(go.Scatter(mode = 'lines', line= dict(color='blue'),x=sample1.time, y=sample1.values,showlegend=False,visible=False))\n",
    "    interp.add_trace(go.Scatter(mode = 'markers', x= max_x_dict['Window: '+str(N)], y=max_y_dict['Window: '+str(N)],\n",
    "                               name = 'Peaks ',showlegend=False,visible=False))\n",
    "    \n",
    "\n",
    "    \n",
    "interp.data[5].visible = True\n",
    "\n",
    "steps = []\n",
    "start = 0\n",
    "for length in lengths:\n",
    "    step = dict(\n",
    "        method=\"update\",\n",
    "        args=[{\"visible\": [False] * len(interp.data)},\n",
    "              {\"title\": 'Peaks Found           Window Length: ' + str(length)}],  # layout attribute\n",
    "    )\n",
    "    step[\"args\"][0][\"visible\"][start] = True # Toggle i'th trace to \"visible\"\n",
    "    step[\"args\"][0][\"visible\"][start+1] = True # Toggle i'th trace to \"visible\"\n",
    "    start = start + 2\n",
    "    steps.append(step)\n",
    "    \n",
    "sliders = [dict(active=5, currentvalue={\"prefix\": \"n: \"}, pad={\"t\": 50}, steps=steps)]\n",
    "interp.update_layout(sliders=sliders);\n",
    "#interp.update_layout(xaxis_range=[79000,85000]);\n",
    "interp.update_layout(xaxis = dict(tickmode = 'array', tickvals = sample1.ticks_values, ticktext = sample1.time_format_axis),autosize=False,width=1300,height=600);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3fc4a5bc-23dd-4be1-ba38-011ad7f9e829",
   "metadata": {},
   "outputs": [],
   "source": [
    "#interp.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd88fb7-8dd7-479c-a634-38cd744f2b09",
   "metadata": {},
   "source": [
    "## Mean Subtraction and wavelet transform "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4501dcd-c4e3-4caf-9749-485b181c9948",
   "metadata": {},
   "source": [
    "### We do the following just to check how good are the PT results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2ed4895c-0b4e-4b62-9ab6-33f7aa50cc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = average_filter(15,sample1.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cba6325d-ddf7-4241-a82f-6962c0443d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_peaks,_ = find_peaks(sample1.values-mean,distance=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2709f70a-8886-49a2-af9a-4901379a19b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig9 = go.Figure()\n",
    "\n",
    "fig9.add_trace(go.Scatter(mode = 'lines', line= dict(color='blue'),x=sample1.time, y=sample1.values,name='Raw Data',showlegend=True))\n",
    "#fig9.add_trace(go.Scatter(mode = 'lines', x=sample1.time, y=mean, name = 'Mean Average', showlegend = True))\n",
    "fig9.add_trace(go.Scatter(mode = 'lines', x=sample1.time, y=sample1.values-mean, name = 'Mean Subtraction', showlegend = True))\n",
    "fig9.update_layout(xaxis_range=[79000,85000]);\n",
    "fig9.update_layout(xaxis = dict(tickmode = 'array', tickvals = sample1.ticks_values, ticktext = sample1.time_format_axis),autosize=False,width=1200,height=600);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3dba5b-514e-4d55-9702-f5a65d95331b",
   "metadata": {},
   "source": [
    "### Interpolating with the mean subtraction peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "076360e9-0ffb-4c06-91a2-23a4588cc335",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shared/braulio/ecg_algorithm/functions.py:232: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in sqrt\n",
      "\n",
      "/home/shared/braulio/ecg_algorithm/functions.py:233: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in sqrt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spline=4;\n",
    "res = 5000\n",
    "max_x_w, max_y_w, peaks_x_w, peaks_y_w, interpolated_peak_x_w, interpolated_peak_y_w,max_idxs_m = interpolation_spline(mean_peaks, sample1.time, sample1.values, 4, res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5fd23c13-c0c1-422f-8470-796739c877ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "amount_of_peaks = len(max_x_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cb5c27fa-41e5-4b02-a201-0958a34d9077",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Comparing peaks of PT with window N"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99d675e-7ba9-422c-a2a7-b40ec042bdf0",
   "metadata": {},
   "source": [
    "### Comparing Pan Tompkins and mean average substraction + Wavelet Transform with all windows in Moving Window Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "48e8c3ec-368e-491b-aedd-0a7613c5ec35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visually missing peaks\n",
    "\n",
    "fig10 = go.Figure()\n",
    "missing_mean_p_dict ={};  missing_pt_p_dict={};\n",
    "spline=4;\n",
    "res = 5000\n",
    "\n",
    "\n",
    "for N in lengths: \n",
    "    #print(N)\n",
    "    missing_pt_p, missing_mean_p = find_missing_peaks(max_x_dict['Window: '+str(N)], max_x_w, True)\n",
    "    missing_pt_p_dict['window_length_'+str(N)] = missing_pt_p\n",
    "    missing_mean_p_dict['window_length_'+str(N)] = missing_mean_p\n",
    "    \n",
    "    fig10.add_trace(go.Scatter(line= dict(color='blue'),x=sample1.time, y=sample1.values,name='Raw Data',showlegend=True, visible = False))\n",
    "    \n",
    "\n",
    "    fig10.add_trace(go.Scatter(mode='markers',marker=dict(size=12),x=max_x_w, y= max_y_w, name = 'Mean Peaks', \n",
    "                               showlegend=True, visible = False))\n",
    "    fig10.add_trace(go.Scatter(mode='markers',marker=dict(size=10,color='#21B626'), x = max_x_dict['Window: '+str(N)], \n",
    "                              y = max_y_dict['Window: '+str(N)], name = 'P.T. Peaks WL: '+str(N),showlegend=True, \n",
    "                              visible = False))\n",
    "    fig10.add_trace(go.Scatter(mode='markers',marker=dict(size=7,color='orange'), x = max_x_dict['Window: '+str(N)][missing_mean_p], \n",
    "                               y= max_y_dict['Window: '+str(N)][missing_mean_p], name = 'Missing Mean Peaks', showlegend=True, visible = False))\n",
    "    \n",
    "    fig10.add_trace(go.Scatter(mode='markers',marker=dict(size=7,color='#00FCF5'),x = max_x_w[missing_pt_p] , y= max_y_w[missing_pt_p], \n",
    "                              name = 'Missing P.T. Peaks', showlegend=True, visible = False))\n",
    "\n",
    "fig10.data[5].visible = True\n",
    "\n",
    "steps = []\n",
    "start = 0\n",
    "for i in range(0,len(lengths)):\n",
    "    step = dict(\n",
    "        method=\"update\",\n",
    "        args=[{\"visible\": [False] * len(fig10.data)},\n",
    "              {\"title\": \"Peaks identified with PT window length \"+str(lengths[i])+ '   Amount of Mean + Wavelet Missing Peaks: '+\n",
    "               str(len(missing_mean_p_dict['window_length_'+str(lengths[i])])) +'   Amount of PT Missing Peaks: '+ \n",
    "               str(len(missing_pt_p_dict['window_length_'+str(lengths[i])]))}],  # layout attribute\n",
    "    )\n",
    "    step[\"args\"][0][\"visible\"][start] = True  # Toggle i'th trace to \"visible\"\n",
    "    step[\"args\"][0][\"visible\"][start+1] = True\n",
    "    step[\"args\"][0][\"visible\"][start+2] = True\n",
    "    step[\"args\"][0][\"visible\"][start+3] = True\n",
    "    step[\"args\"][0][\"visible\"][start+4] = True\n",
    "    \n",
    "    start = start+5\n",
    "    steps.append(step)\n",
    "    \n",
    "sliders = [dict(active=5, currentvalue={\"prefix\": \"n: \"}, pad={\"t\": 50}, steps=steps)]\n",
    "fig10.update_layout(sliders=sliders);\n",
    "fig10.update_layout(xaxis_range=[79000,85000]);\n",
    "fig10.update_layout(xaxis = dict(tickmode = 'array', tickvals = sample1.ticks_values, ticktext = sample1.time_format_axis),autosize=False,width=1200,height=600); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "296daaca-8e52-4f3e-9732-106369deacc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig10.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ec2a74ce-068e-46e9-aa66-8d83effea205",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_array = np.delete(max_x_dict['Window: 25'],0)\n",
    "second_array = np.delete(max_x_dict['Window: 25'],-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f1bc813b-e2c2-44c9-98bb-e7f5cb888e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "dif = (first_array - second_array)/1000\n",
    "time_intvl_mins = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913ea4e6-2032-4f75-8205-5ea3a544fd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k is the index where the cumulative sum of time is greater than half the time interval\n",
    "k = 0\n",
    "cmltive_time = 0\n",
    "even_idx = []\n",
    "odd_idx = [0]\n",
    "\n",
    "# The total time of the interval will be defined by the amount of windows one chooses, the overlap and the length of the windows. \n",
    "time_wind_length = 30\n",
    "overlap_window = 0.5\n",
    "windows = 10\n",
    "total_time = time_wind_length + ((1-overlap_window)*time_wind_length*(windows-1))\n",
    "\n",
    "#This first loop is to find the index of the beginning of the second window \n",
    "while cmltive_time < (time_wind_length*60)/2 : \n",
    "    k = k + 1\n",
    "    cmltive_time = np.sum(dif[0:k])\n",
    "    \n",
    "even_idx = np.append(even_idx,k-1)\n",
    "leading_time = time_intvl_mins*60\n",
    "\n",
    "window_counter = 1\n",
    "odd = True \n",
    "\n",
    "while window_counter <= windows\n",
    "    \n",
    "    window_counter = window_counter + 1\n",
    "    \n",
    "    while cmltive_time < leading_time: \n",
    "        k = k + 1 \n",
    "        cmltive_time = np.sum(dif[0:k])\n",
    "\n",
    "\n",
    "    if odd:\n",
    "        den = 2\n",
    "        odd = False \n",
    "        odd_idx = np.append(odd_idx,k-1)\n",
    "\n",
    "    else: \n",
    "        den = 1\n",
    "        odd = True\n",
    "        even_idx = np.append(even_idx,k-1)\n",
    "\n",
    "\n",
    "    leading_time = cmltive_time + ((time_wind_length*60)/den)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f4ac77a6-a0de-4e5d-97e0-142d846b563c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# k is the index where the cumulative sum of time is greater than half the time interval\n",
    "k = 0\n",
    "cmltive_time = 0\n",
    "even_idx = []\n",
    "odd_idx = [0]\n",
    "\n",
    "# The total time of the interval will be defined by the amount of windows one chooses, the overlap and the length of the windows. \n",
    "time_wind_length = 30\n",
    "overlap_window = 0.5\n",
    "windows = 10\n",
    "total_time = time_wind_length + ((1-overlap_window)*time_wind_length*(windows-1))\n",
    "\n",
    "#This first loop is to find the index of the beginning of the second window \n",
    "while cmltive_time < (time_wind_length*60)/2 : \n",
    "    k = k + 1\n",
    "    cmltive_time = np.sum(dif[0:k])\n",
    "    \n",
    "even_idx = np.append(even_idx,k-1)\n",
    "leading_time = time_intvl_mins*60\n",
    "\n",
    "window_counter = 1\n",
    "odd = True \n",
    "\n",
    "while window_counter <= windows\n",
    "    \n",
    "    window_counter = window_counter + 1\n",
    "    \n",
    "    while cmltive_time < leading_time: \n",
    "        k = k + 1 \n",
    "        cmltive_time = np.sum(dif[0:k])\n",
    "\n",
    "\n",
    "    if odd:\n",
    "        den = 2\n",
    "        odd = False \n",
    "        odd_idx = np.append(odd_idx,k-1)\n",
    "\n",
    "    else: \n",
    "        den = 1\n",
    "        odd = True\n",
    "        even_idx = np.append(even_idx,k-1)\n",
    "\n",
    "\n",
    "    leading_time = cmltive_time + ((time_wind_length*60)/den)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5d89f6d2-d858-4836-9d3a-13ee4123ef2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "be0e3ceb-ce5c-4082-af44-558eab2c2834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(a[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3611d435-1dd4-4bd4-9a60-75f23ae9b4bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([180.85120655, 181.77937709, 182.07347344, 182.42312597,\n",
       "       181.22647486, 181.50944757, 182.33277806, 182.49347852,\n",
       "       182.20693845, 181.17916184, 184.00771046, 179.94499149,\n",
       "       186.16398115, 182.39423665, 186.00882663, 179.99943699,\n",
       "       183.36393582, 180.21660572, 183.6043708 , 184.7725852 ,\n",
       "       178.77125263, 185.52021309, 182.81332845, 182.64498422,\n",
       "       182.42900638, 182.76681673, 181.58037532, 181.42944093,\n",
       "       181.59291633, 179.39519019, 176.45175866, 176.33535051,\n",
       "       173.51108035, 174.21764918, 172.0906726 , 170.63678119,\n",
       "       168.0696172 , 168.34664682, 166.26896454, 164.51074594,\n",
       "       162.91539714, 165.05119095, 161.68347176, 163.46385887,\n",
       "       163.39614388, 164.61699824, 165.3518965 , 165.70620057,\n",
       "       166.35184913, 167.61205116, 168.51391707, 171.26233536,\n",
       "       171.16314381, 174.36219726, 176.1641006 , 175.31783566,\n",
       "       178.28425261, 179.24676744, 180.21258856, 182.13317066,\n",
       "       182.49281168, 183.02391543, 183.30508367, 183.51355264,\n",
       "       183.76167881, 183.54455123, 182.52175977, 183.6232679 ,\n",
       "       184.08594855, 184.11376024, 184.86659556, 184.40601238,\n",
       "       186.40952622, 181.93666363, 180.74100319, 180.28975283,\n",
       "       183.92322718, 180.65030501, 179.54995824, 178.40982946,\n",
       "       177.85535807, 177.26378547, 177.78745439, 177.22827058,\n",
       "       177.72065197, 153.43111066, 213.89465549, 181.39619439,\n",
       "       178.60415492, 179.39011108, 175.78917889, 182.78798579,\n",
       "       180.42973461, 178.17076052, 180.36132494, 178.78657392,\n",
       "       178.67141323, 179.59840382, 179.60269759, 179.75674318,\n",
       "       178.91534169, 178.88734419, 178.95956167, 178.74540063,\n",
       "       178.79257095, 178.90119807, 179.38410412, 179.70028117,\n",
       "       179.15985838, 179.93998488, 180.24067725, 181.20337325,\n",
       "       179.58539699, 180.14385127, 181.06415872, 181.77336462,\n",
       "       181.28571725, 181.86652047, 182.65368831, 181.78949659,\n",
       "       182.18091007, 182.1278158 , 181.21611214, 181.15688871,\n",
       "       180.67114789, 180.43694602, 181.56892939, 180.0523642 ,\n",
       "       181.3086332 , 181.78155912, 180.15157576, 181.99793113,\n",
       "       183.20910702, 181.81602024, 178.66880674, 187.11554503,\n",
       "       185.13348694, 184.8348133 , 185.48317393, 185.66672283,\n",
       "       183.76375918, 184.85530977, 185.44045882, 187.17657147,\n",
       "       185.19114984, 186.57730892, 186.31215255, 184.73084932,\n",
       "       190.64221633, 188.42025203, 141.39764803, 241.77468693,\n",
       "       222.90933602, 190.92889471, 191.93391368, 188.76988264,\n",
       "       189.49911636, 186.28911959, 189.88203099, 190.58753771,\n",
       "       190.69239108, 191.81141464, 192.41405163, 191.80456207,\n",
       "       191.60185953, 190.79158089, 187.33764318, 187.50567237,\n",
       "       210.99366962, 169.30870298, 186.33866149, 186.34728215,\n",
       "       185.40213284, 184.28863243, 184.44415452, 181.15189619,\n",
       "       179.58115171, 181.12013391, 180.84572272])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "60/((first_array - second_array)/1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313c7a8c-8095-4600-a36f-4bc087f2ce9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
