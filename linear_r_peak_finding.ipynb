{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7247ad-c2e8-469b-bf16-8a090c459f2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "290aa860-d2a1-492d-82ec-2d9d127c735e",
   "metadata": {},
   "source": [
    "# Document's Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35d6c0c-3f2a-405d-8553-ef34b88ec6e6",
   "metadata": {},
   "source": [
    "#### · Display raw data from cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb031946-3161-493e-9ec1-04a4741f9e49",
   "metadata": {},
   "source": [
    "#### · Display raw data and located peaks recorded in cluster "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fc7aa9-0dc4-4215-9abf-097d9c171732",
   "metadata": {},
   "source": [
    "#### · Find peaks of recorder raw data with the most updated version of the algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1829aa45-9481-4062-8469-8fa2a67fd1d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b991332-290e-4327-83ab-27b2d45b062a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pymongo==3.13.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f41072d9-9310-4bd7-a3c8-3dbdd8295ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1be889b9-72ff-482f-ada7-345a782889d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_name = 'braulio.ramirez'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf36577a-f81f-42b0-a956-ec62464acdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger('jhub')\n",
    "hostname = 'mongos.mongo.svc.cluster.local:27017'\n",
    "pemkeyfile = '/etc/mongo/jhub-keypem.pem'\n",
    "sslca = '/etc/mongo/root-ca.pem'\n",
    "\n",
    "nirscloud_util_meta.init(logger, 'meta', hostname=hostname, ssl=True, cert=pemkeyfile, ca=sslca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "784166a8-3bb9-4462-bdec-d9255df1654c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-12 15:20:09 [INFO ] cfg#_init_hdfs_kinit@79: after hdfs_kinit: the_stdout: b'' the_stderr: b''\n",
      "2023-07-12 15:20:09 [INFO ] client#__init__@192: Instantiated <KerberosClient(url='https://hdfs2.babynirs.org:9870;https://hdfs1.babynirs.org:9870;https://hdfs4.babynirs.org:9870')>.\n"
     ]
    }
   ],
   "source": [
    "spark_kerberos_principal = my_name + '@BABYNIRS.ORG'\n",
    "\n",
    "params = {\n",
    "    'spark_kerberos_principal': spark_kerberos_principal,\n",
    "}\n",
    "nirscloud_util_hdfs.init('/etc/jhub/conf/production.ini', params=params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9682083-9c01-4a9d-bc69-34bb8224669e",
   "metadata": {},
   "source": [
    "### Pulling the recorded peaks from the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "829c37dc-48bc-4c72-a51f-47f6488b4a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdfs_path = '_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=01/_patient_id=5984929'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5848ff80-2731-4aff-b3bd-0e26d800f5ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kafka_topics = 'nk_rpeak2_NICU'\n",
    "hdfs_prefix = '/kafka/topics/%s'% (kafka_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9443025f-cfe8-4370-879b-797b1a25bf86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _get_df(hdfs_path, the_id):\n",
    "    hdfs_path = hdfs_path\n",
    "    full_path = nirscloud_util_hdfs.full_path(hdfs_prefix, hdfs_path)\n",
    "    err, df = nirscloud_util_hdfs.from_hdfs_path(full_path)\n",
    "    print(err, df)\n",
    "    is_valid = df['id'] == the_id\n",
    "    df = df[is_valid]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbc7b90a-c015-4b49-9375-b1d854cc8744",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-12 15:20:09 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-12 15:20:09 [INFO ] client#status@320: Fetching status for '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=01/_patient_id=5984929'.\n",
      "2023-07-12 15:20:09 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-12 15:20:09 [INFO ] client#status@320: Fetching status for '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=01/_patient_id=5984929'.\n",
      "2023-07-12 15:20:09 [INFO ] client#list@1123: Listing '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=01/_patient_id=5984929'.\n",
      "2023-07-12 15:20:09 [INFO ] client#list@1123: Listing '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=01/_patient_id=5984929'.\n",
      "2023-07-12 15:20:09 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-12 15:20:09 [INFO ] client#status@320: Fetching status for '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=01/_patient_id=5984929/part-00000-2bed6e71-3458-40ff-bd6a-894ea0f677d2.c000.snappy.parquet'.\n",
      "2023-07-12 15:20:09 [INFO ] client#read@731: Reading file '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=01/_patient_id=5984929/part-00000-2bed6e71-3458-40ff-bd6a-894ea0f677d2.c000.snappy.parquet'.\n",
      "2023-07-12 15:20:09 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-12 15:20:09 [INFO ] client#status@320: Fetching status for '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=01/_patient_id=5984929/part-00000-4b0f4db1-a2fa-405a-ab93-a6abcb03527b.c000.snappy.parquet'.\n",
      "2023-07-12 15:20:09 [INFO ] client#read@731: Reading file '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=01/_patient_id=5984929/part-00000-4b0f4db1-a2fa-405a-ab93-a6abcb03527b.c000.snappy.parquet'.\n",
      "2023-07-12 15:20:10 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-12 15:20:10 [INFO ] client#status@320: Fetching status for '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=01/_patient_id=5984929/part-00000-5044d8a5-7d8a-4293-b00c-5d8040e800f4.c000.snappy.parquet'.\n",
      "2023-07-12 15:20:10 [INFO ] client#read@731: Reading file '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=01/_patient_id=5984929/part-00000-5044d8a5-7d8a-4293-b00c-5d8040e800f4.c000.snappy.parquet'.\n",
      "2023-07-12 15:20:10 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-12 15:20:10 [INFO ] client#status@320: Fetching status for '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=01/_patient_id=5984929/part-00000-baac1fae-ebc2-4339-9a47-23d2b20f6823.c000.snappy.parquet'.\n",
      "2023-07-12 15:20:10 [INFO ] client#read@731: Reading file '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=01/_patient_id=5984929/part-00000-baac1fae-ebc2-4339-9a47-23d2b20f6823.c000.snappy.parquet'.\n",
      "2023-07-12 15:20:10 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-12 15:20:10 [INFO ] client#status@320: Fetching status for '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=01/_patient_id=5984929/part-00000-c52510c8-5fd4-4b44-947a-0c25284116d7.c000.snappy.parquet'.\n",
      "2023-07-12 15:20:10 [INFO ] client#read@731: Reading file '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=01/_patient_id=5984929/part-00000-c52510c8-5fd4-4b44-947a-0c25284116d7.c000.snappy.parquet'.\n",
      "2023-07-12 15:20:10 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-12 15:20:10 [INFO ] client#status@320: Fetching status for '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=01/_patient_id=5984929/part-00000-e7f9f121-98a9-4acc-8617-75e3506e9f55.c000.snappy.parquet'.\n",
      "2023-07-12 15:20:10 [INFO ] client#read@731: Reading file '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=01/_patient_id=5984929/part-00000-e7f9f121-98a9-4acc-8617-75e3506e9f55.c000.snappy.parquet'.\n",
      "2023-07-12 15:20:10 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-12 15:20:10 [INFO ] client#status@320: Fetching status for '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=01/_patient_id=5984929/part-00001-29c3fd2b-0756-416e-a92d-680cbe09262e.c000.snappy.parquet'.\n",
      "2023-07-12 15:20:10 [INFO ] client#read@731: Reading file '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=01/_patient_id=5984929/part-00001-29c3fd2b-0756-416e-a92d-680cbe09262e.c000.snappy.parquet'.\n",
      "2023-07-12 15:20:10 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-12 15:20:10 [INFO ] client#status@320: Fetching status for '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=01/_patient_id=5984929/part-00001-73c1ff62-010e-40b9-be39-6da264b503f6.c000.snappy.parquet'.\n",
      "2023-07-12 15:20:10 [INFO ] client#read@731: Reading file '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=01/_patient_id=5984929/part-00001-73c1ff62-010e-40b9-be39-6da264b503f6.c000.snappy.parquet'.\n",
      "2023-07-12 15:20:10 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-12 15:20:10 [INFO ] client#status@320: Fetching status for '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=01/_patient_id=5984929/part-00001-8fbfa19c-4f1c-4c7f-925c-b5b53b2a2afa.c000.snappy.parquet'.\n",
      "2023-07-12 15:20:10 [INFO ] client#read@731: Reading file '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=01/_patient_id=5984929/part-00001-8fbfa19c-4f1c-4c7f-925c-b5b53b2a2afa.c000.snappy.parquet'.\n",
      "2023-07-12 15:20:10 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-12 15:20:10 [INFO ] client#status@320: Fetching status for '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=01/_patient_id=5984929/part-00001-a13eaa12-3885-45ea-a28c-950e3ef28bcf.c000.snappy.parquet'.\n",
      "2023-07-12 15:20:10 [INFO ] client#read@731: Reading file '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=01/_patient_id=5984929/part-00001-a13eaa12-3885-45ea-a28c-950e3ef28bcf.c000.snappy.parquet'.\n",
      "2023-07-12 15:20:10 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-12 15:20:10 [INFO ] client#status@320: Fetching status for '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=01/_patient_id=5984929/part-00001-bf0c82a8-9207-48b5-be17-9aacf6ca4a53.c000.snappy.parquet'.\n",
      "2023-07-12 15:20:10 [INFO ] client#read@731: Reading file '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=01/_patient_id=5984929/part-00001-bf0c82a8-9207-48b5-be17-9aacf6ca4a53.c000.snappy.parquet'.\n",
      "2023-07-12 15:20:10 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-12 15:20:11 [INFO ] client#status@320: Fetching status for '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=01/_patient_id=5984929/part-00001-f9b31328-aa82-4af6-8c1c-40b1cc3bebb6.c000.snappy.parquet'.\n",
      "2023-07-12 15:20:11 [INFO ] client#read@731: Reading file '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=01/_patient_id=5984929/part-00001-f9b31328-aa82-4af6-8c1c-40b1cc3bebb6.c000.snappy.parquet'.\n",
      "2023-07-12 15:20:11 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-12 15:20:11 [INFO ] client#status@320: Fetching status for '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=01/_patient_id=5984929/part-00002-10eb940b-ecb4-4298-b88a-9e25225aeb9d.c000.snappy.parquet'.\n",
      "2023-07-12 15:20:11 [INFO ] client#read@731: Reading file '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=01/_patient_id=5984929/part-00002-10eb940b-ecb4-4298-b88a-9e25225aeb9d.c000.snappy.parquet'.\n",
      "2023-07-12 15:20:11 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-12 15:20:11 [INFO ] client#status@320: Fetching status for '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=01/_patient_id=5984929/part-00002-3bbbc5c7-6f56-4aaa-ac86-43823d123173.c000.snappy.parquet'.\n",
      "2023-07-12 15:20:11 [INFO ] client#read@731: Reading file '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=01/_patient_id=5984929/part-00002-3bbbc5c7-6f56-4aaa-ac86-43823d123173.c000.snappy.parquet'.\n",
      "2023-07-12 15:20:11 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-12 15:20:11 [INFO ] client#status@320: Fetching status for '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=01/_patient_id=5984929/part-00002-422fe796-57f8-4d1d-94dd-0fc9444ecce8.c000.snappy.parquet'.\n",
      "2023-07-12 15:20:11 [INFO ] client#read@731: Reading file '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=01/_patient_id=5984929/part-00002-422fe796-57f8-4d1d-94dd-0fc9444ecce8.c000.snappy.parquet'.\n",
      "2023-07-12 15:20:11 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-12 15:20:11 [INFO ] client#status@320: Fetching status for '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=01/_patient_id=5984929/part-00002-4e9b4b8e-6d89-491d-8b78-35798ec191e5.c000.snappy.parquet'.\n",
      "2023-07-12 15:20:11 [INFO ] client#read@731: Reading file '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=01/_patient_id=5984929/part-00002-4e9b4b8e-6d89-491d-8b78-35798ec191e5.c000.snappy.parquet'.\n",
      "2023-07-12 15:20:11 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-12 15:20:11 [INFO ] client#status@320: Fetching status for '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=01/_patient_id=5984929/part-00002-b6185111-5bf5-424a-bed6-9cfdb51c302f.c000.snappy.parquet'.\n",
      "2023-07-12 15:20:11 [INFO ] client#read@731: Reading file '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=01/_patient_id=5984929/part-00002-b6185111-5bf5-424a-bed6-9cfdb51c302f.c000.snappy.parquet'.\n",
      "2023-07-12 15:20:11 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-12 15:20:11 [INFO ] client#status@320: Fetching status for '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=01/_patient_id=5984929/part-00002-f07e5c04-dbeb-4e4e-a2fb-57aace319cde.c000.snappy.parquet'.\n",
      "2023-07-12 15:20:11 [INFO ] client#read@731: Reading file '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=01/_patient_id=5984929/part-00002-f07e5c04-dbeb-4e4e-a2fb-57aace319cde.c000.snappy.parquet'.\n",
      "2023-07-12 15:20:11 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-12 15:20:11 [INFO ] client#status@320: Fetching status for '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=01/_patient_id=5984929/part-00003-0c0ea968-ce90-4cd1-b5d3-5d358ddec062.c000.snappy.parquet'.\n",
      "2023-07-12 15:20:11 [INFO ] client#read@731: Reading file '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=01/_patient_id=5984929/part-00003-0c0ea968-ce90-4cd1-b5d3-5d358ddec062.c000.snappy.parquet'.\n",
      "2023-07-12 15:20:11 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-12 15:20:11 [INFO ] client#status@320: Fetching status for '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=01/_patient_id=5984929/part-00003-26df9edf-ee62-40b1-b112-16556e2b69a6.c000.snappy.parquet'.\n",
      "2023-07-12 15:20:11 [INFO ] client#read@731: Reading file '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=01/_patient_id=5984929/part-00003-26df9edf-ee62-40b1-b112-16556e2b69a6.c000.snappy.parquet'.\n",
      "2023-07-12 15:20:11 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-12 15:20:11 [INFO ] client#status@320: Fetching status for '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=01/_patient_id=5984929/part-00003-320ac460-5ed5-4c61-9ec0-fd1bbee3d759.c000.snappy.parquet'.\n",
      "2023-07-12 15:20:11 [INFO ] client#read@731: Reading file '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=01/_patient_id=5984929/part-00003-320ac460-5ed5-4c61-9ec0-fd1bbee3d759.c000.snappy.parquet'.\n",
      "2023-07-12 15:20:12 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-12 15:20:12 [INFO ] client#status@320: Fetching status for '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=01/_patient_id=5984929/part-00003-52c9f412-95e8-4581-a6bf-29ea2e1ab06b.c000.snappy.parquet'.\n",
      "2023-07-12 15:20:12 [INFO ] client#read@731: Reading file '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=01/_patient_id=5984929/part-00003-52c9f412-95e8-4581-a6bf-29ea2e1ab06b.c000.snappy.parquet'.\n",
      "2023-07-12 15:20:12 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-12 15:20:12 [INFO ] client#status@320: Fetching status for '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=01/_patient_id=5984929/part-00003-5ea1cc9f-ba00-4440-a31b-fd247965078f.c000.snappy.parquet'.\n",
      "2023-07-12 15:20:12 [INFO ] client#read@731: Reading file '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=01/_patient_id=5984929/part-00003-5ea1cc9f-ba00-4440-a31b-fd247965078f.c000.snappy.parquet'.\n",
      "2023-07-12 15:20:12 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-12 15:20:12 [INFO ] client#status@320: Fetching status for '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=01/_patient_id=5984929/part-00003-d9ff4c4e-9757-4df7-8e65-a4de846d5298.c000.snappy.parquet'.\n",
      "2023-07-12 15:20:12 [INFO ] client#read@731: Reading file '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=01/_patient_id=5984929/part-00003-d9ff4c4e-9757-4df7-8e65-a4de846d5298.c000.snappy.parquet'.\n",
      "2023-07-12 15:20:12 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-12 15:20:12 [INFO ] client#status@320: Fetching status for '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=01/_patient_id=5984929/part-00004-07ce2259-fa73-4434-8c36-6952a3a20d02.c000.snappy.parquet'.\n",
      "2023-07-12 15:20:12 [INFO ] client#read@731: Reading file '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=01/_patient_id=5984929/part-00004-07ce2259-fa73-4434-8c36-6952a3a20d02.c000.snappy.parquet'.\n",
      "2023-07-12 15:20:12 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-12 15:20:12 [INFO ] client#status@320: Fetching status for '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=01/_patient_id=5984929/part-00004-228ea891-55e0-47db-9c0d-305a6092235c.c000.snappy.parquet'.\n",
      "2023-07-12 15:20:12 [INFO ] client#read@731: Reading file '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=01/_patient_id=5984929/part-00004-228ea891-55e0-47db-9c0d-305a6092235c.c000.snappy.parquet'.\n",
      "2023-07-12 15:20:12 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-12 15:20:12 [INFO ] client#status@320: Fetching status for '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=01/_patient_id=5984929/part-00004-2e7a054d-2d08-4211-9ccd-40729d8a255e.c000.snappy.parquet'.\n",
      "2023-07-12 15:20:12 [INFO ] client#read@731: Reading file '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=01/_patient_id=5984929/part-00004-2e7a054d-2d08-4211-9ccd-40729d8a255e.c000.snappy.parquet'.\n",
      "2023-07-12 15:20:12 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-12 15:20:12 [INFO ] client#status@320: Fetching status for '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=01/_patient_id=5984929/part-00004-4ef5ce16-74b2-491d-ba23-c2ca2620aa5b.c000.snappy.parquet'.\n",
      "2023-07-12 15:20:12 [INFO ] client#read@731: Reading file '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=01/_patient_id=5984929/part-00004-4ef5ce16-74b2-491d-ba23-c2ca2620aa5b.c000.snappy.parquet'.\n",
      "2023-07-12 15:20:12 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-12 15:20:12 [INFO ] client#status@320: Fetching status for '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=01/_patient_id=5984929/part-00004-60aa0407-7f44-4647-8ecf-91753687bd8b.c000.snappy.parquet'.\n",
      "2023-07-12 15:20:12 [INFO ] client#read@731: Reading file '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=01/_patient_id=5984929/part-00004-60aa0407-7f44-4647-8ecf-91753687bd8b.c000.snappy.parquet'.\n",
      "2023-07-12 15:20:12 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-12 15:20:12 [INFO ] client#status@320: Fetching status for '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=01/_patient_id=5984929/part-00004-7e6cbcfe-bd8d-47e3-a996-94dd079d7663.c000.snappy.parquet'.\n",
      "2023-07-12 15:20:12 [INFO ] client#read@731: Reading file '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=01/_patient_id=5984929/part-00004-7e6cbcfe-bd8d-47e3-a996-94dd079d7663.c000.snappy.parquet'.\n",
      "2023-07-12 15:20:12 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-12 15:20:12 [INFO ] client#status@320: Fetching status for '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=01/_patient_id=5984929/part-00004-f984fd85-2f73-4db9-8886-ae8b1fbd4a60.c000.snappy.parquet'.\n",
      "2023-07-12 15:20:12 [INFO ] client#read@731: Reading file '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=01/_patient_id=5984929/part-00004-f984fd85-2f73-4db9-8886-ae8b1fbd4a60.c000.snappy.parquet'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None        id             start_ns          rec_nano_ts       val      ver  \\\n",
      "0      II  1686376198314000000  1686376199418015371  1.026001  v0.0.23   \n",
      "1      II  1686376198826000000  1686376199794493203  0.591038  v0.0.23   \n",
      "2      II  1686376199338000000  1686376200164770511 -0.116190  v0.0.23   \n",
      "3      II  1686376199338000000  1686376200535670419  0.825738  v0.0.23   \n",
      "4      II  1686376199850000000  1686376200903335551 -0.066866  v0.0.23   \n",
      "...    ..                  ...                  ...       ...      ...   \n",
      "10095  II  1686374381226000000  1686374382120441656 -0.329833  v0.0.23   \n",
      "10096  II  1686374381226000000  1686374382459361874  1.132980  v0.0.23   \n",
      "10097  II  1686374381738000000  1686374382798450036  0.174888  v0.0.23   \n",
      "10098  II  1686374382250000000  1686374383135835153  0.434357  v0.0.23   \n",
      "10099  II  1686374382250000000  1686374383474825361  0.436551  v0.0.23   \n",
      "\n",
      "      _device_id  _bed_id   _the_date _hr _patient_id  \n",
      "0        Procyon  HA11-01  2023-06-10  01     5984929  \n",
      "1        Procyon  HA11-01  2023-06-10  01     5984929  \n",
      "2        Procyon  HA11-01  2023-06-10  01     5984929  \n",
      "3        Procyon  HA11-01  2023-06-10  01     5984929  \n",
      "4        Procyon  HA11-01  2023-06-10  01     5984929  \n",
      "...          ...      ...         ...  ..         ...  \n",
      "10095    Procyon  HA11-01  2023-06-10  01     5984929  \n",
      "10096    Procyon  HA11-01  2023-06-10  01     5984929  \n",
      "10097    Procyon  HA11-01  2023-06-10  01     5984929  \n",
      "10098    Procyon  HA11-01  2023-06-10  01     5984929  \n",
      "10099    Procyon  HA11-01  2023-06-10  01     5984929  \n",
      "\n",
      "[10100 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "df_II_peaks = _get_df(hdfs_path, 'II')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a745a74-9e1b-4c14-a126-7c116801485d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_II_peaks.sort_values(by=['rec_nano_ts'], inplace=True)\n",
    "df_II_peaks.reset_index(drop=True, inplace=True)\n",
    "df_II_peaks['shift_rec_nano_ts'] = df_II_peaks['rec_nano_ts'].shift(-1)\n",
    "df_II_peaks['dif_rec_nano_ts'] = df_II_peaks['shift_rec_nano_ts'] - df_II_peaks['rec_nano_ts']\n",
    "df_II_peaks;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5bc05c0-5f80-49c0-82f5-954c40710c6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "values_p = np.asarray(df_II_peaks['val'].to_numpy())\n",
    "raw_time_p = np.asarray(df_II_peaks['rec_nano_ts'].to_numpy(), dtype = 'int')\n",
    "time_p = [np.datetime64(int(t),'ns') for t in raw_time_p]\n",
    "time_pks = np.array([(pd.Timestamp(t).hour*60*60*1000) + (pd.Timestamp(t).minute*60*1000) + (pd.Timestamp(t).second*1000) + (pd.Timestamp(t).microsecond/1000) for t in time_p]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "470ad255-978b-484c-b696-300861add7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "kafka_topics_cs = 'nk_waves_NICU'\n",
    "hdfs_prefix_cs = '/nirscloud/agg_by_hr3/%s'% (kafka_topics_cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3983926-1996-4999-b07f-25754dcae52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_df_cs(hdfs_path, the_id):\n",
    "    hdfs_path = hdfs_path + '/id=%s' % (the_id)\n",
    "    full_path = nirscloud_util_hdfs.full_path(hdfs_prefix_cs, hdfs_path)\n",
    "    err, df = nirscloud_util_hdfs.from_hdfs_path(full_path)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6399e94-2bcc-4ece-95b0-2d117375cb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time series need to be concatenated accoording to the amount of time that is going to be analyzed "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8ba35c-8863-41a4-885c-61f31f7afa7d",
   "metadata": {},
   "source": [
    "# Getting a sample from raw data in cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6412c05d-fb3b-4d03-b603-a9338e7dd2f5",
   "metadata": {},
   "source": [
    "##### When getting a sample the first thing to be considered is the amount of time, and this is determined by the stats that are to be done afterwards.\n",
    "##### We cacn think in terms of how many windows do we want to analyze or how much time, the length of the window and their overlap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb7aa59b-5e05-44d7-a644-ed6372d960f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time length can be in intervals of 2.5 minutes starting from 5\n",
      "\n",
      "You can either choose the amount of windows or the total amount of time\n"
     ]
    }
   ],
   "source": [
    "# The total time of the interval will be defined by the amount of windows one chooses, the overlap and the length of the windows.\n",
    "time_wind_length = 5; overlap_window = 0.5; \n",
    "print('Total time length can be in intervals of ' +str(round(time_wind_length*overlap_window,2))+ ' minutes starting from '+str(time_wind_length))\n",
    "print('')\n",
    "print('You can either choose the amount of windows or the total amount of time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c0aff925-5c96-473c-af1a-87e4b859f3c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of time is 20 minutes and the amount of windows is 7\n"
     ]
    }
   ],
   "source": [
    "#In this block you can enter the total amount of time to analyze or the amount of windows\n",
    "\n",
    "by_time = True; total_time = 20; windows = 12;\n",
    "\n",
    "\n",
    "if by_time: \n",
    "    by_windows = False\n",
    "else: by_windows = True\n",
    "\n",
    "if by_time: \n",
    "    if total_time%(time_wind_length*overlap_window) != 0: \n",
    "        print('The amount of time entered is not divisible by '+str(time_wind_length*overlap_window))\n",
    "    windows = int(total_time/(time_wind_length*overlap_window)) - 1 \n",
    "    print('The amount of time is '+str(int(total_time))+' minutes and the amount of windows is '+str(windows))\n",
    "\n",
    "    \n",
    "if by_windows: \n",
    "    windows = 12\n",
    "    total_time = (1-overlap_window)*time_wind_length*(windows) + 15\n",
    "    print('The amount of time is '+str(int(total_time))+' minutes and the amount of windows is '+str(windows))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "16126927-ea07-4ccc-91e6-89f62004944f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This line is important because it establishes what will be the first hour \n",
    "first_hour = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "94387886-a8a2-4d91-b3ec-0cdb4f24528c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-12 15:20:13 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-12 15:20:13 [INFO ] client#status@320: Fetching status for '/nirscloud/agg_by_hr3/nk_waves_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=01/_patient_id=5984929/id=MDC_ECG_ELEC_POTL_II'.\n",
      "2023-07-12 15:20:13 [INFO ] client#status@320: Fetching status for '/'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting 1 hour\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-12 15:20:13 [INFO ] client#status@320: Fetching status for '/nirscloud/agg_by_hr3/nk_waves_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=01/_patient_id=5984929/id=MDC_ECG_ELEC_POTL_II'.\n",
      "2023-07-12 15:20:13 [INFO ] client#list@1123: Listing '/nirscloud/agg_by_hr3/nk_waves_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=01/_patient_id=5984929/id=MDC_ECG_ELEC_POTL_II'.\n",
      "2023-07-12 15:20:13 [INFO ] client#status@320: Fetching status for '/nirscloud/agg_by_hr3/nk_waves_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=01/_patient_id=5984929/id=MDC_ECG_ELEC_POTL_II'.\n",
      "2023-07-12 15:20:13 [INFO ] client#list@1123: Listing '/nirscloud/agg_by_hr3/nk_waves_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=01/_patient_id=5984929/id=MDC_ECG_ELEC_POTL_II'.\n",
      "2023-07-12 15:20:13 [INFO ] client#status@320: Fetching status for '/nirscloud/agg_by_hr3/nk_waves_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=01/_patient_id=5984929/id=MDC_ECG_ELEC_POTL_II'.\n",
      "2023-07-12 15:20:13 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-12 15:20:13 [INFO ] client#status@320: Fetching status for '/nirscloud/agg_by_hr3/nk_waves_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=01/_patient_id=5984929/id=MDC_ECG_ELEC_POTL_II/part-00001-ac0d3d20-be26-431f-94d2-7fc3a5c37dac.c000.snappy.parquet'.\n",
      "2023-07-12 15:20:13 [INFO ] client#read@731: Reading file '/nirscloud/agg_by_hr3/nk_waves_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=01/_patient_id=5984929/id=MDC_ECG_ELEC_POTL_II/part-00001-ac0d3d20-be26-431f-94d2-7fc3a5c37dac.c000.snappy.parquet'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted hour: 1\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "# Extracting and concatenating dataframes according to time. \n",
    "\n",
    "if total_time%60 == 0: \n",
    "    amount_hours = int(total_time/60)\n",
    "else:\n",
    "    amount_hours = int((total_time - total_time%60)/60) + 1 \n",
    "\n",
    "if amount_hours == 1:\n",
    "    print('Extracting '+str(int(amount_hours))+' hour')\n",
    "else: \n",
    "    print('Extracting '+str(int(amount_hours))+' hours')\n",
    "\n",
    "df_dict = {}; time_cts =[]; values_cs = [];\n",
    "hours = np.arange(first_hour,first_hour + amount_hours)\n",
    "lead = 'MDC_ECG_ELEC_POTL_II'\n",
    "\n",
    "for h in hours:\n",
    "    if len(str(h)) == 1:\n",
    "        hdfs_path = '_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=0' + str(h)+'/_patient_id=5984929'\n",
    "    else: \n",
    "        hdfs_path = '_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=' + str(h)+'/_patient_id=5984929'\n",
    "\n",
    "    df_cs = _get_df_cs(hdfs_path, lead)\n",
    "    print('Extracted hour: '+str(h))\n",
    "    df_dict['hour '+str(h)] = df_cs\n",
    "    \n",
    "final_df_cs = pd.concat(df_dict)\n",
    "\n",
    "\n",
    "final_df_cs.sort_values(by=['_milli_ts'], inplace=True)\n",
    "final_df_cs.reset_index(drop=True, inplace=True)\n",
    "final_df_cs['shift_milli_ts'] = final_df_cs['_milli_ts'].shift(-1)\n",
    "final_df_cs['diff_milli_ts'] = final_df_cs['shift_milli_ts'] - final_df_cs['_milli_ts']\n",
    "\n",
    "values_cs = np.asarray(final_df_cs['val'].to_numpy())\n",
    "raw_time_cs = np.asarray(final_df_cs['_milli_ts'].to_numpy(), dtype = 'int')\n",
    "time_cs = [np.datetime64(int(t),'ms') for t in raw_time_cs]\n",
    "time_cts = np.concatenate([time_cts, np.array([(pd.Timestamp(t).hour*60*60*1000) + (pd.Timestamp(t).minute*60*1000) + \n",
    "                 (pd.Timestamp(t).second*1000) + (pd.Timestamp(t).microsecond/1000) for t in time_cs])]);\n",
    "\n",
    "\n",
    "missing_info = final_df_cs[final_df_cs['diff_milli_ts']>4]\n",
    "missing_ids = missing_info.index.to_list()\n",
    "\n",
    "if len(missing_ids)>0:\n",
    "    print('')\n",
    "    print('There is missing data in the following indices')\n",
    "for missing_idx in missing_ids: \n",
    "    print('')\n",
    "    print('Time '+str(round((missing_idx*4/1000)/60,2))+', Index '+str(missing_idx)+' is missing '+str(final_df_cs['diff_milli_ts'][missing_idx])+' milliseconds ahead')\n",
    "    zeros = np.zeros(int(final_df_cs['diff_milli_ts'][missing_idx]/4))\n",
    "    missing_time = np.arange(time_cts[missing_idx]+4,time_cts[missing_idx+1],4)\n",
    "    time_cts = np.insert(time_cts,missing_idx+1,missing_time)\n",
    "    values_cs = np.insert(values_cs,missing_idx,zeros)\n",
    "    \n",
    "time_cts = time_cts - time_cts[0]\n",
    "\n",
    "print('Finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0551947f-9752-4262-a7e8-73b8fdb639d6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e22ee5ee-b8d1-494d-96bf-09888f117a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_pks = time_pks - time_cts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c71380b0-934a-495f-8516-cba2ce8850a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class raw_sample_():\n",
    "    \n",
    "    def __init__(self,min_min,min_sec,max_min,max_sec,seconds_per_label):\n",
    "        \n",
    "        self.min_min = min_min\n",
    "        self.min_sec = min_sec\n",
    "        self.max_min = max_min\n",
    "        self.max_sec = max_sec\n",
    "        self.seconds_per_label = seconds_per_label\n",
    "\n",
    "        self.min_time = int((self.min_min*60*1000)/4) + int(self.min_sec*1000/4)\n",
    "        self.max_time = int((self.max_min*60*1000)/4) + int(self.max_sec*1000/4) + 1\n",
    "        self.pks_time_min = (self.min_min*60*1000) + (self.min_sec*1000)\n",
    "        self.pks_time_max = (self.max_min*60*1000) + (self.max_sec*1000)\n",
    "        self.pks_time = time_pks[(self.pks_time_min > time_pks).argmin():(time_pks < self.pks_time_max).argmin()]\n",
    "        self.pks_values = values_p[(self.pks_time_min > time_pks).argmin():(time_pks < self.pks_time_max).argmin()]\n",
    "        \n",
    "        self.time = time_cts[self.min_time:self.max_time]\n",
    "        self.values = df_II_cs['val'].to_numpy()[self.min_time:self.max_time]\n",
    "\n",
    "        self.fig = go.Figure()\n",
    "        self.fig.add_trace(go.Scatter(line= dict(color='blue'),x=self.time, y=self.values,showlegend=False))\n",
    "        self.fig.add_trace(go.Scatter(mode='markers', marker= dict(color='red'),x=self.pks_time, y=self.pks_values,showlegend=False))\n",
    "\n",
    "        self.ticks_values = []\n",
    "        x = self.time[0]\n",
    "        while x < self.time[-1]:\n",
    "            self.ticks_values = np.append(self.ticks_values,x)\n",
    "            x = 1000*self.seconds_per_label + x\n",
    "\n",
    "        self.time_format_axis = time_f(self.ticks_values)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7c788685-be82-487a-812f-85f74f012b85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class sample_():\n",
    "    \n",
    "    def __init__(self,min_min,min_sec,max_min,max_sec,seconds_per_label,find_the_peaks,inverted):\n",
    "        \n",
    "        self.min_min = min_min\n",
    "        self.min_sec = min_sec\n",
    "        self.max_min = max_min\n",
    "        self.max_sec = max_sec\n",
    "        self.seconds_per_label = seconds_per_label\n",
    "\n",
    "        self.min_time = int((self.min_min*60*1000)/4 + int(self.min_sec*1000)/4) \n",
    "        self.max_time = int((self.max_min*60*1000)/4 + int(self.max_sec*1000)/4) + 1\n",
    "\n",
    "        \n",
    "        time_zero = raw_time_cs[0]\n",
    "        self.time = raw_time_cs[self.min_time:self.max_time] - time_zero\n",
    "        if inverted:\n",
    "            self.values = - values_cs[self.min_time:self.max_time]\n",
    "        else: \n",
    "            self.values = values_cs[self.min_time:self.max_time]\n",
    "\n",
    "        self.fig = go.Figure()\n",
    "        self.fig.add_trace(\n",
    "                      go.Scatter(line= dict(color='blue'),x=self.time, y=self.values,showlegend=False))\n",
    "\n",
    "        self.ticks_values = []\n",
    "        x = self.time[0]\n",
    "        while x < self.time[-1]:\n",
    "            self.ticks_values = np.append(self.ticks_values,x)\n",
    "            x = 1000*self.seconds_per_label + x\n",
    "\n",
    "        self.time_format_axis = time_f(self.ticks_values)\n",
    "        \n",
    "        if find_the_peaks:\n",
    "            self.peaks, _ = find_peaks(self.values, distance=100)\n",
    "            self.fig.add_trace(\n",
    "                      go.Scatter(mode='markers',x=self.time[self.peaks], y=self.values[self.peaks],showlegend=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "91fa0b40-1348-477d-88b8-e33a550e5a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample1 = sample_(0,0,20,0,10,False,False)\n",
    "fig = sample1.fig\n",
    "fig.update_layout(xaxis = dict(tickmode = 'array', tickvals = sample1.ticks_values, ticktext = sample1.time_format_axis),autosize=False,width=1250,\n",
    "                  height=600,showlegend=False,title=\"Raw Data \", xaxis_title=\"Time\", yaxis_title= 'Signal', \n",
    "                  font=dict(family=\"Avenir\",size=14,color=\"Black\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b7dad340-f694-4386-92a8-1e5c520f5d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f291d6-6da2-49be-bec9-407803f6a196",
   "metadata": {},
   "source": [
    "# Pre processing, baseline wander removal through moving average subtraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadfdde5-640c-4a88-b740-00baed0be8dc",
   "metadata": {},
   "source": [
    "$$y[n]_{Moving Average} = \\frac{1}{M_2 + 1}(x[n]-x[n-M_2-1]) + y[n-1]$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9ed82be5-58d7-45fd-8795-79f92da621b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block proves that the difference equation has the same result with the convolution, data has been preprocessed \n",
    "# and pan tompkins algorithm can take place now. \n",
    "\n",
    "upper_limit = 10000\n",
    "w = 15\n",
    "mean = average_filter(w,sample1.values)\n",
    "yn, cut_pts = moving_average(w,sample1.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4a79cf4a-c143-4988-9318-450d2fc565aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "# Comparing different window lengths for pre processing stage\n",
    "\n",
    "fig_pre_p = go.Figure()\n",
    "\n",
    "baseline_removal = {}\n",
    "prepro_data = {}\n",
    "cut_pts ={}\n",
    "x = sample1.time\n",
    "for i in range(10,11):    \n",
    "    print(i)\n",
    "    baseline_removal['Window '+str(i)], cut_pts['Window '+str(i)] = moving_average(i,sample1.values)\n",
    "    prepro_data['Window '+str(i)] =  sample1.values[0:len(x)-cut_pts['Window '+str(i)]] - baseline_removal['Window '+str(i)]\n",
    "    fig_pre_p.add_trace(go.Scatter(line= dict(color='#e65400'), x=x[0:len(x)-cut_pts['Window '+str(i)]], y = prepro_data['Window '+str(i)],\n",
    "                                   name = 'Baseline Removal Window '+str(i), showlegend=False, visible = False))\n",
    "    #fig_pre_p.add_trace(go.Scatter(line= dict(color='blue'),    x=sample1.time, y=sample1.values,name='Raw Data',showlegend=False, visible = False))\n",
    "\n",
    "    \n",
    "fig_pre_p.data[0].visible = True\n",
    "\n",
    "\n",
    "steps = []\n",
    "start = 0\n",
    "for t in range(10,11):\n",
    "    step = dict(\n",
    "        method=\"update\",\n",
    "        args=[{\"visible\": [False] * len(fig_pre_p.data)},\n",
    "              {\"title\":  'Baseline Wander Removal      Moving Average Window: '+str(t)}],  # layout attribute\n",
    "    )\n",
    "    \n",
    "    step[\"args\"][0][\"visible\"][start] = True  # Toggle i'th trace to \"visible\"\n",
    "    #step[\"args\"][0][\"visible\"][start+1] = True\n",
    "\n",
    "    \n",
    "    start = start+1\n",
    "    steps.append(step)\n",
    "\n",
    "    \n",
    "sliders = [dict(active=5, currentvalue={\"prefix\": \"n: \"}, pad={\"t\": 50}, steps=steps)]\n",
    "fig_pre_p.update_layout(sliders=sliders);\n",
    "fig_pre_p.update_layout(xaxis = dict(tickmode = 'array', tickvals = sample1.ticks_values, ticktext = sample1.time_format_axis),autosize=False,width=1200,height=600);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7e4828e4-75a6-4eb3-a815-1eaf60fdd786",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig_pre_p.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "02f40133-eef2-41f3-a528-c123c9e37d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparing the Raw data and Pre processed data in subplots\n",
    "\n",
    "i =  10\n",
    "fig3 = make_subplots(\n",
    "    rows=2, cols=1,\n",
    "    subplot_titles=(\"Raw Data\",\" Mean Subtraction Filter \"))\n",
    "\n",
    "fig3.add_trace(go.Scatter(line = dict(color='blue'), x=sample1.time, y=sample1.values,name='Raw Data',showlegend=False),row=1, col=1)\n",
    "fig3.add_trace(go.Scatter(x=x[0:len(x)-cut_pts['Window '+str(i)]], y= prepro_data['Window '+str(i)],\n",
    "                                   name = 'Baseline Removal Window '+str(i), showlegend=False,),row=2, col=1)\n",
    "\n",
    "\n",
    "\n",
    "fig3.update_layout(xaxis_range=[79000,85000], xaxis2_range=[79000,85000],yaxis_range=[-0.6,0.65])\n",
    "fig3.update_layout(xaxis = dict(tickmode = 'array', tickvals = sample1.ticks_values, ticktext = sample1.time_format_axis),autosize=False,width=1200,height=600);\n",
    "fig3.update_layout(xaxis2 = dict(tickmode = 'array', tickvals = sample1.ticks_values, ticktext = sample1.time_format_axis),autosize=False,width=1200,height=600);\n",
    "fig3.update_layout(height=700,width = 1300);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4eb1ef2-3fc2-41d6-8cf5-0a6549ee3f8d",
   "metadata": {},
   "source": [
    "#### A window of 10 is chosen for the mean subtraction, based oon high noise intervals, need too look deeper into this"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da63f0a8-ad47-4cdd-a3e4-5562c446829a",
   "metadata": {},
   "source": [
    "## Pan Tompkins starts here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f82cf286-f3f5-4c4c-982d-22e146ba99ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling Frequency: 250.0Hz\n"
     ]
    }
   ],
   "source": [
    "#time_dif = np.unique(np.diff(sample1.time))/np.timedelta64(1, \"ms\")\n",
    "time_dif = 4/1000\n",
    "sampling_freq = 1/time_dif\n",
    "print('Sampling Frequency: '+str(sampling_freq)+'Hz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ca2b5b2a-00c4-40a9-9f41-78ee3231f6ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nlow = lowcut / nyquist_freq\\nhigh = highcut / nyquist_freq\\nb, a = butter(2, [low, high], btype=\"band\")\\n'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lowcut = 3; highcut = 100;\n",
    "nyquist_freq = 0.5 * sampling_freq\n",
    "\"\"\"\n",
    "low = lowcut / nyquist_freq\n",
    "high = highcut / nyquist_freq\n",
    "b, a = butter(2, [low, high], btype=\"band\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60245f04-5aa0-408b-af4a-c8837b77e2c9",
   "metadata": {},
   "source": [
    "## Bandpass Filter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2169a124-fd08-41d6-b902-d958960b6917",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfr_r = go.Figure()\\nfs = 250\\ntrans_width = 2.88\\nband = [3, 18]  # Desired pass band, Hz\\nfilter_size= np.arange(100,200,1)\\nedges = [0, band[0] - trans_width, band[0], band[1],\\n         band[1] + trans_width, 0.5*fs]\\ntrans_width = 2.8    # Width of transition from pass to stop, Hz\\ntaps = {}\\n\\nfor i in range(0,len(filter_size)):\\n\\n    numtaps=filter_size[i]      # Size of the FIR filter.\\n\\n    taps[\\'size: \\'+str(filter_size[i])] = signal.remez(numtaps, edges, [0, 1, 0], fs=fs)\\n    w, h = signal.freqz(taps[\\'size: \\'+str(filter_size[i])], [1], worN=2000, fs=fs)\\n    fr_r.add_trace(go.Scatter(x=w,y=20*np.log10(np.abs(h))))\\n    \\nfr_r.data[5].visible = True\\n\\nsteps = []\\nfor tw in range(0,len(filter_size)):\\n    step = dict(\\n        method=\"update\",\\n        args=[{\"visible\": [False] * len(fr_r.data)},\\n              {\"title\": \\'Size of Filter: \\'+ str(filter_size[tw])}],  # layout attribute\\n    )\\n    step[\"args\"][0][\"visible\"][tw] = True  # Toggle i\\'th trace to \"visible\"\\n    steps.append(step)\\n    \\nsliders = [dict(active=5, currentvalue={\"prefix\": \"n: \"}, pad={\"t\": 50}, steps=steps)]\\nfr_r.update_layout(sliders=sliders);\\n\\n\\nfr_r.update_layout(\\n    xaxis = dict(tickmode = \\'array\\',tickvals = [np.log10(1),np.log10(2),np.log10(3),np.log10(4),np.log10(5),np.log10(6),np.log10(7),np.log10(8),np.log10(9),\\n                    np.log10(10),np.log10(15),np.log10(20)],\\n        ticktext = [\\'1\\', \\'2\\', \\'3\\', \\'4\\', \\'5\\', \\'6\\',\\'7\\',\\'8\\',\\'9\\',\\'10\\',\\'15\\',\\'20\\']))\\n\\nfr_r.update_layout(autosize=False,width=1200, height=600, xaxis_title=\"w\", yaxis_title= \\'20log( |H(s)| ) (dB)\\' ,\\n                      font=dict(family=\"Avenir\",size=16,color=\"Black\"))\\n\\nfr_r.update_layout(xaxis_range=[0,150], yaxis_range=[-50,10]);\\n\\n'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "fr_r = go.Figure()\n",
    "fs = 250\n",
    "trans_width = 2.88\n",
    "band = [3, 18]  # Desired pass band, Hz\n",
    "filter_size= np.arange(100,200,1)\n",
    "edges = [0, band[0] - trans_width, band[0], band[1],\n",
    "         band[1] + trans_width, 0.5*fs]\n",
    "trans_width = 2.8    # Width of transition from pass to stop, Hz\n",
    "taps = {}\n",
    "\n",
    "for i in range(0,len(filter_size)):\n",
    "\n",
    "    numtaps=filter_size[i]      # Size of the FIR filter.\n",
    "\n",
    "    taps['size: '+str(filter_size[i])] = signal.remez(numtaps, edges, [0, 1, 0], fs=fs)\n",
    "    w, h = signal.freqz(taps['size: '+str(filter_size[i])], [1], worN=2000, fs=fs)\n",
    "    fr_r.add_trace(go.Scatter(x=w,y=20*np.log10(np.abs(h))))\n",
    "    \n",
    "fr_r.data[5].visible = True\n",
    "\n",
    "steps = []\n",
    "for tw in range(0,len(filter_size)):\n",
    "    step = dict(\n",
    "        method=\"update\",\n",
    "        args=[{\"visible\": [False] * len(fr_r.data)},\n",
    "              {\"title\": 'Size of Filter: '+ str(filter_size[tw])}],  # layout attribute\n",
    "    )\n",
    "    step[\"args\"][0][\"visible\"][tw] = True  # Toggle i'th trace to \"visible\"\n",
    "    steps.append(step)\n",
    "    \n",
    "sliders = [dict(active=5, currentvalue={\"prefix\": \"n: \"}, pad={\"t\": 50}, steps=steps)]\n",
    "fr_r.update_layout(sliders=sliders);\n",
    "\n",
    "\n",
    "fr_r.update_layout(\n",
    "    xaxis = dict(tickmode = 'array',tickvals = [np.log10(1),np.log10(2),np.log10(3),np.log10(4),np.log10(5),np.log10(6),np.log10(7),np.log10(8),np.log10(9),\n",
    "                    np.log10(10),np.log10(15),np.log10(20)],\n",
    "        ticktext = ['1', '2', '3', '4', '5', '6','7','8','9','10','15','20']))\n",
    "\n",
    "fr_r.update_layout(autosize=False,width=1200, height=600, xaxis_title=\"w\", yaxis_title= '20log( |H(s)| ) (dB)' ,\n",
    "                      font=dict(family=\"Avenir\",size=16,color=\"Black\"))\n",
    "\n",
    "fr_r.update_layout(xaxis_range=[0,150], yaxis_range=[-50,10]);\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "88514b7d-4852-46bb-bf3e-739f8aa34014",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig_bp = go.Figure()\n",
    "i = 10\n",
    "bandstop = np.arange(3,4)\n",
    "fs = 250\n",
    "trans_width = 2.88\n",
    "taps = {}\n",
    "numtaps = 152\n",
    "\n",
    "for bs in bandstop:\n",
    "    band = [bs, 100]\n",
    "    edges = [0, band[0] - trans_width, band[0], band[1],\n",
    "             band[1] + trans_width, 0.5*fs]\n",
    "    \n",
    "    taps['Bandstart: '+str(bs)] = signal.remez(numtaps, edges, [0, 1, 0], fs=fs)\n",
    "    \n",
    "    \n",
    "    x = np.append(prepro_data['Window '+str(i)],np.zeros(len(taps['Bandstart: '+str(bs)])))\n",
    "    y_bp = np.zeros(len(prepro_data['Window '+str(i)])+len(taps['Bandstart: '+str(bs)]))\n",
    "\n",
    "    for j in range(0,len(prepro_data['Window '+str(i)])+len(taps['Bandstart: '+str(bs)])): \n",
    "        sum = 0\n",
    "        for k in range(0,len(taps['Bandstart: '+str(bs)])):\n",
    "            sum = (x[j-k]*taps['Bandstart: '+str(bs)][k]) + sum\n",
    "        y_bp[j] = sum\n",
    "\n",
    "    y_bp=np.delete(y_bp,[np.arange(0,int(len(taps['Bandstart: '+str(bs)])/2))])\n",
    "    fig_bp.add_trace(go.Scatter(x=sample1.time, y=y_bp,visible=False))\n",
    "\n",
    "fig_bp.data[0].visible = True\n",
    "\n",
    "steps = []\n",
    "for bps in range(0,len(bandstop)):\n",
    "    step = dict(\n",
    "        method=\"update\",\n",
    "        args=[{\"visible\": [False] * len(fig_bp.data)},\n",
    "              {\"title\": ' Mean Removal Windoow: '+str(i)+'      Bandstart: '+ str(bandstop[bps])}],  # layout attribute\n",
    "    )\n",
    "    step[\"args\"][0][\"visible\"][bps] = True  # Toggle i'th trace to \"visible\"\n",
    "    steps.append(step)\n",
    "    \n",
    "sliders = [dict(active=5, currentvalue={\"prefix\": \"n: \"}, pad={\"t\": 50}, steps=steps)]\n",
    "\n",
    "fig_bp.update_layout(sliders=sliders);\n",
    "fig_bp.update_layout(xaxis = dict(tickmode = 'array', tickvals = sample1.ticks_values, ticktext = sample1.time_format_axis)); \n",
    "fig_bp.update_layout(autosize=False,width=1200, height=600, xaxis_title=\"Time\", yaxis_title= 'Signal' ,\n",
    "                      font=dict(family=\"Avenir\",size=16,color=\"Black\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9b2e7aaa-9d41-43ba-97a9-6ad8ccaa577c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig_bp.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4654610c-2847-4e08-a9f9-abfe0f440d3b",
   "metadata": {},
   "source": [
    "#### Chosen FIR Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a892dc7f-335f-4d63-b9b9-66d6c998b687",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 10\n",
    "x = np.append(prepro_data['Window '+str(i)],np.zeros(len(taps['Bandstart: 3'])))\n",
    "y_bp = np.zeros(len(prepro_data['Window '+str(i)])+len(taps['Bandstart: 3']))\n",
    "\n",
    "for j in range(0,len(prepro_data['Window '+str(i)])+len(taps['Bandstart: 3'])): \n",
    "    sum = 0\n",
    "    for k in range(0,len(taps['Bandstart: 3'])):\n",
    "        sum = (x[j-k]*taps['Bandstart: 3'][k]) + sum\n",
    "    y_bp[j] = sum\n",
    "    \n",
    "y_bp=np.delete(y_bp,[np.arange(0,int(len(taps['Bandstart: 3'])/2))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9d2c14fe-b03b-4dcb-a4ed-e80289a73b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparing the Mean Subtraction and Bandpass in subplots\n",
    "\n",
    "i = 10\n",
    "fig3 = make_subplots(\n",
    "    rows=2, cols=1,\n",
    "    subplot_titles=(\" Mean Subtraction Filter \",\" Bandpass \"))\n",
    "\n",
    "fig3.add_trace(go.Scatter(line=dict(color = 'red'),x=sample1.time, y = y_bp,name='Raw Data',showlegend=False),row=2, col=1)\n",
    "fig3.add_trace(go.Scatter(x=x[0:len(x)-cut_pts['Window '+str(i)]], y= prepro_data['Window '+str(i)],\n",
    "                                   name = 'Baseline Removal Window '+str(i), showlegend=False,),row=1, col=1)\n",
    "\n",
    "\n",
    "\n",
    "fig3.update_layout(xaxis_range=[79000,85000], xaxis2_range=[79000,85000])\n",
    "fig3.update_layout(xaxis = dict(tickmode = 'array', tickvals = sample1.ticks_values, ticktext = sample1.time_format_axis),autosize=False,width=1200,height=600);\n",
    "fig3.update_layout(xaxis2 = dict(tickmode = 'array', tickvals = sample1.ticks_values, ticktext = sample1.time_format_axis),autosize=False,width=1200,height=600)\n",
    "fig3.update_layout(height=700,width = 1300);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "89baf68e-b882-49b9-9bda-182a69d1b3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4829e49d-fba3-4ca8-b8c5-c7307578ed4c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nx0 =np.append(prepro_data['Window '+str(6)],np.zeros(len(b)))\\ndif_y = np.zeros(len(x0))\\n\\nfor i in range(0,len(prepro_data['Window 15'])):\\n    dif_y[i] = (1/a[0]) * (b[0]*x[i] + b[1]*x[i-1] + b[2]*x[i-2] + b[3]*x[i-3] + b[4]*x[i-4] - \\n                       (a[1]*dif_y[i-1] + a[2]*dif_y[i-2] + a[3]*dif_y[i-3] + a[4]*dif_y[i-4]))\\n    \\n\\ndif_y = np.delete(dif_y,np.arange(len(dif_y)-len(b),len(dif_y),1))\\n\""
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Transfer Function for IIR\n",
    "\"\"\"\n",
    "x0 =np.append(prepro_data['Window '+str(6)],np.zeros(len(b)))\n",
    "dif_y = np.zeros(len(x0))\n",
    "\n",
    "for i in range(0,len(prepro_data['Window 15'])):\n",
    "    dif_y[i] = (1/a[0]) * (b[0]*x[i] + b[1]*x[i-1] + b[2]*x[i-2] + b[3]*x[i-3] + b[4]*x[i-4] - \n",
    "                       (a[1]*dif_y[i-1] + a[2]*dif_y[i-2] + a[3]*dif_y[i-3] + a[4]*dif_y[i-4]))\n",
    "    \n",
    "\n",
    "dif_y = np.delete(dif_y,np.arange(len(dif_y)-len(b),len(dif_y),1))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cceb4c-c8a7-46b5-af08-7d1ee9856fc1",
   "metadata": {},
   "source": [
    "### AN FIR FILTER WAS MADE WITH NUMBER OF TAPS 152"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189b6129-cde0-47bc-87ab-86835bfb4d33",
   "metadata": {},
   "source": [
    "#### FROM NOW ON THE DATA HAS BEEN FILTERED WITH AN FIR BANDPASS AND CAN CONTINUE WITH THE REST OF THE STEPS IN PAN TOMPKINS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4e4a6e73-b82e-4d4c-8d06-0fea62361fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = str(10)\n",
    "fig2 = go.Figure()\n",
    "fig2.add_trace(go.Scatter(line= dict(color='blue', width =2),x=sample1.time, y = sample1.values,name='Raw Data',showlegend=True))\n",
    "fig2.add_trace(go.Scatter(line= dict(width = 2),x=sample1.time, y = prepro_data['Window '+i],name='Preprocessed Data',showlegend=True))\n",
    "fig2.add_trace(go.Scatter(line= dict(width = 2),x=sample1.time, y = y_bp,name='FIR Filter',showlegend=True))\n",
    "fig2.update_layout(xaxis_range=[79000,85000],xaxis = dict(tickmode = 'array', tickvals = sample1.ticks_values, ticktext = sample1.time_format_axis), \n",
    "                    autosize=False,width=1200, height=600, title='Band Pass Filtered and Raw Data', \n",
    "                    xaxis_title=\"Time\", yaxis_title= 'Signal');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c5593a45-b306-45fa-af3f-4913ad9d7318",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#fig2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da39ba1b-262d-4b95-a062-d89787f15a62",
   "metadata": {},
   "source": [
    "### Difference Equation for derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e375c05-a109-4733-b7b4-0d3c5bb79581",
   "metadata": {},
   "source": [
    "#### y[n] = (1/8T) (-x[n-2] - 2x[n-1] + 2x[n+1] + x[n+2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "69b8ea8c-66dd-4849-b1fa-b86f1defafd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Difference Equation\n",
    "\n",
    "der1 = np.zeros(len(y_bp))\n",
    "\n",
    "x = np.append(y_bp,np.zeros(2))\n",
    "\n",
    "for i in range(0,len(y_bp)):\n",
    "    der1[i] = (1/8) * (-(x[i-2]) - (2*x[i-1]) + (2*x[i+1]) + (x[i+2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4cba611b-928a-4e00-b0e9-78757c6bf519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bandpass and Derivative\n",
    "\n",
    "fig3 = make_subplots(\n",
    "    rows=2, cols=1,\n",
    "    subplot_titles=(\"Bandpass Filter\",'Derivative Filter '))\n",
    "\n",
    "#fig3.add_trace(go.Scatter(line= dict(color='green'),x=sample1.time, y = der1,name='Derivative Filter',showlegend=False),row=1, col=1)\n",
    "\n",
    "fig3.add_trace(go.Scatter(line= dict(color='red'),x=sample1.time, y = y_bp,name='Bandpass',showlegend=False),row=1, col=1)\n",
    "fig3.add_trace(go.Scatter(line= dict(color='Green'),x=sample1.time, y = der1,name='Derivative',showlegend=False),row=2, col=1)\n",
    "#fig3.add_trace(go.Scatter(line= dict(color='Blue'),x=sample1.time, y = der2,name='Derivative',showlegend=False),row=3, col=1)\n",
    "\n",
    "fig3.update_layout(xaxis = dict(tickmode = 'array', tickvals = sample1.ticks_values, ticktext = sample1.time_format_axis),\n",
    "                    xaxis2 = dict(tickmode = 'array', tickvals = sample1.ticks_values, ticktext = sample1.time_format_axis),\n",
    "                    xaxis3 = dict(tickmode = 'array', tickvals = sample1.ticks_values, ticktext = sample1.time_format_axis))\n",
    "\n",
    "#fig3.update_layout(xaxis_range=[0,1000], xaxis2_range=[0,85000])\n",
    "fig3.update_layout(height=750,width = 1300);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9378589-8880-4672-8ec2-40645fa5fab4",
   "metadata": {},
   "source": [
    "### Squaring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7f990f90-61bd-49b4-b700-a63a0d4643f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "squared = (der1) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f658de98-090a-4602-93be-8c0520421574",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Derivative and Squared\n",
    "\n",
    "\n",
    "fig4 = make_subplots(\n",
    "    rows=2, cols=1,\n",
    "    subplot_titles=(\"Derivative Filter     Average Window: 6      Bandstart: 22\",\" Squared        Average Window: 6         Bandstart: 22 \"))\n",
    "\n",
    "#fig4.add_trace(go.Scatter(line= dict(color='orange'),x=sample1.time, y = squared,name='Squared',showlegend=False),row=1, col=1)\n",
    "\n",
    "fig4.add_trace(go.Scatter(line= dict(color='green'),x=sample1.time, y = der1,name='Derivative',showlegend=False),row=1, col=1)\n",
    "fig4.add_trace(go.Scatter(line= dict(color='orange'),x=sample1.time, y = squared,name='Squared',showlegend=False),row=2, col=1)\n",
    "\n",
    "fig4.update_layout(xaxis = dict(tickmode = 'array', tickvals = sample1.ticks_values, ticktext = sample1.time_format_axis),\n",
    "                    xaxis2 = dict(tickmode = 'array', tickvals = sample1.ticks_values, ticktext = sample1.time_format_axis))\n",
    "\n",
    "fig4.update_layout(xaxis_range=[79000,85000], xaxis2_range=[79000,85000], yaxis2_range=[-0.001,0.016])\n",
    "fig4.update_layout(height=700,width = 1300);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba78441-b29d-4852-a461-de575cfcc0b9",
   "metadata": {},
   "source": [
    "## Moving Integration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75671d1b-d6ff-49f7-8bcf-edfcf89b4a32",
   "metadata": {},
   "source": [
    "#### The moving window integration difference equation is given by \n",
    "#### $$y[n] = (x[n-(N-1)] + x[n-(N-2)] + .... + x[n])$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1073446-5365-4ef2-b9e2-b4eb8771d64d",
   "metadata": {},
   "source": [
    "##### The following is the moving integration difference equation implemented through a loop just to test and compare later on with a constructed function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6048bb14-71ac-4df2-8603-f2d35b19de88",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ma = np.zeros(len(squared))\n",
    "y_mi = np.zeros(len(squared))\n",
    "\n",
    "# N = window_length\n",
    "N = 11\n",
    "squared_y = np.append(squared,np.zeros(N-1))\n",
    "for n in range(0,len(y_ma)):\n",
    "    y_ma[n] = (1/N) * (squared_y[n-(N-1)] + squared_y[n-(N-2)] + squared_y[n-(N-3)] + squared_y[n-(N-4)] + squared_y[n-(N-5)] + squared_y[n-(N-6)] + \n",
    "                       squared_y[n-(N-7)] + squared_y[n-(N-8)] + squared_y[n-(N-9)] + squared_y[n-(N-10)] + squared_y[n])\n",
    "    y_mi[n] = (squared_y[n-(N-1)] + squared_y[n-(N-2)] + squared_y[n-(N-3)] + squared_y[n-(N-4)] + squared_y[n-(N-5)] + squared_y[n-(N-6)] + \n",
    "                       squared_y[n-(N-7)] + squared_y[n-(N-8)] + squared_y[n-(N-9)] + squared_y[n-(N-10)] + squared_y[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2acb71e9-82f4-4a92-b27b-ea8e1881ef7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The constructed function\n",
    "prueba = dif_eq_window_integration(squared,11,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4d573c8d-3a31-41eb-b199-ea9f411916d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This just doublechecks that the function works\n",
    "\n",
    "fig5 = go.Figure()\n",
    "\n",
    "fig5.add_trace(go.Scatter(mode = 'lines', line= dict(color='green'),x=sample1.time, y=squared,name='Squared',showlegend=True))\n",
    "fig5.add_trace(go.Scatter(mode = 'lines', line= dict(color='blue',width = 4),x=sample1.time, y=y_ma,name='Moving Window Average',showlegend=True))\n",
    "fig5.add_trace(go.Scatter(mode = 'lines', line= dict(color='red',width = 4),x=sample1.time, y=prueba, name='Prueba',showlegend=True))\n",
    "fig5.add_trace(go.Scatter(mode = 'lines', x=sample1.time, y=y_mi,name='Moving Window Integration',showlegend=True))\n",
    "\n",
    "\n",
    "fig5.update_layout(xaxis_range=[79000,85000],xaxis = dict(tickmode = 'array', tickvals = sample1.ticks_values, ticktext = sample1.time_format_axis), \n",
    "                    autosize=False,width=1250, height=600, title=\"Squared and Moving Window Integration WL: \" + str(N), \n",
    "                    xaxis_title=\"Time\", yaxis_title= 'Signal', font=dict(family=\"Avenir\",size=14,color=\"Black\"));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d83e46-0034-4510-85df-8fa0f3f05a44",
   "metadata": {},
   "source": [
    "## Looking to different window lengths in the window integration difference equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "778d6910-5480-4c9e-8e5d-2aa6bbf6999d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving Window Integration\n",
    "\n",
    "fig6 = go.Figure()\n",
    "\n",
    "y_mw_dict ={}\n",
    "lengths = np.arange(10,35,1)\n",
    "peaks_trial = {}\n",
    "\n",
    "for N in lengths: \n",
    "    y_mw_dict['MW Integration W: '+str(N)] = dif_eq_window_integration(squared,N,False)\n",
    "    #peaks_trial['MWI W peaks: '+str(N)], _ = find_peaks(y_mw_dict['MW Integration W: '+str(N)],distance = 100)\n",
    "    fig6.add_trace(go.Scatter(mode = 'lines', line= dict(color='blue'),x=sample1.time, y=y_mw_dict['MW Integration W: '+str(N)],\n",
    "                               name = 'Differece Equation',showlegend=False, visible =False))\n",
    "    \n",
    "fig6.data[5].visible = True\n",
    "\n",
    "steps = []\n",
    "start = 0\n",
    "for i in range(0,len(lengths)):\n",
    "    step = dict(\n",
    "        method=\"update\",\n",
    "        args=[{\"visible\": [False] * len(fig6.data)},\n",
    "              {\"title\": 'Moving Window Integration           Window Length: ' + str(lengths[i])}],  # layout attribute\n",
    "    )\n",
    "    step[\"args\"][0][\"visible\"][i] = True # Toggle i'th trace to \"visible\"\n",
    "    #step[\"args\"][0][\"visible\"][start + 1] = True # Toggle i'th trace to \"visible\"\n",
    "    #start = start +2\n",
    "\n",
    "    steps.append(step)\n",
    "    \n",
    "sliders = [dict(active=5, currentvalue={\"prefix\": \"n: \"}, pad={\"t\": 50}, steps=steps)]\n",
    "fig6.update_layout(sliders=sliders);\n",
    "fig6.update_layout(xaxis_range=[79000,85000]);\n",
    "fig6.update_layout(xaxis = dict(tickmode = 'array', tickvals = sample1.ticks_values, ticktext = sample1.time_format_axis),autosize=False,width=1200,height=600); \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "adc38639-72ab-423d-aa36-9d04d4f7c315",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig6.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2962e092-dcd0-404d-8190-8fe7a782c118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving Window Integration and Squared THIS IS BASICALLY THE SAME AS THE ABOVE BUT WITH THE SQUARED\n",
    "\n",
    "fig7 = go.Figure()\n",
    "\n",
    "y_mw_dict ={};\n",
    "\n",
    "\n",
    "for N in lengths: \n",
    "    y_mw_dict['MW Integration W: '+str(N)] = dif_eq_window_integration(squared,N,False)\n",
    "    fig7.add_trace(go.Scatter(mode = 'lines', line= dict(color='orange'),x=sample1.time, y=squared,\n",
    "                               name = 'Squared',showlegend=True,visible=False))\n",
    "    fig7.add_trace(go.Scatter(mode = 'lines', line= dict(color='blue',width=3),x=sample1.time, y=y_mw_dict['MW Integration W: '+str(N)],\n",
    "                               name = 'Differece Equation',showlegend=True,visible=False))\n",
    "    \n",
    "fig7.data[5].visible = True\n",
    "\n",
    "steps = []\n",
    "start = 0\n",
    "for i in range(0,len(lengths)):\n",
    "    step = dict(\n",
    "        method=\"update\",\n",
    "        args=[{\"visible\": [False] * len(fig7.data)},\n",
    "              {\"title\": 'Moving Window Integration           Window Length: ' + str(lengths[i])}],  # layout attribute\n",
    "    )\n",
    "    step[\"args\"][0][\"visible\"][start] = True # Toggle i'th trace to \"visible\"\n",
    "    step[\"args\"][0][\"visible\"][start+1] = True # Toggle i'th trace to \"visible\"\n",
    "    start = start + 2\n",
    "    steps.append(step)\n",
    "    \n",
    "sliders = [dict(active=5, currentvalue={\"prefix\": \"n: \"}, pad={\"t\": 50}, steps=steps)]\n",
    "fig7.update_layout(sliders=sliders);\n",
    "fig7.update_layout(xaxis_range=[79000,85000],yaxis_range = [0,0.014]);\n",
    "fig7.update_layout(xaxis = dict(tickmode = 'array', tickvals = sample1.ticks_values, ticktext = sample1.time_format_axis),autosize=False,width=1250,height=650); \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c23b1f2b-dd40-4da3-87b7-bbae548334dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig7.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4ad0476c-7783-4693-8805-1b6825c76be1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Squared and Moving Window Integration\n",
    "\n",
    "fig4 = make_subplots(\n",
    "    rows=2, cols=1,\n",
    "    subplot_titles=(\"Squared\",\" Moving Window Integration \"))\n",
    "\n",
    "#fig4.add_trace(go.Scatter(line= dict(color='orange'),x=sample1.time, y = squared,name='Squared',showlegend=False),row=1, col=1)\n",
    "\n",
    "fig4.add_trace(go.Scatter(line= dict(color='#0a4345'),x=sample1.time, y = y_mw_dict['MW Integration W: 25'],name='MWI',showlegend=False),row=2, col=1)\n",
    "fig4.add_trace(go.Scatter(line= dict(color='orange'),x=sample1.time, y = squared,name='Squared',showlegend=False),row=1, col=1)\n",
    "\n",
    "fig4.update_layout(xaxis = dict(tickmode = 'array', tickvals = sample1.ticks_values, ticktext = sample1.time_format_axis),\n",
    "                    xaxis2 = dict(tickmode = 'array', tickvals = sample1.ticks_values, ticktext = sample1.time_format_axis))\n",
    "\n",
    "fig4.update_layout(xaxis_range=[79000,85000], xaxis2_range=[79000,85000], yaxis_range=[-0.001,0.0155], yaxis2_range=[-0.001,0.085])\n",
    "fig4.update_layout(height=800,width = 1300);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3d02d8d9-d206-46db-b059-1dad303539e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving Window Integration and its peaks\n",
    "\n",
    "fig8 = go.Figure()\n",
    "fiducial_point_dict = {}\n",
    "\n",
    "for N in lengths: \n",
    "    fig8.add_trace(go.Scatter(mode = 'lines', line= dict(color='blue'),x=sample1.time, y=y_mw_dict['MW Integration W: '+str(N)],\n",
    "                               name = 'MWI length: '+str(N),showlegend=False,visible=False))\n",
    "    \n",
    "    fiducial_point_dict['Window Length: '+str(N)] = find_fiducial_point(y_mw_dict['MW Integration W: '+str(N)],sample1.time,3,0.8,N)\n",
    "\n",
    "    fig8.add_trace(go.Scatter(mode = 'markers', marker= dict(size = 10, color='red'),x=sample1.time[fps],\n",
    "                              y=y_mw_dict['MW Integration W: '+str(N)][fps],\n",
    "                               name = 'Peaks_function',showlegend=False,visible=False))\n",
    "    \n",
    "fig8.data[5].visible = True\n",
    "\n",
    "steps = []\n",
    "start = 0\n",
    "for length in lengths:\n",
    "    step = dict(\n",
    "        method=\"update\",\n",
    "        args=[{\"visible\": [False] * len(fig8.data)},\n",
    "              {\"title\": 'Moving Window Integration           Window Length: ' + str(length) + '         Peaks Found: '+str(len(fiducial_point_dict['Window Length: '+str(length)]))}],  # layout attribute\n",
    "    )\n",
    "    step[\"args\"][0][\"visible\"][start] = True # Toggle i'th trace to \"visible\"\n",
    "    step[\"args\"][0][\"visible\"][start+1] = True # Toggle i'th trace to \"visible\"\n",
    "\n",
    "    start = start + 2\n",
    "    steps.append(step)\n",
    "    \n",
    "sliders = [dict(active=5, currentvalue={\"prefix\": \"n: \"}, pad={\"t\": 50}, steps=steps)]\n",
    "fig8.update_layout(sliders=sliders);\n",
    "fig8.update_layout(xaxis_range=[79000,85000]);\n",
    "fig8.update_layout(xaxis = dict(tickmode = 'array', tickvals = sample1.ticks_values, ticktext = sample1.time_format_axis),autosize=False,width=1200,height=600); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5685eb3f-05a1-4e51-bae6-18bea820180c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig8.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a9ae9f18-d640-4d0c-bdaa-248e56a9b5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The algorithm needs to store maybe 5 peaks to learn whats a good height to be consider a peak in the moving window integration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "edd1fef0-c041-45be-b242-c4752464b2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A very simple strategy is to allow for 3 segments of one second or maybe 0.7 seconds to go by and get the maximum value of each segment in \n",
    "# that way we have a sample of what a maximum looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a10d0c09-7d6b-476f-ad6e-7b2dc110bb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving Window Integration and Raw Peaks\n",
    "spline = 4\n",
    "res = 1000\n",
    "max_x, max_y, peaks_x, peaks_y, interpolated_peak_x, interpolated_peak_y,max_ids = interpolation_spline(fiducial_point_dict['Window Length: 25'], \n",
    "                                                                                               sample1.time, sample1.values, spline, res)\n",
    "i = 10\n",
    "fig4 = make_subplots(\n",
    "    rows=3, cols=1,\n",
    "    subplot_titles=(\"Moving Window Integration\",\" Raw Peaks \", 'Mean Subtraction'))\n",
    "\n",
    "#fig4.add_trace(go.Scatter(line= dict(color='orange'),x=sample1.time, y = squared,name='Squared',showlegend=False),row=1, col=1)\n",
    "\n",
    "fig4.add_trace(go.Scatter(line= dict(color='#0a4345'),x=sample1.time, y = y_mw_dict['MW Integration W: 25'],name='MWI',showlegend=False),row=1, col=1)\n",
    "fig4.add_trace(go.Scatter(mode = 'markers',x=sample1.time[fiducial_point_dict['Window Length: 25']], \n",
    "                          y = y_mw_dict['MW Integration W: 25'][fiducial_point_dict['Window Length: 25']],\n",
    "                          name='MWI',showlegend=False),row=1, col=1)\n",
    "fig4.add_trace(go.Scatter(x=x[0:len(x)-cut_pts['Window '+str(i)]], y= prepro_data['Window '+str(i)],\n",
    "                                   name = 'Baseline Removal Window '+str(i), showlegend=False,),row=3, col=1)\n",
    "\n",
    "\n",
    "fig4.add_trace(go.Scatter(line= dict(color='blue'),x=sample1.time, y = sample1.values,name='Peaks in MWI',showlegend=False),row=2, col=1)\n",
    "fig4.add_trace(go.Scatter(mode='markers',marker=dict(color='red'), x=peaks_x, y = peaks_y, name='Peaks In Raw Data',showlegend=False),row=2, col=1)\n",
    "\n",
    "fig4.update_layout(xaxis = dict(tickmode = 'array', tickvals = sample1.ticks_values, ticktext = sample1.time_format_axis),\n",
    "                    xaxis2 = dict(tickmode = 'array', tickvals = sample1.ticks_values, ticktext = sample1.time_format_axis),\n",
    "                    xaxis3 = dict(tickmode = 'array', tickvals = sample1.ticks_values, ticktext = sample1.time_format_axis))\n",
    "\n",
    "fig4.update_layout(xaxis_range=[79000,85000], xaxis2_range=[79000,85000],xaxis3_range=[79000,85000], yaxis_range=[-0.001,0.085], yaxis2_range=[-0.5,0.68])\n",
    "fig4.update_layout(height=1200,width = 1300);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5db523-74b3-4c74-aa62-51e016d8cc78",
   "metadata": {},
   "source": [
    "# Analytical Solution for peaks in interpolation method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a2d27091-ce5a-4bb3-be10-72a54123e13f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nf = go.Figure()\\n\\nf.add_trace(go.Scatter(line = dict(color = \\'blue\\'), x=sample1.time,y=sample1.values, name=\\'Raw Data\\'))\\nf.add_trace(go.Scatter(mode=\\'markers\\',marker=dict(color = \\'#26E31A\\', size = 8), x = max_x,y=max_y,name=\\'Analytical Solution\\'))\\nf.add_trace(go.Scatter(mode=\\'markers\\',marker=dict(color = \\'green\\' ,size = 6), x = peaks_x, y=peaks_y, name=\\' Collected Peak Interpolation \\'+str(res)+\\'Hz\\'))\\n\\nfor h in range(0,len(max_x)):\\n    f.add_trace(go.Scatter(mode=\\'lines\\',line=dict(color=\\'#FE4384\\'), x = interpolated_peak_x[\\'peak: \\'+str(h)], \\n                               y = interpolated_peak_y[\\'peak: \\'+str(h)], showlegend= False))\\n\\n\\nf.update_layout(xaxis = dict(tickmode = \\'array\\', tickvals = sample1.ticks_values, ticktext = sample1.time_format_axis),autosize=False,\\n                     width=1250,height=600)\\n\\nf.update_layout(title=\"Pan Tompkins Interpolated Peaks       Moving Average Window = 14 samples     Analytical Solution \", \\n                         xaxis_title=\"Time\", yaxis_title= \\'Signal\\', font=dict(family=\"Avenir\",size=16,color=\"Black\"));\\n                         '"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "f = go.Figure()\n",
    "\n",
    "f.add_trace(go.Scatter(line = dict(color = 'blue'), x=sample1.time,y=sample1.values, name='Raw Data'))\n",
    "f.add_trace(go.Scatter(mode='markers',marker=dict(color = '#26E31A', size = 8), x = max_x,y=max_y,name='Analytical Solution'))\n",
    "f.add_trace(go.Scatter(mode='markers',marker=dict(color = 'green' ,size = 6), x = peaks_x, y=peaks_y, name=' Collected Peak Interpolation '+str(res)+'Hz'))\n",
    "\n",
    "for h in range(0,len(max_x)):\n",
    "    f.add_trace(go.Scatter(mode='lines',line=dict(color='#FE4384'), x = interpolated_peak_x['peak: '+str(h)], \n",
    "                               y = interpolated_peak_y['peak: '+str(h)], showlegend= False))\n",
    "\n",
    "\n",
    "f.update_layout(xaxis = dict(tickmode = 'array', tickvals = sample1.ticks_values, ticktext = sample1.time_format_axis),autosize=False,\n",
    "                     width=1250,height=600)\n",
    "\n",
    "f.update_layout(title=\"Pan Tompkins Interpolated Peaks       Moving Average Window = 14 samples     Analytical Solution \", \n",
    "                         xaxis_title=\"Time\", yaxis_title= 'Signal', font=dict(family=\"Avenir\",size=16,color=\"Black\"));\n",
    "                         \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "41509f73-a478-4909-bfa2-d129fac2000b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#f.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e0e8e1dd-7eef-4198-b53c-7c791c623988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw Peaks and Third Order Spline Peaks \n",
    "max_x, max_y, peaks_x, peaks_y, interpolated_peak_x, interpolated_peak_y, max_idxs = interpolation_spline(fiducial_point_dict['Window Length: 25'], \n",
    "                                                                                               sample1.time, sample1.values, spline, res)\n",
    "\n",
    "#fig4 = make_subplots(\n",
    "#    rows=2, cols=1,\n",
    "#    subplot_titles=(\"Raw Peaks\",\" Analytical Solution \"))\n",
    "\n",
    "fig4 = go.Figure()\n",
    "\n",
    "#fig4.add_trace(go.Scatter(line= dict(color='orange'),x=sample1.time, y = squared,name='Squared',showlegend=False),row=1, col=1)\n",
    "#fig4.add_trace(go.Scatter(line= dict(color='blue'), x=sample1.time, y = sample1.values,name='Peaks in Raw Data',showlegend=False),row=2, col=1)\n",
    "#fig4.add_trace(go.Scatter(mode='markers',marker=dict(color='red', size=9), x= sample1.time[max_idxs], y = sample1.values[max_idxs], name='Peaks In Raw Data',showlegend=False),row=2, col=1)\n",
    "\n",
    "fig4.add_trace(go.Scatter(line= dict(color='blue'), x=sample1.time, y = sample1.values,name='Peaks in MWI',showlegend=False))\n",
    "\n",
    "\n",
    "for j in range(0,len(interpolated_peak_x)):\n",
    "    fig4.add_trace(go.Scatter(line= dict(color='green'), x=interpolated_peak_x['peak: '+str(j)], y = interpolated_peak_y['peak: '+str(j)], name='Peaks in MWI',showlegend=False))\n",
    "\n",
    "    \n",
    "fig4.add_trace(go.Scatter(mode='markers',marker=dict(color='red', size=9), x=max_x, y = max_y, name='Peaks In Raw Data',showlegend=False))\n",
    "fig4.add_trace(go.Scatter(mode='markers',marker=dict(color='orange', size=7), x=sample1.time[max_idxs], y = sample1.values[max_idxs], name='Raw Peaks',showlegend=False))\n",
    "\n",
    "fig4.update_layout(xaxis = dict(tickmode = 'array', tickvals = sample1.ticks_values, ticktext = sample1.time_format_axis),\n",
    "                    xaxis2 = dict(tickmode = 'array', tickvals = sample1.ticks_values, ticktext = sample1.time_format_axis));\n",
    "fig4.update_layout(xaxis_range=[79000,85000], yaxis_range=[-0.5,0.68])\n",
    "fig4.update_layout(height=600,width = 1300);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a16a6056-1aee-4975-a356-69245d7591c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig4.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5503b0a-e42f-4937-8767-cbfa494fe012",
   "metadata": {},
   "source": [
    "#### Time Differences with different amount of control points and re sampling frequency "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8002ceb-f694-42d8-819c-768cd3248e3d",
   "metadata": {},
   "source": [
    "## Interpolation with different window lenghts in the moving window integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5dcc9537-4d99-4d69-8c14-a1aa5ff0c638",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shared/braulio/ecg_algorithm/functions.py:232: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in sqrt\n",
      "\n",
      "/home/shared/braulio/ecg_algorithm/functions.py:233: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in sqrt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "interp = go.Figure()\n",
    "spline = 4\n",
    "max_x_dict= {};max_y_dict= {}\n",
    "res = 1000 \n",
    "\n",
    "\n",
    "for N in lengths: \n",
    "    \n",
    "    max_x_dict['Window: '+str(N)], max_y_dict['Window: '+str(N)], peaks_x, peaks_y, interpolated_peak_x, interpolated_peak_y, max_idx = interpolation_spline(\n",
    "        fiducial_point_dict['Window Length: '+str(N)], sample1.time, sample1.values, spline, res) \n",
    "    \n",
    "    interp.add_trace(go.Scatter(mode = 'lines', line= dict(color='blue'),x=sample1.time, y=sample1.values,showlegend=False,visible=False))\n",
    "    interp.add_trace(go.Scatter(mode = 'markers', x= max_x_dict['Window: '+str(N)], y=max_y_dict['Window: '+str(N)],\n",
    "                               name = 'Peaks ',showlegend=False,visible=False))\n",
    "    \n",
    "\n",
    "    \n",
    "interp.data[5].visible = True\n",
    "\n",
    "steps = []\n",
    "start = 0\n",
    "for length in lengths:\n",
    "    step = dict(\n",
    "        method=\"update\",\n",
    "        args=[{\"visible\": [False] * len(interp.data)},\n",
    "              {\"title\": 'Peaks Found           Window Length: ' + str(length)}],  # layout attribute\n",
    "    )\n",
    "    step[\"args\"][0][\"visible\"][start] = True # Toggle i'th trace to \"visible\"\n",
    "    step[\"args\"][0][\"visible\"][start+1] = True # Toggle i'th trace to \"visible\"\n",
    "    start = start + 2\n",
    "    steps.append(step)\n",
    "    \n",
    "sliders = [dict(active=5, currentvalue={\"prefix\": \"n: \"}, pad={\"t\": 50}, steps=steps)]\n",
    "interp.update_layout(sliders=sliders);\n",
    "#interp.update_layout(xaxis_range=[79000,85000]);\n",
    "interp.update_layout(xaxis = dict(tickmode = 'array', tickvals = sample1.ticks_values, ticktext = sample1.time_format_axis),autosize=False,width=1300,height=600);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3fc4a5bc-23dd-4be1-ba38-011ad7f9e829",
   "metadata": {},
   "outputs": [],
   "source": [
    "#interp.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd88fb7-8dd7-479c-a634-38cd744f2b09",
   "metadata": {},
   "source": [
    "## Mean Subtraction and wavelet transform "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4501dcd-c4e3-4caf-9749-485b181c9948",
   "metadata": {},
   "source": [
    "### We do the following just to check how good are the PT results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2ed4895c-0b4e-4b62-9ab6-33f7aa50cc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = average_filter(15,sample1.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cba6325d-ddf7-4241-a82f-6962c0443d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_peaks,_ = find_peaks(sample1.values-mean,distance=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2709f70a-8886-49a2-af9a-4901379a19b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig9 = go.Figure()\n",
    "\n",
    "fig9.add_trace(go.Scatter(mode = 'lines', line= dict(color='blue'),x=sample1.time, y=sample1.values,name='Raw Data',showlegend=True))\n",
    "#fig9.add_trace(go.Scatter(mode = 'lines', x=sample1.time, y=mean, name = 'Mean Average', showlegend = True))\n",
    "fig9.add_trace(go.Scatter(mode = 'lines', x=sample1.time, y=sample1.values-mean, name = 'Mean Subtraction', showlegend = True))\n",
    "fig9.update_layout(xaxis_range=[79000,85000]);\n",
    "fig9.update_layout(xaxis = dict(tickmode = 'array', tickvals = sample1.ticks_values, ticktext = sample1.time_format_axis),autosize=False,width=1200,height=600);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3dba5b-514e-4d55-9702-f5a65d95331b",
   "metadata": {},
   "source": [
    "### Interpolating with the mean subtraction peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "076360e9-0ffb-4c06-91a2-23a4588cc335",
   "metadata": {},
   "outputs": [],
   "source": [
    "spline=4;\n",
    "res = 5000\n",
    "max_x_w, max_y_w, peaks_x_w, peaks_y_w, interpolated_peak_x_w, interpolated_peak_y_w,max_idxs_m = interpolation_spline(mean_peaks, sample1.time, sample1.values, 4, res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5fd23c13-c0c1-422f-8470-796739c877ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "amount_of_peaks = len(max_x_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cb5c27fa-41e5-4b02-a201-0958a34d9077",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Comparing peaks of PT with window N"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99d675e-7ba9-422c-a2a7-b40ec042bdf0",
   "metadata": {},
   "source": [
    "### Comparing Pan Tompkins and mean average substraction + Wavelet Transform with all windows in Moving Window Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "48e8c3ec-368e-491b-aedd-0a7613c5ec35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visually missing peaks\n",
    "\n",
    "fig10 = go.Figure()\n",
    "missing_mean_p_dict ={};  missing_pt_p_dict={};\n",
    "spline=4;\n",
    "res = 5000\n",
    "\n",
    "\n",
    "for N in lengths: \n",
    "    #print(N)\n",
    "    missing_pt_p, missing_mean_p = find_missing_peaks(max_x_dict['Window: '+str(N)], max_x_w, True)\n",
    "    missing_pt_p_dict['window_length_'+str(N)] = missing_pt_p\n",
    "    missing_mean_p_dict['window_length_'+str(N)] = missing_mean_p\n",
    "    \n",
    "    fig10.add_trace(go.Scatter(line= dict(color='blue'),x=sample1.time, y=sample1.values,name='Raw Data',showlegend=True, visible = False))\n",
    "    \n",
    "\n",
    "    fig10.add_trace(go.Scatter(mode='markers',marker=dict(size=12),x=max_x_w, y= max_y_w, name = 'Mean Peaks', \n",
    "                               showlegend=True, visible = False))\n",
    "    fig10.add_trace(go.Scatter(mode='markers',marker=dict(size=10,color='#21B626'), x = max_x_dict['Window: '+str(N)], \n",
    "                              y = max_y_dict['Window: '+str(N)], name = 'P.T. Peaks WL: '+str(N),showlegend=True, \n",
    "                              visible = False))\n",
    "    fig10.add_trace(go.Scatter(mode='markers',marker=dict(size=7,color='orange'), x = max_x_dict['Window: '+str(N)][missing_mean_p], \n",
    "                               y= max_y_dict['Window: '+str(N)][missing_mean_p], name = 'Missing Mean Peaks', showlegend=True, visible = False))\n",
    "    \n",
    "    fig10.add_trace(go.Scatter(mode='markers',marker=dict(size=7,color='#00FCF5'),x = max_x_w[missing_pt_p] , y= max_y_w[missing_pt_p], \n",
    "                              name = 'Missing P.T. Peaks', showlegend=True, visible = False))\n",
    "\n",
    "fig10.data[5].visible = True\n",
    "\n",
    "steps = []\n",
    "start = 0\n",
    "for i in range(0,len(lengths)):\n",
    "    step = dict(\n",
    "        method=\"update\",\n",
    "        args=[{\"visible\": [False] * len(fig10.data)},\n",
    "              {\"title\": \"Peaks identified with PT window length \"+str(lengths[i])+ '   Amount of Mean + Wavelet Missing Peaks: '+\n",
    "               str(len(missing_mean_p_dict['window_length_'+str(lengths[i])])) +'   Amount of PT Missing Peaks: '+ \n",
    "               str(len(missing_pt_p_dict['window_length_'+str(lengths[i])]))}],  # layout attribute\n",
    "    )\n",
    "    step[\"args\"][0][\"visible\"][start] = True  # Toggle i'th trace to \"visible\"\n",
    "    step[\"args\"][0][\"visible\"][start+1] = True\n",
    "    step[\"args\"][0][\"visible\"][start+2] = True\n",
    "    step[\"args\"][0][\"visible\"][start+3] = True\n",
    "    step[\"args\"][0][\"visible\"][start+4] = True\n",
    "    \n",
    "    start = start+5\n",
    "    steps.append(step)\n",
    "    \n",
    "sliders = [dict(active=5, currentvalue={\"prefix\": \"n: \"}, pad={\"t\": 50}, steps=steps)]\n",
    "fig10.update_layout(sliders=sliders);\n",
    "fig10.update_layout(xaxis_range=[79000,85000]);\n",
    "fig10.update_layout(xaxis = dict(tickmode = 'array', tickvals = sample1.ticks_values, ticktext = sample1.time_format_axis),autosize=False,width=1200,height=600); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "296daaca-8e52-4f3e-9732-106369deacc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig10.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2a74ce-068e-46e9-aa66-8d83effea205",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "b2a9f141-fe1b-4635-952e-6415d36a2162",
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlapping_mean(total_time,heart_beat_time, time_window_length, windows): \n",
    "    # This block calculates the mean heartrate of the different windows \n",
    "    print('total_time: '+str(total_time) + ' mins')\n",
    "    print('')\n",
    "    print('windows: '+ str(windows))\n",
    "\n",
    "    first_array = np.delete(heart_beat_time,0)\n",
    "    second_array = np.delete(heart_beat_time,-1)\n",
    "\n",
    "    dif = (first_array - second_array)/1000\n",
    "    heart_rate = 60/dif\n",
    "\n",
    "    # k is the index where the cumulative sum of time is greater than half the time interval\n",
    "    k = 0\n",
    "    cmltive_time = 0\n",
    "\n",
    "    #The even_idx and odd_idx arrays store the indices where the windows start and finish.\n",
    "    even_idx = []\n",
    "    odd_idx = [0]\n",
    "    odd_window_mean = []\n",
    "    even_window_mean = []\n",
    "\n",
    "    # The total time of the interval will be defined by the amount of windows one chooses, the overlap and the length of the windows. \n",
    "    #This first loop is to find the index of the beginning of the second window \n",
    "    while cmltive_time < (time_window_length*60)/2 : \n",
    "        k = k + 1\n",
    "        cmltive_time = np.sum(dif[0:k])\n",
    "    even_idx = np.append(even_idx,k-1)\n",
    "\n",
    "    leading_time = time_window_length*60\n",
    "\n",
    "    window_counter = 1\n",
    "    odd = True \n",
    "\n",
    "\n",
    "    #At the end of the while there is still one more window to calculate its mean.\n",
    "    while window_counter < windows : \n",
    "        while cmltive_time < leading_time: \n",
    "            k = k + 1 \n",
    "            cmltive_time = np.sum(dif[0:k])\n",
    "\n",
    "        # The reason we append the index k-1 is because when the condition cmltive_time < leading_time isn't met you actually want the index from the sample before where the condition was actually met, \n",
    "        # which is k-1. \n",
    "\n",
    "        # The 'dif' array is actually the heartrate array. So what we need to do is to consider all of the heartbeats in that array for the established windows. \n",
    "\n",
    "        if odd:\n",
    "            odd = False \n",
    "            odd_idx = np.append(odd_idx,k-1)\n",
    "            odd_idx = np.asarray(odd_idx, dtype = 'int')\n",
    "            odd_window_mean = np.append(odd_window_mean ,np.mean(heart_rate[odd_idx[-2]:odd_idx[-1]]))\n",
    "\n",
    "        else: \n",
    "            odd = True\n",
    "            even_idx = np.append(even_idx,k-1)\n",
    "            even_idx = np.asarray(even_idx, dtype = 'int')\n",
    "            even_window_mean = np.append(even_window_mean, np.mean(heart_rate[even_idx[-2]:even_idx[-1]]))\n",
    "\n",
    "        leading_time = (time_window_length + (1-overlap_window)*(time_window_length)*(window_counter))*60\n",
    "        window_counter = window_counter + 1\n",
    "\n",
    "    #In this last part we include the mean of the last window. \n",
    "\n",
    "    if odd:\n",
    "        odd_idx=np.append(odd_idx,len(dif))\n",
    "        odd_window_mean = np.append(odd_window_mean ,np.mean(heart_rate[odd_idx[-2]:odd_idx[-1]]))\n",
    "\n",
    "    else: \n",
    "        even_idx=np.append(even_idx,len(dif))\n",
    "        even_window_mean = np.append(even_window_mean ,np.mean(heart_rate[even_idx[-2]:even_idx[-1]]))\n",
    "\n",
    "    overlap_mean_values=odd_window_mean\n",
    "    adding = 1\n",
    "\n",
    "    #Joinning the mean odd and even window arrays to a single one in order. \n",
    "    for j in range(0, len(even_window_mean)):\n",
    "        overlap_mean_values = np.insert(overlap_mean_values,j+adding,even_window_mean[j])\n",
    "        adding = adding + 1\n",
    "    \n",
    "    return overlap_mean_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "86a58680-2b95-4dee-a667-023e280f473d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_time: 20 mins\n",
      "\n",
      "windows: 7\n",
      "\n",
      "overlapping_array: [177.94915155 182.36143809 183.38517608 174.21389    171.08633536\n",
      " 171.73596706 170.82293089]\n"
     ]
    }
   ],
   "source": [
    "overlapping_array = overlapping_mean(total_time,max_x_dict['Window: 25'], time_wind_length, windows)\n",
    "print('')\n",
    "print('overlapping_array: '+str(overlapping_array))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b648c0-27b0-4c00-985c-f59b1f18898d",
   "metadata": {},
   "source": [
    "## Calculating the mean of overlapping windows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "913ea4e6-2032-4f75-8205-5ea3a544fd79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_time: 20 mins\n",
      "\n",
      "windows: 7\n"
     ]
    }
   ],
   "source": [
    "# This block calculates the mean heartrate of the different windows \n",
    "print('total_time: '+str(total_time) + ' mins')\n",
    "print('')\n",
    "print('windows: '+ str(windows))\n",
    "\n",
    "first_array = np.delete(max_x_dict['Window: 25'],0)\n",
    "second_array = np.delete(max_x_dict['Window: 25'],-1)\n",
    "\n",
    "dif = (first_array - second_array)/1000\n",
    "heart_rate = 60/dif\n",
    "\n",
    "# k is the index where the cumulative sum of time is greater than half the time interval\n",
    "k = 0\n",
    "cmltive_time = 0\n",
    "\n",
    "#The even_idx and odd_idx arrays store the indices where the windows start and finish.\n",
    "even_idx = []\n",
    "odd_idx = [0]\n",
    "odd_window_mean = []\n",
    "even_window_mean = []\n",
    "\n",
    "# The total time of the interval will be defined by the amount of windows one chooses, the overlap and the length of the windows. \n",
    "#This first loop is to find the index of the beginning of the second window \n",
    "while cmltive_time < (time_wind_length*60)/2 : \n",
    "    k = k + 1\n",
    "    cmltive_time = np.sum(dif[0:k])\n",
    "even_idx = np.append(even_idx,k-1)\n",
    "\n",
    "leading_time = time_wind_length*60\n",
    "\n",
    "window_counter = 1\n",
    "odd = True \n",
    "\n",
    "\n",
    "#At the end of the while there is still one more window to calculate its mean.\n",
    "while window_counter < windows : \n",
    "    while cmltive_time < leading_time: \n",
    "        k = k + 1 \n",
    "        cmltive_time = np.sum(dif[0:k])\n",
    "\n",
    "    # The reason we append the index k-1 is because when the condition cmltive_time < leading_time isn't met you actually want the index from the sample before where the condition was actually met, \n",
    "    # which is k-1. \n",
    "    \n",
    "    # The 'dif' array is actually the heartrate array. So what we need to do is to consider all of the heartbeats in that array for the established windows. \n",
    "    \n",
    "    if odd:\n",
    "        odd = False \n",
    "        odd_idx = np.append(odd_idx,k-1)\n",
    "        odd_idx = np.asarray(odd_idx, dtype = 'int')\n",
    "        odd_window_mean = np.append(odd_window_mean ,np.mean(heart_rate[odd_idx[-2]:odd_idx[-1]]))\n",
    "\n",
    "    else: \n",
    "        odd = True\n",
    "        even_idx = np.append(even_idx,k-1)\n",
    "        even_idx = np.asarray(even_idx, dtype = 'int')\n",
    "        even_window_mean = np.append(even_window_mean, np.mean(heart_rate[ even_idx[-2] : even_idx[-1] ]))\n",
    "\n",
    "        \n",
    "\n",
    "    leading_time = (time_wind_length + (1-overlap_window)*(time_wind_length)*(window_counter))*60\n",
    "    window_counter = window_counter + 1\n",
    "    \n",
    "#In this last part we include the mean of the last window. \n",
    "\n",
    "if odd:\n",
    "    odd_idx=np.append(odd_idx,len(dif))\n",
    "    odd_window_mean = np.append(odd_window_mean ,np.mean(heart_rate[odd_idx[-2]:odd_idx[-1]]))\n",
    "\n",
    "else: \n",
    "    even_idx=np.append(even_idx,len(dif))\n",
    "    even_window_mean = np.append(even_window_mean ,np.mean(heart_rate[ even_idx[-2] : even_idx[-1] ]))\n",
    "\n",
    "overlap_m_values=odd_window_mean\n",
    "adding = 1\n",
    "\n",
    "#Joinning the mean odd and even window arrays to a single one in order. \n",
    "for j in range(0, len(even_window_mean)):\n",
    "    overlap_m_values = np.insert(overlap_m_values,j+adding,even_window_mean[j])\n",
    "    adding = adding + 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7207f329-1f60-4973-ab49-335accfd3a6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932b6644-6add-4652-bc70-90206271359a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff97b2c-c40d-4a6c-ab1a-37fa88ab5e58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
