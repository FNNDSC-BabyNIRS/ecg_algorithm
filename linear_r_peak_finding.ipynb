{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "290aa860-d2a1-492d-82ec-2d9d127c735e",
   "metadata": {},
   "source": [
    "# Document's Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35d6c0c-3f2a-405d-8553-ef34b88ec6e6",
   "metadata": {},
   "source": [
    "#### · Display raw data from cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb031946-3161-493e-9ec1-04a4741f9e49",
   "metadata": {},
   "source": [
    "#### · Display raw data and located peaks recorded in cluster "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fc7aa9-0dc4-4215-9abf-097d9c171732",
   "metadata": {},
   "source": [
    "#### · Find peaks of recorder raw data with the most updated version of the algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d8be0e4-fdde-4314-81b1-347a2738249e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import nirscloud_util_meta\n",
    "import nirscloud_util_hdfs\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly\n",
    "import pyspark\n",
    "import sys\n",
    "from plotly.subplots import make_subplots\n",
    "import math \n",
    "import plotly.graph_objects as go\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import matrix\n",
    "from scipy.signal import find_peaks\n",
    "import datetime\n",
    "from scipy.signal import find_peaks,butter, lfilter, lfilter_zi, convolve,resample, correlate, iirnotch, filtfilt, stft\n",
    "from scipy import signal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b991332-290e-4327-83ab-27b2d45b062a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pymongo==3.13.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f41072d9-9310-4bd7-a3c8-3dbdd8295ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1be889b9-72ff-482f-ada7-345a782889d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_name = 'braulio.ramirez'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf36577a-f81f-42b0-a956-ec62464acdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger('jhub')\n",
    "hostname = 'mongos.mongo.svc.cluster.local:27017'\n",
    "pemkeyfile = '/etc/mongo/jhub-keypem.pem'\n",
    "sslca = '/etc/mongo/root-ca.pem'\n",
    "\n",
    "nirscloud_util_meta.init(logger, 'meta', hostname=hostname, ssl=True, cert=pemkeyfile, ca=sslca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "784166a8-3bb9-4462-bdec-d9255df1654c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-05 14:48:12 [INFO ] cfg#_init_hdfs_kinit@79: after hdfs_kinit: the_stdout: b'' the_stderr: b''\n",
      "2023-07-05 14:48:12 [INFO ] client#__init__@192: Instantiated <KerberosClient(url='https://hdfs2.babynirs.org:9870;https://hdfs1.babynirs.org:9870;https://hdfs4.babynirs.org:9870')>.\n"
     ]
    }
   ],
   "source": [
    "spark_kerberos_principal = my_name + '@BABYNIRS.ORG'\n",
    "\n",
    "params = {\n",
    "    'spark_kerberos_principal': spark_kerberos_principal,\n",
    "}\n",
    "nirscloud_util_hdfs.init('/etc/jhub/conf/production.ini', params=params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9682083-9c01-4a9d-bc69-34bb8224669e",
   "metadata": {},
   "source": [
    "### Pulling the recorded peaks from the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "829c37dc-48bc-4c72-a51f-47f6488b4a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdfs_path = '_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5848ff80-2731-4aff-b3bd-0e26d800f5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "kafka_topics = 'nk_rpeak2_NICU'\n",
    "hdfs_prefix = '/kafka/topics/%s'% (kafka_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9443025f-cfe8-4370-879b-797b1a25bf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_df(hdfs_path, the_id):\n",
    "    hdfs_path = hdfs_path\n",
    "    full_path = nirscloud_util_hdfs.full_path(hdfs_prefix, hdfs_path)\n",
    "    err, df = nirscloud_util_hdfs.from_hdfs_path(full_path)\n",
    "    print(err, df)\n",
    "    is_valid = df['id'] == the_id\n",
    "    df = df[is_valid]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fbc7b90a-c015-4b49-9375-b1d854cc8744",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-05 14:48:17 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-05 14:48:18 [INFO ] client#status@320: Fetching status for '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929'.\n",
      "2023-07-05 14:48:19 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-05 14:48:20 [INFO ] client#status@320: Fetching status for '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929'.\n",
      "2023-07-05 14:48:21 [INFO ] client#list@1123: Listing '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929'.\n",
      "2023-07-05 14:48:22 [INFO ] client#list@1123: Listing '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929'.\n",
      "2023-07-05 14:48:22 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-05 14:48:23 [INFO ] client#status@320: Fetching status for '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929/part-00000-3dc1ad61-1e54-40f7-bf0c-9dd31613338c.c000.snappy.parquet'.\n",
      "2023-07-05 14:48:24 [INFO ] client#read@731: Reading file '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929/part-00000-3dc1ad61-1e54-40f7-bf0c-9dd31613338c.c000.snappy.parquet'.\n",
      "2023-07-05 14:48:28 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-05 14:48:30 [INFO ] client#status@320: Fetching status for '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929/part-00000-a7de3d7b-e862-44e6-92e4-3c5f614da7c3.c000.snappy.parquet'.\n",
      "2023-07-05 14:48:31 [INFO ] client#read@731: Reading file '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929/part-00000-a7de3d7b-e862-44e6-92e4-3c5f614da7c3.c000.snappy.parquet'.\n",
      "2023-07-05 14:48:36 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-05 14:48:36 [INFO ] client#status@320: Fetching status for '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929/part-00001-5c9b6e80-d106-4e98-8785-30fac20ce5d9.c000.snappy.parquet'.\n",
      "2023-07-05 14:48:36 [INFO ] client#read@731: Reading file '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929/part-00001-5c9b6e80-d106-4e98-8785-30fac20ce5d9.c000.snappy.parquet'.\n",
      "2023-07-05 14:48:38 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-05 14:48:39 [INFO ] client#status@320: Fetching status for '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929/part-00001-7d8f0b76-fb44-42de-b9b2-c872825e306e.c000.snappy.parquet'.\n",
      "2023-07-05 14:48:39 [INFO ] client#read@731: Reading file '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929/part-00001-7d8f0b76-fb44-42de-b9b2-c872825e306e.c000.snappy.parquet'.\n",
      "2023-07-05 14:48:42 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-05 14:48:43 [INFO ] client#status@320: Fetching status for '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929/part-00001-ffd4be5c-52ca-4aa1-a4e7-ae7835c7b982.c000.snappy.parquet'.\n",
      "2023-07-05 14:48:43 [INFO ] client#read@731: Reading file '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929/part-00001-ffd4be5c-52ca-4aa1-a4e7-ae7835c7b982.c000.snappy.parquet'.\n",
      "2023-07-05 14:48:43 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-05 14:48:43 [INFO ] client#status@320: Fetching status for '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929/part-00002-b1b22d74-6344-4835-a54d-e4f13c127cc5.c000.snappy.parquet'.\n",
      "2023-07-05 14:48:43 [INFO ] client#read@731: Reading file '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929/part-00002-b1b22d74-6344-4835-a54d-e4f13c127cc5.c000.snappy.parquet'.\n",
      "2023-07-05 14:48:43 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-05 14:48:43 [INFO ] client#status@320: Fetching status for '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929/part-00002-d984a888-fd97-424c-ad25-24edaf49eb1f.c000.snappy.parquet'.\n",
      "2023-07-05 14:48:43 [INFO ] client#read@731: Reading file '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929/part-00002-d984a888-fd97-424c-ad25-24edaf49eb1f.c000.snappy.parquet'.\n",
      "2023-07-05 14:48:43 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-05 14:48:43 [INFO ] client#status@320: Fetching status for '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929/part-00003-a9d4f8c2-0090-480d-9297-dbda0f436f70.c000.snappy.parquet'.\n",
      "2023-07-05 14:48:43 [INFO ] client#read@731: Reading file '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929/part-00003-a9d4f8c2-0090-480d-9297-dbda0f436f70.c000.snappy.parquet'.\n",
      "2023-07-05 14:48:43 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-05 14:48:43 [INFO ] client#status@320: Fetching status for '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929/part-00003-f3cdcf06-7be1-43a9-a32a-c6e9decbf73d.c000.snappy.parquet'.\n",
      "2023-07-05 14:48:43 [INFO ] client#read@731: Reading file '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929/part-00003-f3cdcf06-7be1-43a9-a32a-c6e9decbf73d.c000.snappy.parquet'.\n",
      "2023-07-05 14:48:43 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-05 14:48:43 [INFO ] client#status@320: Fetching status for '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929/part-00004-17d15225-8719-4953-ad45-73ed1dd42460.c000.snappy.parquet'.\n",
      "2023-07-05 14:48:43 [INFO ] client#read@731: Reading file '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929/part-00004-17d15225-8719-4953-ad45-73ed1dd42460.c000.snappy.parquet'.\n",
      "2023-07-05 14:48:44 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-05 14:48:44 [INFO ] client#status@320: Fetching status for '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929/part-00004-b112fd52-76d1-4ffd-b27c-fa89fb2c521d.c000.snappy.parquet'.\n",
      "2023-07-05 14:48:44 [INFO ] client#read@731: Reading file '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929/part-00004-b112fd52-76d1-4ffd-b27c-fa89fb2c521d.c000.snappy.parquet'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None       id             start_ns          rec_nano_ts       val      ver  \\\n",
      "0     II  1686372038314000000  1686372039283320820  1.149853  v0.0.23   \n",
      "1     II  1686372038826000000  1686372039623391041  0.070611  v0.0.23   \n",
      "2     II  1686372038826000000  1686372039963980267  0.471633  v0.0.23   \n",
      "3     II  1686372039338000000  1686372040304866902  0.387760  v0.0.23   \n",
      "4     II  1686372039850000000  1686372040645622712  0.322574  v0.0.23   \n",
      "...   ..                  ...                  ...       ...      ...   \n",
      "3476  II  1686373175978000000  1686373176977949007 -0.491993  v0.0.23   \n",
      "3477  II  1686373176490000000  1686373177586859349  0.641429  v0.0.23   \n",
      "3478  II  1686373177002000000  1686373178182592895  0.716261  v0.0.23   \n",
      "3479  II  1686373177514000000  1686373178621707140  0.550078  v0.0.23   \n",
      "3480  II  1686373178026000000  1686373179078254610  2.296289  v0.0.23   \n",
      "\n",
      "     _device_id  _bed_id   _the_date _hr _patient_id  \n",
      "0       Procyon  HA11-01  2023-06-10  00     5984929  \n",
      "1       Procyon  HA11-01  2023-06-10  00     5984929  \n",
      "2       Procyon  HA11-01  2023-06-10  00     5984929  \n",
      "3       Procyon  HA11-01  2023-06-10  00     5984929  \n",
      "4       Procyon  HA11-01  2023-06-10  00     5984929  \n",
      "...         ...      ...         ...  ..         ...  \n",
      "3476    Procyon  HA11-01  2023-06-10  00     5984929  \n",
      "3477    Procyon  HA11-01  2023-06-10  00     5984929  \n",
      "3478    Procyon  HA11-01  2023-06-10  00     5984929  \n",
      "3479    Procyon  HA11-01  2023-06-10  00     5984929  \n",
      "3480    Procyon  HA11-01  2023-06-10  00     5984929  \n",
      "\n",
      "[3481 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "df_II_peaks = _get_df(hdfs_path, 'II')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a745a74-9e1b-4c14-a126-7c116801485d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_II_peaks.sort_values(by=['rec_nano_ts'], inplace=True)\n",
    "df_II_peaks.reset_index(drop=True, inplace=True)\n",
    "df_II_peaks['shift_rec_nano_ts'] = df_II_peaks['rec_nano_ts'].shift(-1)\n",
    "df_II_peaks['dif_rec_nano_ts'] = df_II_peaks['shift_rec_nano_ts'] - df_II_peaks['rec_nano_ts']\n",
    "df_II_peaks;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5bc05c0-5f80-49c0-82f5-954c40710c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "values_p = np.asarray(df_II_peaks['val'].to_numpy())\n",
    "raw_time_p = np.asarray(df_II_peaks['rec_nano_ts'].to_numpy(), dtype = 'int')\n",
    "time_p = [np.datetime64(int(t),'ns') for t in raw_time_p]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd620ff-217c-4393-a6f2-ad9e9d181d42",
   "metadata": {},
   "source": [
    "## Pulling continuous signal data from cluster "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "470ad255-978b-484c-b696-300861add7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "kafka_topics_cs = 'nk_waves_NICU'\n",
    "hdfs_prefix_cs = '/nirscloud/agg_by_hr3/%s'% (kafka_topics_cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3983926-1996-4999-b07f-25754dcae52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_df_cs(hdfs_path, the_id):\n",
    "    hdfs_path = hdfs_path + '/id=%s' % (the_id)\n",
    "    full_path = nirscloud_util_hdfs.full_path(hdfs_prefix_cs, hdfs_path)\n",
    "    err, df = nirscloud_util_hdfs.from_hdfs_path(full_path)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f926607-7c77-4373-bc88-ebb12881fa2f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-05 14:48:53 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-05 14:48:53 [INFO ] client#status@320: Fetching status for '/nirscloud/agg_by_hr3/nk_waves_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929/id=MDC_ECG_ELEC_POTL_II'.\n",
      "2023-07-05 14:48:53 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-05 14:48:53 [INFO ] client#status@320: Fetching status for '/nirscloud/agg_by_hr3/nk_waves_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929/id=MDC_ECG_ELEC_POTL_II'.\n",
      "2023-07-05 14:48:53 [INFO ] client#list@1123: Listing '/nirscloud/agg_by_hr3/nk_waves_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929/id=MDC_ECG_ELEC_POTL_II'.\n",
      "2023-07-05 14:48:53 [INFO ] client#status@320: Fetching status for '/nirscloud/agg_by_hr3/nk_waves_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929/id=MDC_ECG_ELEC_POTL_II'.\n",
      "2023-07-05 14:48:53 [INFO ] client#list@1123: Listing '/nirscloud/agg_by_hr3/nk_waves_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929/id=MDC_ECG_ELEC_POTL_II'.\n",
      "2023-07-05 14:48:53 [INFO ] client#status@320: Fetching status for '/nirscloud/agg_by_hr3/nk_waves_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929/id=MDC_ECG_ELEC_POTL_II'.\n",
      "2023-07-05 14:48:53 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-05 14:48:53 [INFO ] client#status@320: Fetching status for '/nirscloud/agg_by_hr3/nk_waves_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929/id=MDC_ECG_ELEC_POTL_II/part-00000-1f75843e-e8df-43ac-84d1-1c5b94653a8c.c000.snappy.parquet'.\n",
      "2023-07-05 14:48:53 [INFO ] client#read@731: Reading file '/nirscloud/agg_by_hr3/nk_waves_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929/id=MDC_ECG_ELEC_POTL_II/part-00000-1f75843e-e8df-43ac-84d1-1c5b94653a8c.c000.snappy.parquet'.\n"
     ]
    }
   ],
   "source": [
    "df_II_cs = _get_df_cs(hdfs_path, 'MDC_ECG_ELEC_POTL_II')\n",
    "df_II_cs.sort_values(by=['_milli_ts'], inplace=True)\n",
    "df_II_cs.reset_index(drop=True, inplace=True)\n",
    "df_II_cs['shift_milli_ts'] = df_II_cs['_milli_ts'].shift(-1)\n",
    "df_II_cs['diff_milli_ts'] = df_II_cs['shift_milli_ts'] - df_II_cs['_milli_ts']\n",
    "df_II_cs;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cdd81ff9-3979-477d-a917-eb7eb5835489",
   "metadata": {},
   "outputs": [],
   "source": [
    "values_cs = np.asarray(df_II_cs['val'].to_numpy())\n",
    "raw_time_cs = np.asarray(df_II_cs['_milli_ts'].to_numpy(), dtype = 'int')\n",
    "time_cs = [np.datetime64(int(t),'ms') for t in raw_time_cs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a98a6802-808f-41b5-8189-97ae411966a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_pks = np.array([(pd.Timestamp(t).hour*60*60*1000) + (pd.Timestamp(t).minute*60*1000) + (pd.Timestamp(t).second*1000) + (pd.Timestamp(t).microsecond/1000) for t in time_p]);\n",
    "time_cts = np.array([(pd.Timestamp(t).hour*60*60*1000) + (pd.Timestamp(t).minute*60*1000) + (pd.Timestamp(t).second*1000) + (pd.Timestamp(t).microsecond/1000) for t in time_cs]);\n",
    "time_pks = time_pks - time_cts[0]; time_cts = time_cts - time_cts[0];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "646078d7-b988-4a50-be5a-55b4d520a2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_f(time_array):\n",
    "\n",
    "    mins = ((time_array/1000)/60).astype(int);\n",
    "    sec = ((time_array/1000)%60).astype(int);\n",
    "    mili = ((time_array - (mins*60*1000 + sec*1000))*100).astype(int)/100 #*100.astype(int)/100 is to round to two decimals\n",
    "\n",
    "    return (np.array([str(minutes)+':'+str(seconds)+':'+str(milis) for minutes, seconds, milis in zip(mins,sec,mili)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c71380b0-934a-495f-8516-cba2ce8850a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class raw_sample_():\n",
    "    \n",
    "    def __init__(self,min_min,min_sec,max_min,max_sec,seconds_per_label):\n",
    "        \n",
    "        self.min_min = min_min\n",
    "        self.min_sec = min_sec\n",
    "        self.max_min = max_min\n",
    "        self.max_sec = max_sec\n",
    "        self.seconds_per_label = seconds_per_label\n",
    "\n",
    "        self.min_time = int((self.min_min*60*1000)/4) + int(self.min_sec*1000/4)\n",
    "        self.max_time = int((self.max_min*60*1000)/4) + int(self.max_sec*1000/4) + 1\n",
    "        self.pks_time_min = (self.min_min*60*1000) + (self.min_sec*1000)\n",
    "        self.pks_time_max = (self.max_min*60*1000) + (self.max_sec*1000)\n",
    "        self.pks_time = time_pks[(self.pks_time_min > time_pks).argmin():(time_pks < self.pks_time_max).argmin()]\n",
    "        self.pks_values = values_p[(self.pks_time_min > time_pks).argmin():(time_pks < self.pks_time_max).argmin()]\n",
    "        \n",
    "        self.time =time_cts[self.min_time:self.max_time]\n",
    "        self.values = df_II_cs['val'].to_numpy()[self.min_time:self.max_time]\n",
    "\n",
    "        self.fig = go.Figure()\n",
    "        self.fig.add_trace(go.Scatter(line= dict(color='blue'),x=self.time, y=self.values,showlegend=False))\n",
    "        self.fig.add_trace(go.Scatter(mode='markers', marker= dict(color='red'),x=self.pks_time, y=self.pks_values,showlegend=False))\n",
    "\n",
    "        self.ticks_values = []\n",
    "        x = self.time[0]\n",
    "        while x < self.time[-1]:\n",
    "            self.ticks_values = np.append(self.ticks_values,x)\n",
    "            x = 1000*self.seconds_per_label + x\n",
    "\n",
    "        self.time_format_axis = time_f(self.ticks_values)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1b123945-48f5-489e-9108-a4f02415434d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample1 = raw_sample_(1,0,2,0,1)\n",
    "fig_raw = sample1.fig\n",
    "fig_raw.update_layout(xaxis = dict(tickmode = 'array', tickvals = sample1.ticks_values, ticktext = sample1.time_format_axis),autosize=False,width=1250,\n",
    "                  height=600,showlegend=False,title=\"Cluster Data          Bed: HA11-01           hr: 00  \", xaxis_title=\"Time\", yaxis_title= 'Signal', \n",
    "                  font=dict(family=\"Avenir\",size=14,color=\"Black\"));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0551947f-9752-4262-a7e8-73b8fdb639d6",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7c788685-be82-487a-812f-85f74f012b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "class sample_():\n",
    "    \n",
    "    def __init__(self,min_min,min_sec,max_min,max_sec,seconds_per_label,find_the_peaks,inverted):\n",
    "        \n",
    "        self.min_min = min_min\n",
    "        self.min_sec = min_sec\n",
    "        self.max_min = max_min\n",
    "        self.max_sec = max_sec\n",
    "        self.seconds_per_label = seconds_per_label\n",
    "\n",
    "        self.min_time = int((self.min_min*60*1000)/4 + int(self.min_sec*1000)/4) \n",
    "        self.max_time = int((self.max_min*60*1000)/4 + int(self.max_sec*1000)/4) + 1\n",
    "\n",
    "        \n",
    "        time_zero = raw_time_cs[0]\n",
    "        self.time = raw_time_cs[self.min_time:self.max_time] - time_zero\n",
    "        if inverted:\n",
    "            self.values = - df_II_cs['val'].to_numpy()[self.min_time:self.max_time]\n",
    "        else: \n",
    "            self.values =  df_II_cs['val'].to_numpy()[self.min_time:self.max_time]\n",
    "\n",
    "        self.fig = go.Figure()\n",
    "        self.fig.add_trace(\n",
    "                      go.Scatter(line= dict(color='blue'),x=self.time, y=self.values,showlegend=False))\n",
    "\n",
    "        self.ticks_values = []\n",
    "        x = self.time[0]\n",
    "        while x < self.time[-1]:\n",
    "            self.ticks_values = np.append(self.ticks_values,x)\n",
    "            x = 1000*self.seconds_per_label + x\n",
    "\n",
    "        self.time_format_axis = time_f(self.ticks_values)\n",
    "        \n",
    "        if find_the_peaks:\n",
    "            self.peaks, _ = find_peaks(self.values, distance=100)\n",
    "            self.fig.add_trace(\n",
    "                      go.Scatter(mode='markers',x=self.time[self.peaks], y=self.values[self.peaks],showlegend=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6997df68-88fe-4c6b-a522-049584b0c4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bandpass_filter(data, lowcut, highcut, signal_freq, filter_order):\n",
    "    nyquist_freq = 0.5 * signal_freq\n",
    "    low = lowcut / nyquist_freq\n",
    "    high = highcut / nyquist_freq\n",
    "    b, a = butter(filter_order, [low, high], btype=\"band\")\n",
    "    y = lfilter(b, a, data)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b0bb2149-70c4-4270-8a8f-e21415c3bcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#found_peaks needs to be the index of the peaks in the raw_data_values or raw_data_time\n",
    "# This function returns the maximum or the interpolated peaks and the interpolated peak itself\n",
    "def interpolation(found_peaks,raw_data_time, raw_data_values):\n",
    "    \n",
    "    # First identify if we are past the peak or before \n",
    "    amount_of_peaks = len(found_peaks)\n",
    "    corrected_peaks_dict = {}; interpolated_peak_y = {} ;interpolated_peak_x = {};\n",
    "    peaks_x = []; peaks_y = [];\n",
    "\n",
    "    f = np.zeros(3)\n",
    "\n",
    "    for i in range (0,amount_of_peaks): \n",
    "\n",
    "        #print(i)\n",
    "\n",
    "        index = found_peaks[i]\n",
    "        point = raw_data_values[index]\n",
    "        previous_point = raw_data_values[index-1]\n",
    "\n",
    "        if previous_point < point: \n",
    "            while previous_point < point: \n",
    "                index = index + 1\n",
    "                point = raw_data_values[index]\n",
    "                previous_point = raw_data_values[index-1]\n",
    "\n",
    "            # When the while isn't valid the maximum is located at index-1\n",
    "\n",
    "            last_p = index + 2\n",
    "            first_p = index - 3\n",
    "\n",
    "        #point will be the point past the maximum \n",
    "        else: \n",
    "            while previous_point > point: \n",
    "                index = index - 1\n",
    "                point = raw_data_values[index]\n",
    "                previous_point = raw_data_values[index-1]\n",
    "\n",
    "            #when the while finished or isn't valid the maximum is located at index\n",
    "            last_p = index+3\n",
    "            first_p = index-2\n",
    "\n",
    "        # Were staying with the maximum, one forward, and two previous points \n",
    "\n",
    "        r = raw_data_values[[first_p,first_p+2,last_p-1,last_p]]\n",
    "        x = raw_data_time[[first_p,first_p+2,last_p-1,last_p]]\n",
    "\n",
    "        # interpolation \n",
    "\n",
    "        f[0] = (x[2] - x[0]) / (x[1] - x[0])\n",
    "        f[1] = (x[3] - x[3]) / (x[1] - x[0])\n",
    "        f[2] = (((x[3]**2) - (x[0]**2)) - (f[1]*((x[1]**2) - (x[0]**2)))) / (((x[2]**2) - (x[0]**2)) - (f[0]*((x[1]**2) - (x[0]**2))))\n",
    "\n",
    "\n",
    "        d = ( r[3]-r[0] - ( f[1] * ( r[1] - r[0] ) ) - ( ( r[2] - r[0] - (f[0] * (r[1]-r[0]) ) )*f[1]) ) / ((x[3]**3) - (x[0]**3) - ( ( (x[1]**3) - (x[0]**3) ) * f[1]) - (f[2]*( ( (x[2]**3) - (x[0]**3) ) - (f[0] * ( (x[1]**3)-(x[0]**3) )  ) ) ))\n",
    "        c = ( r[2] - r[0] - ( (r[1]-r[0])*f[0]) - ( d * ( (x[2]**3) - (x[0]**3) - (f[0]*( (x[1]**3) - (x[0]**3) ) ) ) ) ) / ( (x[2]**2) - (x[0]**2) - ( f[0] * ( (x[1]**2) - (x[0]**2) )  ) )\n",
    "        b = ( r[1] - r[0] - (d*((x[1]**3) - (x[0]**3))) - (c*((x[1]**2) - (x[0]**2))) ) / (x[1]-x[0])\n",
    "        a = r[0] - (b*x[0]) - (c*(x[0]**2)) - (d*(x[0]**3))\n",
    "\n",
    "        x_interp = np.arange(x[0],x[2]+0.5,0.5)\n",
    "        y = a + (b*x_interp) + (c*(x_interp**2)) + (d*(x_interp**3))\n",
    "        max_index = np.where(max(y)==y)\n",
    "\n",
    "        peaks_x = np.append(peaks_x,x_interp[max_index][0])\n",
    "        peaks_y = np.append(peaks_y, y[max_index][0])\n",
    "        interpolated_peak_x['peak: '+str(i)] = x_interp\n",
    "        interpolated_peak_y['peak: '+str(i)] = y\n",
    "        corrected_peaks_dict['peak: '+str(i) ] = [x_interp[max_index][0],y[max_index][0]]\n",
    "        \n",
    "        \n",
    "    return peaks_x, peaks_y, interpolated_peak_x, interpolated_peak_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "da62a572-5345-44cd-96c1-a97274074d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrices={}\n",
    "three_spline_m = np.array([[4, 1, 0, 0, 0, 0]])\n",
    "four_spline_m =  np.array([[4, 1, 0, 0, 0, 0, 0, 0]])\n",
    "\n",
    "two_spline_m =  np.array([[4, 1, 0, 0], [1, 4, 1, 0], [0, 1 , 4 , 1], [0, 0, 1, 4]])\n",
    "\n",
    "new_row_3 = np.array([1, 4, 1, 0, 0, 0,])\n",
    "new_row_4 = np.array([1, 4, 1, 0, 0, 0, 0, 0])\n",
    "\n",
    "for l in range(0,(6-2)):\n",
    "    three_spline_m = np.vstack([three_spline_m, np.roll(new_row_3, l)])\n",
    "three_spline_m = np.vstack([three_spline_m, np.array([[0, 0, 0, 0, 1, 4]])])\n",
    "\n",
    "for u in range(0,(8-2)):\n",
    "    four_spline_m = np.vstack([four_spline_m, np.roll(new_row_4, u)])\n",
    "four_spline_m = np.vstack([four_spline_m, np.array([[0, 0, 0, 0, 0, 0, 1, 4]])])\n",
    "\n",
    "inverse_two_spline_m = np.linalg.inv(two_spline_m); inverse_three_spline_m = np.linalg.inv(three_spline_m); inverse_four_spline_m = np.linalg.inv(four_spline_m)\n",
    "matrices['2_splines'] = inverse_two_spline_m; matrices['3_splines'] = inverse_three_spline_m; matrices['4_splines'] = inverse_four_spline_m;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "90006a82-dc58-4ff2-bc21-1519f6d0d1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "xn = np.arange(400,412 + 1000/5000 ,1000/5000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d2b6da11-51f4-4a79-9262-de194ae6d595",
   "metadata": {},
   "outputs": [],
   "source": [
    "#found_peaks needs to be the index of the peaks in the raw_data_values or raw_data_time\n",
    "# This function returns the maximum or the interpolated peaks and the interpolated peak itself\n",
    "# splines is how many splines you want to carry out around the peak, minumum is 1 for it to have  \n",
    "# one polynomial to the right and one to the left\n",
    "\n",
    "def interpolation_spline(found_peaks, raw_data_time, raw_data_values, splines, resolution):\n",
    "    \n",
    "    res = 1000/resolution\n",
    "    \n",
    "    # First identify if we are past the peak or before \n",
    "    h = 4;\n",
    "    max_indices = []\n",
    "    \n",
    "    #amount of control points\n",
    "    amount_of_peaks = len(found_peaks)\n",
    "    corrected_peaks_dict = {}; interpolated_peak_y = {} ;interpolated_peak_x = {};\n",
    "    peaks_x = []; peaks_y = []; max_x = []; max_y = [];\n",
    "\n",
    "    f = np.zeros(3)\n",
    "    for i in range (0,amount_of_peaks): \n",
    "\n",
    "        #print(i)\n",
    "\n",
    "        index = found_peaks[i]\n",
    "        point = raw_data_values[index]\n",
    "        previous_point = raw_data_values[index-1]\n",
    "\n",
    "        #Finding the maximum\n",
    "        \n",
    "        if previous_point < point: \n",
    "            while previous_point < point: \n",
    "                index = index + 1\n",
    "                point = raw_data_values[index]\n",
    "                previous_point = raw_data_values[index-1]\n",
    "\n",
    "            # When the while isn't valid the maximum is located at index-1\n",
    "            max_idx = index - 1\n",
    "\n",
    "\n",
    "        #point will be the point past the maximum \n",
    "        \n",
    "        else: \n",
    "            while previous_point > point: \n",
    "                index = index - 1\n",
    "                point = raw_data_values[index]\n",
    "                previous_point = raw_data_values[index-1]\n",
    "\n",
    "            #when the while finished or isn't valid the maximum is located at index\n",
    "            \n",
    "            max_idx = index\n",
    "        \n",
    "        max_indices = np.append(max_indices,max_idx)\n",
    "        last_p = max_idx + splines + 2\n",
    "        first_p = max_idx - (splines + 1)\n",
    "\n",
    "        # r and x include from x_{-1} up to x_{n+3}\n",
    "        r = raw_data_values[first_p:last_p+1]\n",
    "        x = raw_data_time[first_p:last_p+1]\n",
    "\n",
    "        # interpolation \n",
    "        \n",
    "        \n",
    "        #M_(-1)\n",
    "        m_1 =  (r[2] - (2*r[1]) + r[0]) / (h**2)\n",
    "        #M_(n+1)\n",
    "        m_n_1 =  (r[-1] - (2*r[-2]) + r[-3]) /(h**2)\n",
    "        ys =[]\n",
    "        ys = np.append( ys, ( (6/(h**2)) * (r[0] - (2*r[1]) + r[2]) ) + m_1 )\n",
    "        actual_cp = splines*2\n",
    "        \n",
    "        for n in range(1,(actual_cp-2)+1):\n",
    "            ys = np.append( ys, (6/(h**2)) * (r[n] - (2*r[n+1]) + r[n+2]) )\n",
    "        \n",
    "        ys = np.append( ys, (6/(h**2)) * (r[actual_cp-1] - (2*r[actual_cp]) + r[actual_cp+1]) - m_n_1)\n",
    "        \n",
    "        \n",
    "        # Now the define inverted matrices\n",
    "        \n",
    "        inverted_matrix = matrices[str(splines)+'_splines']\n",
    "        \n",
    "        \n",
    "        Ms = np.matmul(inverted_matrix, ys)\n",
    "        b = Ms/2\n",
    "        #We are appending m_n_1 which is the variable for M_{n+1} because we need it to calculate the c's\n",
    "        Ms = np.append(Ms,m_n_1)\n",
    "        a = (Ms[1:actual_cp+1] - Ms[0:actual_cp])/(6*h)\n",
    "        c = ((r[2:(actual_cp+1)+1] - r[1:actual_cp + 1])/h) - ((h/6)*(Ms[1:actual_cp+1]+(2*Ms[0:actual_cp])))\n",
    "        d = r[1:actual_cp +1] \n",
    "        # Remember the plus one is to include the last element which is the actual_cp index other wise python doesn't touch the last elemment\n",
    "        \n",
    "        interpolated_y = []\n",
    "        \n",
    "        #Piecewise polynomials\n",
    "        for k in range (1,(splines*2)): \n",
    "            x_int = np.arange(x[k],x[k+1],res)\n",
    "            y_int = (a[k-1]*((x_int - x[k])**3)) + (b[k-1]*((x_int - x[k])**2)) + (c[k-1]*(x_int-x[k])) + d[k-1]\n",
    "            interpolated_y = np.concatenate((interpolated_y,y_int))\n",
    "            \n",
    "        # We delete every last point so that it doesn't repeat with the first of the next piecewise polynomial\n",
    "        # So this last block of code is to include the last interpolation with the last point\n",
    "        l_cp = splines*2\n",
    "        x_int = np.arange(x[l_cp],x[l_cp+1]+res,res)\n",
    "        y_int = (a[l_cp-1]*((x_int - x[l_cp])**3)) + (b[l_cp-1]*((x_int - x[l_cp])**2)) + (c[l_cp-1]*(x_int-x[l_cp])) + d[l_cp-1]\n",
    "        interpolated_y = np.concatenate((interpolated_y, y_int))\n",
    "        interpolated_x = np.arange(x[1],x[(splines*2)+1]+res ,res)\n",
    "        \n",
    "        interpolated_peak_y['peak: '+str(i)] = interpolated_y; interpolated_peak_x['peak: '+str(i)] = interpolated_x; \n",
    "        \n",
    "        # getting the maximum collecting  vallues\n",
    "        max_index = np.where(max(interpolated_y)==interpolated_y)\n",
    "\n",
    "        peaks_x = np.append(peaks_x,interpolated_x[max_index][0])\n",
    "        peaks_y = np.append(peaks_y, interpolated_y[max_index][0])\n",
    "        \n",
    "        #Analytical Solution\n",
    "        \n",
    "        roots_1 = []; roots_2 = []; s_eval_roots = []; s2_eval_roots =[]\n",
    "        aj = a[splines-1:splines+1]; bj = b[splines-1:splines+1]; cj = c[splines-1:splines+1]; dj = d[splines-1:splines+1]; xj = x[splines:splines+2]\n",
    "        \n",
    "        #Coefficients of general formula 1 is for the first piecewise poolynomial and 2 is for the second piecewise polynomial\n",
    "        g_a1 = 3*aj[0]; g_b1 = (2*bj[0] - (2*xj[0]*3*aj[0])); g_c1 = (3*aj[0]*(xj[0]**2)) - (2*bj[0]*xj[0]) + cj[0]\n",
    "        g_a2 = 3*aj[1]; g_b2 = (2*bj[1] - (2*xj[1]*3*aj[1])); g_c2 = (3*aj[1]*(xj[1]**2)) - (2*bj[1]*xj[1]) + cj[1]\n",
    "\n",
    "        roots_1 = np.append(roots_1, (- g_b1 + np.sqrt((g_b1**2) - (4 * g_a1 * g_c1 )))/(2*g_a1) );\n",
    "        roots_1 = np.append(roots_1, (- g_b1 - np.sqrt((g_b1**2) - (4 * g_a1 * g_c1 )))/(2*g_a1) );\n",
    "        s_eval_roots = np.append(s_eval_roots, aj[0]*((roots_1[0]-xj[0])**3) + bj[0]*((roots_1[0]-xj[0])**2) + cj[0]*(roots_1[0]-xj[0]) + dj[0])\n",
    "        s_eval_roots = np.append(s_eval_roots, aj[0]*((roots_1[1]-xj[0])**3) + bj[0]*((roots_1[1]-xj[0])**2) + cj[0]*(roots_1[1]-xj[0]) + dj[0])\n",
    "        \n",
    "        if roots_1[np.argmax(s_eval_roots)] <=xj[1]:\n",
    "            max_x = np.append(max_x, roots_1[np.argmax(s_eval_roots)])\n",
    "            max_y = np.append(max_y, s_eval_roots[np.argmax(s_eval_roots)])\n",
    "            \n",
    "        else: \n",
    "            roots_2 = np.append(roots_2, (- g_b2 + np.sqrt((g_b2**2) - (4 * g_a2 * g_c2 )))/(2*g_a2) );\n",
    "            roots_2 = np.append(roots_2, (- g_b2 - np.sqrt((g_b2**2) - (4 * g_a2 * g_c2 )))/(2*g_a2) );\n",
    "            s2_eval_roots = np.append(s2_eval_roots, aj[1]*((roots_2[0]-xj[1])**3) + bj[1]*((roots_2[0]-xj[1])**2) + cj[1]*(roots_2[0]-xj[1]) + dj[1])\n",
    "            s2_eval_roots = np.append(s2_eval_roots, aj[1]*((roots_2[1]-xj[1])**3) + bj[1]*((roots_2[1]-xj[1])**2) + cj[1]*(roots_2[1]-xj[1]) + dj[1])\n",
    "            max_x = np.append(max_x, roots_2[np.argmax(s2_eval_roots)])\n",
    "            max_y = np.append(max_y, s2_eval_roots[np.argmax(s2_eval_roots)])\n",
    "            \n",
    "    max_indices = np.asarray(max_indices, dtype = 'int')\n",
    "        \n",
    "    #max_x and max_y is for analytical solutions, peaks_x and peaks_y is for maximum by collecting data, and interpolated_peak_x/y is the actual interpolation\n",
    "    return max_x, max_y, peaks_x, peaks_y, interpolated_peak_x, interpolated_peak_y,max_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0e33b2a8-30a7-4d87-9b8d-1b81172a3ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function takes two arrays of peaks, where each value in the array is the index of the peak, and finds \n",
    "# if any of them have missing peaks compared to the other array\n",
    "# Index comparing is when you are comparing the index of two different arrays but you might want to compare actual elements\n",
    "\n",
    "def find_missing_peaks(a_peaks, b_peaks, index_comparing):\n",
    "    missing_b_peaks = []; missing_a_peaks = []\n",
    "\n",
    "    if len(a_peaks)<len(b_peaks):\n",
    "        #a_peaks is the shortest in length\n",
    "        a_peaks=np.append(a_peaks,np.zeros(len(b_peaks) - len(a_peaks)))        \n",
    "\n",
    "    else: \n",
    "        #b_peaks is the shortest in length\n",
    "        b_peaks=np.append(b_peaks,np.zeros(len(a_peaks) - len(b_peaks)))\n",
    "\n",
    "        \n",
    "    difference = abs(a_peaks - b_peaks) #Subtraction order don't matter\n",
    "\n",
    "    a_insertions = 0; b_insertions = 0;\n",
    "\n",
    "    while (difference>70).any():\n",
    "        \n",
    "\n",
    "        #Here we first find in what index is where a mark is misssing\n",
    "\n",
    "        index = np.min(np.where(difference>70))\n",
    "        #This defines if either the short pivot or the long pivot array is missing a mark on a peak\n",
    "        \n",
    "        # If True then there's a missing peak in the b pivot\n",
    "\n",
    "        if (a_peaks[index] - b_peaks[index]) < 0:\n",
    "            \n",
    "\n",
    "            #This is for handling the last zeros. When you arrive to the ending zeros it means that you will not do \n",
    "            # more insertions but rather replace the zeros for the peaks\n",
    "            \n",
    "            if a_peaks[index] == 0:\n",
    "                a_peaks = np.insert(a_peaks,index,b_peaks[index])\n",
    "                a_peaks = np.delete(a_peaks,-1)\n",
    "                missing_a_peaks = np.append(missing_a_peaks,index-b_insertions)\n",
    "\n",
    "            else:\n",
    "                missing_b_peaks = np.append(missing_b_peaks,index-a_insertions)\n",
    "                b_peaks = np.insert(b_peaks,index,a_peaks[index])\n",
    "                b_insertions = b_insertions + 1\n",
    "                \n",
    "                \n",
    "                # If last element is zero you can erease last element, otherwise append a 0 to the other array. \n",
    "                if b_peaks[-1] == 0 :\n",
    "                    b_peaks = np.delete(b_peaks,-1)\n",
    "                else:\n",
    "                    a_peaks =  np.append(a_peaks,0)\n",
    "\n",
    "        #There is a missing peak in the a_peaks\n",
    "        else:\n",
    "            \n",
    "           #This is for handling the last zeros. \n",
    "            if b_peaks[index] == 0:\n",
    "\n",
    "                b_peaks = np.insert(b_peaks,index,a_peaks[index])\n",
    "                b_peaks = np.delete(b_peaks,-1)\n",
    "                missing_b_peaks = np.append(missing_b_peaks,index-a_insertions)\n",
    "\n",
    "\n",
    "            else:\n",
    "                missing_a_peaks = np.append(missing_a_peaks,index - b_insertions)\n",
    "                a_peaks = np.insert(a_peaks,index,b_peaks[index])\n",
    "                a_insertions = a_insertions + 1\n",
    "                \n",
    "                if a_peaks[-1] == 0 :\n",
    "                    a_peaks = np.delete(a_peaks,-1)\n",
    "                else:\n",
    "                    b_peaks =  np.append(b_peaks,0)\n",
    "                \n",
    "        difference = abs(a_peaks - b_peaks)\n",
    "    \n",
    "   \n",
    "    if index_comparing: \n",
    "        missing_a_peaks = np.asarray(missing_a_peaks, dtype = 'int'); missing_b_peaks = np.asarray(missing_b_peaks, dtype = 'int')\n",
    "    else: \n",
    "        missing_a_peaks = np.asarray(missing_a_peaks, dtype = 'float'); missing_b_peaks = np.asarray(missing_b_peaks, dtype = 'float')\n",
    "        \n",
    "        \n",
    "    # The outcome are the indices that are missing in the other array. For example if a is missing the index N in the b array \n",
    "    # then the index N is stored in missing_a_peaks\n",
    "    # missing_a_peaks are indices of the b array, with elements that a doesn't contain\n",
    "    return missing_a_peaks, missing_b_peaks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7e157bb0-ab19-4c42-8a9e-39fe29e93c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This moving average function which serves as a difference equation is a central moving average which means that you are \n",
    "# averaging a point taking into account both sides neighbors. So at last you will need to cut either (window_length-1)/2)\n",
    "# or (window_length-2)/2) depending wether you are having an even or odd number in the window length\n",
    "\n",
    "def moving_average(window_length, y):\n",
    "    \n",
    "    x=y\n",
    "    M = window_length - 1\n",
    "    z = np.zeros(M+1)\n",
    "    x_modified = np.concatenate((z,x[0:len(x) - (M+1)]))\n",
    "    y1= (1/(M+1)) * (x[0]-x_modified[0])\n",
    "    yn = [y1]\n",
    "\n",
    "    for n in range (1,len(x)):\n",
    "        y_value = ((1/(M+1)) * (x[n]-x_modified[n])) + yn[n-1]\n",
    "        yn = np.append(yn,y_value)\n",
    "\n",
    "    if window_length% 2 == 1: \n",
    "        cutting_points = int((window_length-1)/2) \n",
    "        yn = yn[cutting_points:len(yn)]\n",
    "        \n",
    "    else: \n",
    "        cutting_points = int((window_length-2)/2)\n",
    "        yn = yn[cutting_points:len(yn)]\n",
    "        \n",
    "    return yn, cutting_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "37400d19-429b-4b2b-9c46-3a90c5f0cad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_filter(window_length,signal):\n",
    "\n",
    "    m2 = window_length - 1\n",
    "\n",
    "    u = np.heaviside(np.arange(0,len(signal)),1)\n",
    "    u_sub = np.concatenate([np.zeros(window_length),np.heaviside(np.arange(0,len(signal)-(window_length)),1)])\n",
    "    h_n_s= (1/(window_length)) * (u - u_sub)\n",
    "\n",
    "    mov_av_s = np.convolve (h_n_s,signal)\n",
    "    mov_av_s_sh = mov_av_s[int(m2/2):len(signal)+int(m2/2)]\n",
    "    \n",
    "    return mov_av_s_sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "44ff6a16-3f32-4c22-8675-1d0336cc9e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dif_eq_window_integration(function,window_length,divide):\n",
    "    \n",
    "    pivot_function = function\n",
    "    \n",
    "    for i in range(1,window_length):\n",
    "        pivot_function = np.insert(pivot_function,0,0)\n",
    "        pivot_function = np.delete(pivot_function,len(pivot_function)-1)\n",
    "        #print(pivot_function)\n",
    "        function = function + pivot_function\n",
    "\n",
    "        if divide: \n",
    "            result = (1/N)*function\n",
    "        else: \n",
    "            result = function\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d4b97028-ba88-4cca-a1ca-e9b0b4d5f451",
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_peaks_height_av(y,segments,fraction_of_a_second):\n",
    "\n",
    "    s = 0\n",
    "    max_values = []\n",
    "    \n",
    "    f = 250*fraction_of_a_second\n",
    "\n",
    "    while s < segments: \n",
    "\n",
    "        max_values = np.append(max_values,np.max(y[int(f*s):int(f*(s+1))]))\n",
    "        s = s+1\n",
    "\n",
    "    average_peak_h = np.sum(max_values)/segments\n",
    "    \n",
    "    return average_peak_h, max_values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8ba35c-8863-41a4-885c-61f31f7afa7d",
   "metadata": {},
   "source": [
    "## Getting a sample from raw data in cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "91fa0b40-1348-477d-88b8-e33a550e5a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample1 = sample_(1,0,2,0,1,False,False)\n",
    "fig = sample1.fig\n",
    "fig.update_layout(xaxis = dict(tickmode = 'array', tickvals = sample1.ticks_values, ticktext = sample1.time_format_axis),autosize=False,width=1250,\n",
    "                  height=600,showlegend=False,title=\"Raw Data \", xaxis_title=\"Time\", yaxis_title= 'Signal', \n",
    "                  font=dict(family=\"Avenir\",size=14,color=\"Black\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b7dad340-f694-4386-92a8-1e5c520f5d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f291d6-6da2-49be-bec9-407803f6a196",
   "metadata": {},
   "source": [
    "## Pre processing, baseline wander removal through moving average subtraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadfdde5-640c-4a88-b740-00baed0be8dc",
   "metadata": {},
   "source": [
    "$$y[n]_{Moving Average} = \\frac{1}{M_2 + 1}(x[n]-x[n-M_2-1]) + y[n-1]$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9ed82be5-58d7-45fd-8795-79f92da621b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block proves that the difference equation has the same result with the convolution, data has been preprocessed \n",
    "# and pan tompkins algorithm can take place now. \n",
    "\n",
    "upper_limit = 10000\n",
    "w = 15\n",
    "mean = average_filter(w,sample1.values)\n",
    "yn, cut_pts = moving_average(w,sample1.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4a79cf4a-c143-4988-9318-450d2fc565aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing different window lengths for pre processing stage\n",
    "\n",
    "fig_pre_p = go.Figure()\n",
    "\n",
    "baseline_removal = {}\n",
    "prepro_data = {}\n",
    "cut_pts ={}\n",
    "x = sample1.time\n",
    "for i in range(5,20):    \n",
    "    #print(i)\n",
    "    baseline_removal['Window '+str(i)], cut_pts['Window '+str(i)] = moving_average(i,sample1.values)\n",
    "    prepro_data['Window '+str(i)] =  sample1.values[0:len(x)-cut_pts['Window '+str(i)]] - baseline_removal['Window '+str(i)]\n",
    "    fig_pre_p.add_trace(go.Scatter(line= dict(color='#e65400'), x=x[0:len(x)-cut_pts['Window '+str(i)]], y = prepro_data['Window '+str(i)],\n",
    "                                   name = 'Baseline Removal Window '+str(i), showlegend=False, visible = False))\n",
    "    #fig_pre_p.add_trace(go.Scatter(line= dict(color='blue'),    x=sample1.time, y=sample1.values,name='Raw Data',showlegend=False, visible = False))\n",
    "\n",
    "    \n",
    "fig_pre_p.data[5].visible = True\n",
    "\n",
    "\n",
    "steps = []\n",
    "start = 0\n",
    "for t in range(5,20):\n",
    "    step = dict(\n",
    "        method=\"update\",\n",
    "        args=[{\"visible\": [False] * len(fig_pre_p.data)},\n",
    "              {\"title\":  'Baseline Wander Removal      Moving Average Window: '+str(t)}],  # layout attribute\n",
    "    )\n",
    "    \n",
    "    step[\"args\"][0][\"visible\"][start] = True  # Toggle i'th trace to \"visible\"\n",
    "    #step[\"args\"][0][\"visible\"][start+1] = True\n",
    "\n",
    "    \n",
    "    start = start+1\n",
    "    steps.append(step)\n",
    "\n",
    "    \n",
    "sliders = [dict(active=5, currentvalue={\"prefix\": \"n: \"}, pad={\"t\": 50}, steps=steps)]\n",
    "fig_pre_p.update_layout(sliders=sliders);\n",
    "fig_pre_p.update_layout(xaxis = dict(tickmode = 'array', tickvals = sample1.ticks_values, ticktext = sample1.time_format_axis),autosize=False,width=1200,height=600);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7e4828e4-75a6-4eb3-a815-1eaf60fdd786",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig_pre_p.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "02f40133-eef2-41f3-a528-c123c9e37d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparing the Raw data and Pre processed data in subplots\n",
    "\n",
    "i =  10\n",
    "fig3 = make_subplots(\n",
    "    rows=2, cols=1,\n",
    "    subplot_titles=(\"Raw Data\",\" Mean Subtraction Filter \"))\n",
    "\n",
    "fig3.add_trace(go.Scatter(line = dict(color='blue'), x=sample1.time, y=sample1.values,name='Raw Data',showlegend=False),row=1, col=1)\n",
    "fig3.add_trace(go.Scatter(x=x[0:len(x)-cut_pts['Window '+str(i)]], y= prepro_data['Window '+str(i)],\n",
    "                                   name = 'Baseline Removal Window '+str(i), showlegend=False,),row=2, col=1)\n",
    "\n",
    "\n",
    "\n",
    "fig3.update_layout(xaxis_range=[79000,85000], xaxis2_range=[79000,85000],yaxis_range=[-0.6,0.65])\n",
    "fig3.update_layout(xaxis = dict(tickmode = 'array', tickvals = sample1.ticks_values, ticktext = sample1.time_format_axis),autosize=False,width=1200,height=600);\n",
    "fig3.update_layout(xaxis2 = dict(tickmode = 'array', tickvals = sample1.ticks_values, ticktext = sample1.time_format_axis),autosize=False,width=1200,height=600);\n",
    "fig3.update_layout(height=700,width = 1300);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4eb1ef2-3fc2-41d6-8cf5-0a6549ee3f8d",
   "metadata": {},
   "source": [
    "#### A window of 10 is chosen for the mean subtraction, based oon high noise intervals, need too look deeper into this"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da63f0a8-ad47-4cdd-a3e4-5562c446829a",
   "metadata": {},
   "source": [
    "## Pan Tompkins starts here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f82cf286-f3f5-4c4c-982d-22e146ba99ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling Frequency: 250.0Hz\n"
     ]
    }
   ],
   "source": [
    "#time_dif = np.unique(np.diff(sample1.time))/np.timedelta64(1, \"ms\")\n",
    "time_dif = 4/1000\n",
    "sampling_freq = 1/time_dif\n",
    "print('Sampling Frequency: '+str(sampling_freq)+'Hz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ca2b5b2a-00c4-40a9-9f41-78ee3231f6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "lowcut = 3; highcut = 100;\n",
    "nyquist_freq = 0.5 * sampling_freq\n",
    "low = lowcut / nyquist_freq\n",
    "high = highcut / nyquist_freq\n",
    "b, a = butter(2, [low, high], btype=\"band\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6a17f361-b48e-4ea8-85bc-5e241896fffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = lfilter(b, a, prepro_data['Window '+str(6)])\n",
    "x = np.append(sample1.values,np.zeros(len(b)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60245f04-5aa0-408b-af4a-c8837b77e2c9",
   "metadata": {},
   "source": [
    "## Bandpass Filter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2169a124-fd08-41d6-b902-d958960b6917",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfr_r = go.Figure()\\nfs = 250\\ntrans_width = 2.88\\nband = [3, 18]  # Desired pass band, Hz\\nfilter_size= np.arange(100,200,1)\\nedges = [0, band[0] - trans_width, band[0], band[1],\\n         band[1] + trans_width, 0.5*fs]\\ntrans_width = 2.8    # Width of transition from pass to stop, Hz\\ntaps = {}\\n\\nfor i in range(0,len(filter_size)):\\n\\n    numtaps=filter_size[i]      # Size of the FIR filter.\\n\\n    taps[\\'size: \\'+str(filter_size[i])] = signal.remez(numtaps, edges, [0, 1, 0], fs=fs)\\n    w, h = signal.freqz(taps[\\'size: \\'+str(filter_size[i])], [1], worN=2000, fs=fs)\\n    fr_r.add_trace(go.Scatter(x=w,y=20*np.log10(np.abs(h))))\\n    \\nfr_r.data[5].visible = True\\n\\nsteps = []\\nfor tw in range(0,len(filter_size)):\\n    step = dict(\\n        method=\"update\",\\n        args=[{\"visible\": [False] * len(fr_r.data)},\\n              {\"title\": \\'Size of Filter: \\'+ str(filter_size[tw])}],  # layout attribute\\n    )\\n    step[\"args\"][0][\"visible\"][tw] = True  # Toggle i\\'th trace to \"visible\"\\n    steps.append(step)\\n    \\nsliders = [dict(active=5, currentvalue={\"prefix\": \"n: \"}, pad={\"t\": 50}, steps=steps)]\\nfr_r.update_layout(sliders=sliders);\\n\\n\\nfr_r.update_layout(\\n    xaxis = dict(tickmode = \\'array\\',tickvals = [np.log10(1),np.log10(2),np.log10(3),np.log10(4),np.log10(5),np.log10(6),np.log10(7),np.log10(8),np.log10(9),\\n                    np.log10(10),np.log10(15),np.log10(20)],\\n        ticktext = [\\'1\\', \\'2\\', \\'3\\', \\'4\\', \\'5\\', \\'6\\',\\'7\\',\\'8\\',\\'9\\',\\'10\\',\\'15\\',\\'20\\']))\\n\\nfr_r.update_layout(autosize=False,width=1200, height=600, xaxis_title=\"w\", yaxis_title= \\'20log( |H(s)| ) (dB)\\' ,\\n                      font=dict(family=\"Avenir\",size=16,color=\"Black\"))\\n\\nfr_r.update_layout(xaxis_range=[0,150], yaxis_range=[-50,10]);\\n\\n'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "fr_r = go.Figure()\n",
    "fs = 250\n",
    "trans_width = 2.88\n",
    "band = [3, 18]  # Desired pass band, Hz\n",
    "filter_size= np.arange(100,200,1)\n",
    "edges = [0, band[0] - trans_width, band[0], band[1],\n",
    "         band[1] + trans_width, 0.5*fs]\n",
    "trans_width = 2.8    # Width of transition from pass to stop, Hz\n",
    "taps = {}\n",
    "\n",
    "for i in range(0,len(filter_size)):\n",
    "\n",
    "    numtaps=filter_size[i]      # Size of the FIR filter.\n",
    "\n",
    "    taps['size: '+str(filter_size[i])] = signal.remez(numtaps, edges, [0, 1, 0], fs=fs)\n",
    "    w, h = signal.freqz(taps['size: '+str(filter_size[i])], [1], worN=2000, fs=fs)\n",
    "    fr_r.add_trace(go.Scatter(x=w,y=20*np.log10(np.abs(h))))\n",
    "    \n",
    "fr_r.data[5].visible = True\n",
    "\n",
    "steps = []\n",
    "for tw in range(0,len(filter_size)):\n",
    "    step = dict(\n",
    "        method=\"update\",\n",
    "        args=[{\"visible\": [False] * len(fr_r.data)},\n",
    "              {\"title\": 'Size of Filter: '+ str(filter_size[tw])}],  # layout attribute\n",
    "    )\n",
    "    step[\"args\"][0][\"visible\"][tw] = True  # Toggle i'th trace to \"visible\"\n",
    "    steps.append(step)\n",
    "    \n",
    "sliders = [dict(active=5, currentvalue={\"prefix\": \"n: \"}, pad={\"t\": 50}, steps=steps)]\n",
    "fr_r.update_layout(sliders=sliders);\n",
    "\n",
    "\n",
    "fr_r.update_layout(\n",
    "    xaxis = dict(tickmode = 'array',tickvals = [np.log10(1),np.log10(2),np.log10(3),np.log10(4),np.log10(5),np.log10(6),np.log10(7),np.log10(8),np.log10(9),\n",
    "                    np.log10(10),np.log10(15),np.log10(20)],\n",
    "        ticktext = ['1', '2', '3', '4', '5', '6','7','8','9','10','15','20']))\n",
    "\n",
    "fr_r.update_layout(autosize=False,width=1200, height=600, xaxis_title=\"w\", yaxis_title= '20log( |H(s)| ) (dB)' ,\n",
    "                      font=dict(family=\"Avenir\",size=16,color=\"Black\"))\n",
    "\n",
    "fr_r.update_layout(xaxis_range=[0,150], yaxis_range=[-50,10]);\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "88514b7d-4852-46bb-bf3e-739f8aa34014",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig_bp = go.Figure()\n",
    "i = 10\n",
    "bandstop = np.arange(3,10)\n",
    "fs = 250\n",
    "trans_width = 2.88\n",
    "taps = {}\n",
    "numtaps = 152\n",
    "\n",
    "for bs in bandstop:\n",
    "    band = [bs, 100]\n",
    "    edges = [0, band[0] - trans_width, band[0], band[1],\n",
    "             band[1] + trans_width, 0.5*fs]\n",
    "    \n",
    "    taps['Bandstart: '+str(bs)] = signal.remez(numtaps, edges, [0, 1, 0], fs=fs)\n",
    "    \n",
    "    \n",
    "    x = np.append(prepro_data['Window '+str(i)],np.zeros(len(taps['Bandstart: '+str(bs)])))\n",
    "    y_bp = np.zeros(len(prepro_data['Window '+str(i)])+len(taps['Bandstart: '+str(bs)]))\n",
    "\n",
    "    for j in range(0,len(prepro_data['Window '+str(i)])+len(taps['Bandstart: '+str(bs)])): \n",
    "        sum = 0\n",
    "        for k in range(0,len(taps['Bandstart: '+str(bs)])):\n",
    "            sum = (x[j-k]*taps['Bandstart: '+str(bs)][k]) + sum\n",
    "        y_bp[j] = sum\n",
    "\n",
    "    y_bp=np.delete(y_bp,[np.arange(0,int(len(taps['Bandstart: '+str(bs)])/2))])\n",
    "    fig_bp.add_trace(go.Scatter(x=sample1.time, y=y_bp,visible=False))\n",
    "\n",
    "fig_bp.data[5].visible = True\n",
    "\n",
    "steps = []\n",
    "for bps in range(0,len(bandstop)):\n",
    "    step = dict(\n",
    "        method=\"update\",\n",
    "        args=[{\"visible\": [False] * len(fig_bp.data)},\n",
    "              {\"title\": ' Mean Removal Windoow: '+str(i)+'      Bandstart: '+ str(bandstop[bps])}],  # layout attribute\n",
    "    )\n",
    "    step[\"args\"][0][\"visible\"][bps] = True  # Toggle i'th trace to \"visible\"\n",
    "    steps.append(step)\n",
    "    \n",
    "sliders = [dict(active=5, currentvalue={\"prefix\": \"n: \"}, pad={\"t\": 50}, steps=steps)]\n",
    "\n",
    "fig_bp.update_layout(sliders=sliders);\n",
    "fig_bp.update_layout(xaxis = dict(tickmode = 'array', tickvals = sample1.ticks_values, ticktext = sample1.time_format_axis)); \n",
    "fig_bp.update_layout(autosize=False,width=1200, height=600, xaxis_title=\"Time\", yaxis_title= 'Signal' ,\n",
    "                      font=dict(family=\"Avenir\",size=16,color=\"Black\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9b2e7aaa-9d41-43ba-97a9-6ad8ccaa577c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig_bp.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4654610c-2847-4e08-a9f9-abfe0f440d3b",
   "metadata": {},
   "source": [
    "#### Chosen FIR Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a892dc7f-335f-4d63-b9b9-66d6c998b687",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 10\n",
    "x = np.append(prepro_data['Window '+str(i)],np.zeros(len(taps['Bandstart: 3'])))\n",
    "y_bp = np.zeros(len(prepro_data['Window '+str(i)])+len(taps['Bandstart: 3']))\n",
    "\n",
    "for j in range(0,len(prepro_data['Window '+str(i)])+len(taps['Bandstart: 3'])): \n",
    "    sum = 0\n",
    "    for k in range(0,len(taps['Bandstart: 3'])):\n",
    "        sum = (x[j-k]*taps['Bandstart: 3'][k]) + sum\n",
    "    y_bp[j] = sum\n",
    "    \n",
    "y_bp=np.delete(y_bp,[np.arange(0,int(len(taps['Bandstart: 3'])/2))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9d2c14fe-b03b-4dcb-a4ed-e80289a73b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparing the Mean Subtraction and Bandpass in subplots\n",
    "\n",
    "i = 10\n",
    "fig3 = make_subplots(\n",
    "    rows=2, cols=1,\n",
    "    subplot_titles=(\" Mean Subtraction Filter \",\" Bandpass \"))\n",
    "\n",
    "fig3.add_trace(go.Scatter(line=dict(color = 'red'),x=sample1.time, y = y_bp,name='Raw Data',showlegend=False),row=2, col=1)\n",
    "fig3.add_trace(go.Scatter(x=x[0:len(x)-cut_pts['Window '+str(i)]], y= prepro_data['Window '+str(i)],\n",
    "                                   name = 'Baseline Removal Window '+str(i), showlegend=False,),row=1, col=1)\n",
    "\n",
    "\n",
    "\n",
    "fig3.update_layout(xaxis_range=[79000,85000], xaxis2_range=[79000,85000])\n",
    "fig3.update_layout(xaxis = dict(tickmode = 'array', tickvals = sample1.ticks_values, ticktext = sample1.time_format_axis),autosize=False,width=1200,height=600);\n",
    "fig3.update_layout(xaxis2 = dict(tickmode = 'array', tickvals = sample1.ticks_values, ticktext = sample1.time_format_axis),autosize=False,width=1200,height=600)\n",
    "fig3.update_layout(height=700,width = 1300);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "89baf68e-b882-49b9-9bda-182a69d1b3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4829e49d-fba3-4ca8-b8c5-c7307578ed4c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nx0 =np.append(prepro_data['Window '+str(6)],np.zeros(len(b)))\\ndif_y = np.zeros(len(x0))\\n\\nfor i in range(0,len(prepro_data['Window 15'])):\\n    dif_y[i] = (1/a[0]) * (b[0]*x[i] + b[1]*x[i-1] + b[2]*x[i-2] + b[3]*x[i-3] + b[4]*x[i-4] - \\n                       (a[1]*dif_y[i-1] + a[2]*dif_y[i-2] + a[3]*dif_y[i-3] + a[4]*dif_y[i-4]))\\n    \\n\\ndif_y = np.delete(dif_y,np.arange(len(dif_y)-len(b),len(dif_y),1))\\n\""
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Transfer Function for IIR\n",
    "\"\"\"\n",
    "x0 =np.append(prepro_data['Window '+str(6)],np.zeros(len(b)))\n",
    "dif_y = np.zeros(len(x0))\n",
    "\n",
    "for i in range(0,len(prepro_data['Window 15'])):\n",
    "    dif_y[i] = (1/a[0]) * (b[0]*x[i] + b[1]*x[i-1] + b[2]*x[i-2] + b[3]*x[i-3] + b[4]*x[i-4] - \n",
    "                       (a[1]*dif_y[i-1] + a[2]*dif_y[i-2] + a[3]*dif_y[i-3] + a[4]*dif_y[i-4]))\n",
    "    \n",
    "\n",
    "dif_y = np.delete(dif_y,np.arange(len(dif_y)-len(b),len(dif_y),1))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cceb4c-c8a7-46b5-af08-7d1ee9856fc1",
   "metadata": {},
   "source": [
    "### AN FIR FILTER WAS MADE WITH NUMBER OF TAPS 152"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189b6129-cde0-47bc-87ab-86835bfb4d33",
   "metadata": {},
   "source": [
    "#### FROM NOW ON THE DATA HAS BEEN FILTERED WITH AN FIR BANDPASS AND CAN CONTINUE WITH THE REST OF THE STEPS IN PAN TOMPKINS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4e4a6e73-b82e-4d4c-8d06-0fea62361fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = str(10)\n",
    "fig2 = go.Figure()\n",
    "fig2.add_trace(go.Scatter(line= dict(color='blue', width =2),x=sample1.time, y = sample1.values,name='Raw Data',showlegend=True))\n",
    "fig2.add_trace(go.Scatter(line= dict(width = 2),x=sample1.time, y = prepro_data['Window '+i],name='Preprocessed Data',showlegend=True))\n",
    "fig2.add_trace(go.Scatter(line= dict(width = 2),x=sample1.time, y = y_bp,name='FIR Filter',showlegend=True))\n",
    "fig2.update_layout(xaxis_range=[79000,85000],xaxis = dict(tickmode = 'array', tickvals = sample1.ticks_values, ticktext = sample1.time_format_axis), \n",
    "                    autosize=False,width=1200, height=600, title='Band Pass Filtered and Raw Data', \n",
    "                    xaxis_title=\"Time\", yaxis_title= 'Signal');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c5593a45-b306-45fa-af3f-4913ad9d7318",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "da990d22-d5b1-42e7-b455-358f7134fddb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nx =np.append(prepro_data['Window '+str(15)],np.zeros(len(b)))\\ndif_y = np.zeros(len(x))\\n#Difference Equation, if we are to use FIR then the below transfer equations won't be used\\n\\n\\nfor i in range(0,len(prepro_data['Window 15'])):\\n    dif_y[i] = (1/a[0]) * (b[0]*x[i] + b[1]*x[i-1] + b[2]*x[i-2] + b[3]*x[i-3] + b[4]*x[i-4] - \\n                       (a[1]*dif_y[i-1] + a[2]*dif_y[i-2] + a[3]*dif_y[i-3] + a[4]*dif_y[i-4]))\\n    \\ndif_y = np.delete(dif_y,np.arange(len(dif_y)-len(b),len(dif_y),1))\\n\""
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###  Using the difference equation for bandpass filter\n",
    "\"\"\"\n",
    "x =np.append(prepro_data['Window '+str(15)],np.zeros(len(b)))\n",
    "dif_y = np.zeros(len(x))\n",
    "#Difference Equation, if we are to use FIR then the below transfer equations won't be used\n",
    "\n",
    "\n",
    "for i in range(0,len(prepro_data['Window 15'])):\n",
    "    dif_y[i] = (1/a[0]) * (b[0]*x[i] + b[1]*x[i-1] + b[2]*x[i-2] + b[3]*x[i-3] + b[4]*x[i-4] - \n",
    "                       (a[1]*dif_y[i-1] + a[2]*dif_y[i-2] + a[3]*dif_y[i-3] + a[4]*dif_y[i-4]))\n",
    "    \n",
    "dif_y = np.delete(dif_y,np.arange(len(dif_y)-len(b),len(dif_y),1))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c00dda0c-f7a6-48c9-b82a-8b1d53ce20bf",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Transfer Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6041f4e0-8a95-4828-a931-dd1de1f26ca0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# $$H(z) = \\frac{0.6046 - 1.2092z^{-2} + 0.6046z^{-4}}{1 - 0.7554 z^{-1} - 0.8417z^{-2} + 0.239z^{-3} + 0.3721z^{-4}}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "55f61de9-0415-4de2-8da4-6eb1e37f7da8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfig2 = go.Figure()\\nfig2.add_trace(go.Scatter(line= dict(color=\\'red\\', width =2),x=sample1.time, y = dif_y,name=\\'Band Pass Filter\\',showlegend=True))\\nfig2.add_trace(go.Scatter(line= dict(width =2),x=sample1.time,y = y,name=\\'Python Filtered\\',showlegend=True));\\nfig2.add_trace(go.Scatter(line= dict(color=\\'blue\\', width =2),x=sample1.time,y = sample1.values, name=\\'Raw Data\\',showlegend=True));\\nfig2.add_trace(go.Scatter(line= dict(width =2),x=sample1.time,y = y_bp[\\'size: 152\\'], name=\\'Bandpass\\',showlegend=True));\\n\\nfig2.update_layout(xaxis_range=[79000,85000],xaxis = dict(tickmode = \\'array\\', tickvals = sample1.ticks_values, ticktext = sample1.time_format_axis), \\n                    autosize=False,width=1200, height=600, title=\\'Band Pass Filtered and Raw Data\\', \\n                    xaxis_title=\"Time\", yaxis_title= \\'Signal\\');\\n#fig2.show();\\n'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Difference Equation worked just fine! \n",
    "\n",
    "\"\"\"\n",
    "fig2 = go.Figure()\n",
    "fig2.add_trace(go.Scatter(line= dict(color='red', width =2),x=sample1.time, y = dif_y,name='Band Pass Filter',showlegend=True))\n",
    "fig2.add_trace(go.Scatter(line= dict(width =2),x=sample1.time,y = y,name='Python Filtered',showlegend=True));\n",
    "fig2.add_trace(go.Scatter(line= dict(color='blue', width =2),x=sample1.time,y = sample1.values, name='Raw Data',showlegend=True));\n",
    "fig2.add_trace(go.Scatter(line= dict(width =2),x=sample1.time,y = y_bp['size: 152'], name='Bandpass',showlegend=True));\n",
    "\n",
    "fig2.update_layout(xaxis_range=[79000,85000],xaxis = dict(tickmode = 'array', tickvals = sample1.ticks_values, ticktext = sample1.time_format_axis), \n",
    "                    autosize=False,width=1200, height=600, title='Band Pass Filtered and Raw Data', \n",
    "                    xaxis_title=\"Time\", yaxis_title= 'Signal');\n",
    "#fig2.show();\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da39ba1b-262d-4b95-a062-d89787f15a62",
   "metadata": {},
   "source": [
    "### Difference Equation for derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5446da44-b5a5-4b28-b441-aed155de0681",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "#### Difference equation 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e375c05-a109-4733-b7b4-0d3c5bb79581",
   "metadata": {},
   "source": [
    "#### y[n] = (1/8T) (-x[n-2] - 2x[n-1] + 2x[n+1] + x[n+2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d5d7afb4-9ebf-422a-ab59-cd8e0720d884",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### Difference equation 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "69b8ea8c-66dd-4849-b1fa-b86f1defafd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Difference Equation\n",
    "\n",
    "der1 = np.zeros(len(y_bp))\n",
    "der2 = np.zeros(len(y_bp))\n",
    "\n",
    "x = np.append(y_bp,np.zeros(2))\n",
    "x2 = np.append(y_bp,np.zeros(4))\n",
    "\n",
    "for i in range(0,len(y_bp)):\n",
    "    der1[i] = (1/8) * (-(x[i-2]) - (2*x[i-1]) + (2*x[i+1]) + (x[i+2]))\n",
    "    der2[i] = (2*x2[i] + x2[i-1] - x2[i-3] - 2*x2[i-4])/8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4cba611b-928a-4e00-b0e9-78757c6bf519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bandpass and Derivative\n",
    "\n",
    "fig3 = make_subplots(\n",
    "    rows=2, cols=1,\n",
    "    subplot_titles=(\"Bandpass Filter\",'Derivative Filter '))\n",
    "\n",
    "#fig3.add_trace(go.Scatter(line= dict(color='green'),x=sample1.time, y = der1,name='Derivative Filter',showlegend=False),row=1, col=1)\n",
    "\n",
    "fig3.add_trace(go.Scatter(line= dict(color='red'),x=sample1.time, y = y_bp,name='Bandpass',showlegend=False),row=1, col=1)\n",
    "fig3.add_trace(go.Scatter(line= dict(color='Green'),x=sample1.time, y = der1,name='Derivative',showlegend=False),row=2, col=1)\n",
    "#fig3.add_trace(go.Scatter(line= dict(color='Blue'),x=sample1.time, y = der2,name='Derivative',showlegend=False),row=3, col=1)\n",
    "\n",
    "fig3.update_layout(xaxis = dict(tickmode = 'array', tickvals = sample1.ticks_values, ticktext = sample1.time_format_axis),\n",
    "                    xaxis2 = dict(tickmode = 'array', tickvals = sample1.ticks_values, ticktext = sample1.time_format_axis),\n",
    "                    xaxis3 = dict(tickmode = 'array', tickvals = sample1.ticks_values, ticktext = sample1.time_format_axis))\n",
    "\n",
    "#fig3.update_layout(xaxis_range=[0,1000], xaxis2_range=[0,85000])\n",
    "fig3.update_layout(height=750,width = 1300);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9378589-8880-4672-8ec2-40645fa5fab4",
   "metadata": {},
   "source": [
    "### Squaring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7f990f90-61bd-49b4-b700-a63a0d4643f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "squared = (der1) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f658de98-090a-4602-93be-8c0520421574",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Derivative and Squared\n",
    "\n",
    "\n",
    "fig4 = make_subplots(\n",
    "    rows=2, cols=1,\n",
    "    subplot_titles=(\"Derivative Filter     Average Window: 6      Bandstart: 22\",\" Squared        Average Window: 6         Bandstart: 22 \"))\n",
    "\n",
    "#fig4.add_trace(go.Scatter(line= dict(color='orange'),x=sample1.time, y = squared,name='Squared',showlegend=False),row=1, col=1)\n",
    "\n",
    "fig4.add_trace(go.Scatter(line= dict(color='green'),x=sample1.time, y = der1,name='Derivative',showlegend=False),row=1, col=1)\n",
    "fig4.add_trace(go.Scatter(line= dict(color='orange'),x=sample1.time, y = squared,name='Squared',showlegend=False),row=2, col=1)\n",
    "\n",
    "fig4.update_layout(xaxis = dict(tickmode = 'array', tickvals = sample1.ticks_values, ticktext = sample1.time_format_axis),\n",
    "                    xaxis2 = dict(tickmode = 'array', tickvals = sample1.ticks_values, ticktext = sample1.time_format_axis))\n",
    "\n",
    "fig4.update_layout(xaxis_range=[79000,85000], xaxis2_range=[79000,85000], yaxis2_range=[-0.001,0.016])\n",
    "fig4.update_layout(height=700,width = 1300);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba78441-b29d-4852-a461-de575cfcc0b9",
   "metadata": {},
   "source": [
    "## Moving Integration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75671d1b-d6ff-49f7-8bcf-edfcf89b4a32",
   "metadata": {},
   "source": [
    "#### The moving window integration difference equation is given by \n",
    "#### $$y[n] = (x[n-(N-1)] + x[n-(N-2)] + .... + x[n])$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1073446-5365-4ef2-b9e2-b4eb8771d64d",
   "metadata": {},
   "source": [
    "##### The following is the moving integration difference equation implemented through a loop just to test and compare later on with a constructed function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6048bb14-71ac-4df2-8603-f2d35b19de88",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ma = np.zeros(len(squared))\n",
    "y_mi = np.zeros(len(squared))\n",
    "\n",
    "# N = window_length\n",
    "N = 11\n",
    "squared_y = np.append(squared,np.zeros(N-1))\n",
    "for n in range(0,len(y_ma)):\n",
    "    y_ma[n] = (1/N) * (squared_y[n-(N-1)] + squared_y[n-(N-2)] + squared_y[n-(N-3)] + squared_y[n-(N-4)] + squared_y[n-(N-5)] + squared_y[n-(N-6)] + \n",
    "                       squared_y[n-(N-7)] + squared_y[n-(N-8)] + squared_y[n-(N-9)] + squared_y[n-(N-10)] + squared_y[n])\n",
    "    y_mi[n] = (squared_y[n-(N-1)] + squared_y[n-(N-2)] + squared_y[n-(N-3)] + squared_y[n-(N-4)] + squared_y[n-(N-5)] + squared_y[n-(N-6)] + \n",
    "                       squared_y[n-(N-7)] + squared_y[n-(N-8)] + squared_y[n-(N-9)] + squared_y[n-(N-10)] + squared_y[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2acb71e9-82f4-4a92-b27b-ea8e1881ef7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The constructed function\n",
    "prueba = dif_eq_window_integration(squared,11,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4d573c8d-3a31-41eb-b199-ea9f411916d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This just doublechecks that the function works\n",
    "\n",
    "fig5 = go.Figure()\n",
    "\n",
    "fig5.add_trace(go.Scatter(mode = 'lines', line= dict(color='green'),x=sample1.time, y=squared,name='Squared',showlegend=True))\n",
    "fig5.add_trace(go.Scatter(mode = 'lines', line= dict(color='blue',width = 4),x=sample1.time, y=y_ma,name='Moving Window Average',showlegend=True))\n",
    "fig5.add_trace(go.Scatter(mode = 'lines', line= dict(color='red',width = 4),x=sample1.time, y=prueba, name='Prueba',showlegend=True))\n",
    "fig5.add_trace(go.Scatter(mode = 'lines', x=sample1.time, y=y_mi,name='Moving Window Integration',showlegend=True))\n",
    "\n",
    "\n",
    "fig5.update_layout(xaxis_range=[79000,85000],xaxis = dict(tickmode = 'array', tickvals = sample1.ticks_values, ticktext = sample1.time_format_axis), \n",
    "                    autosize=False,width=1250, height=600, title=\"Squared and Moving Window Integration WL: \" + str(N), \n",
    "                    xaxis_title=\"Time\", yaxis_title= 'Signal', font=dict(family=\"Avenir\",size=14,color=\"Black\"));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d83e46-0034-4510-85df-8fa0f3f05a44",
   "metadata": {},
   "source": [
    "## Looking to different window lengths in the window integration difference equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "778d6910-5480-4c9e-8e5d-2aa6bbf6999d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving Window Integration\n",
    "\n",
    "fig6 = go.Figure()\n",
    "\n",
    "y_mw_dict ={}\n",
    "lengths = np.arange(10,35,1)\n",
    "peaks_trial = {}\n",
    "\n",
    "for N in lengths: \n",
    "    y_mw_dict['MW Integration W: '+str(N)] = dif_eq_window_integration(squared,N,False)\n",
    "    #peaks_trial['MWI W peaks: '+str(N)], _ = find_peaks(y_mw_dict['MW Integration W: '+str(N)],distance = 100)\n",
    "    fig6.add_trace(go.Scatter(mode = 'lines', line= dict(color='blue'),x=sample1.time, y=y_mw_dict['MW Integration W: '+str(N)],\n",
    "                               name = 'Differece Equation',showlegend=False, visible =False))\n",
    "    \n",
    "fig6.data[5].visible = True\n",
    "\n",
    "steps = []\n",
    "start = 0\n",
    "for i in range(0,len(lengths)):\n",
    "    step = dict(\n",
    "        method=\"update\",\n",
    "        args=[{\"visible\": [False] * len(fig6.data)},\n",
    "              {\"title\": 'Moving Window Integration           Window Length: ' + str(lengths[i])}],  # layout attribute\n",
    "    )\n",
    "    step[\"args\"][0][\"visible\"][i] = True # Toggle i'th trace to \"visible\"\n",
    "    #step[\"args\"][0][\"visible\"][start + 1] = True # Toggle i'th trace to \"visible\"\n",
    "    #start = start +2\n",
    "\n",
    "    steps.append(step)\n",
    "    \n",
    "sliders = [dict(active=5, currentvalue={\"prefix\": \"n: \"}, pad={\"t\": 50}, steps=steps)]\n",
    "fig6.update_layout(sliders=sliders);\n",
    "fig6.update_layout(xaxis_range=[79000,85000]);\n",
    "fig6.update_layout(xaxis = dict(tickmode = 'array', tickvals = sample1.ticks_values, ticktext = sample1.time_format_axis),autosize=False,width=1200,height=600); \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "adc38639-72ab-423d-aa36-9d04d4f7c315",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig6.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2962e092-dcd0-404d-8190-8fe7a782c118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving Window Integration and Squared THIS IS BASICALLY THE SAME AS THE ABOVE BUT WITH THE SQUARED\n",
    "\n",
    "fig7 = go.Figure()\n",
    "\n",
    "y_mw_dict ={};\n",
    "\n",
    "\n",
    "for N in lengths: \n",
    "    y_mw_dict['MW Integration W: '+str(N)] = dif_eq_window_integration(squared,N,False)\n",
    "    fig7.add_trace(go.Scatter(mode = 'lines', line= dict(color='orange'),x=sample1.time, y=squared,\n",
    "                               name = 'Squared',showlegend=True,visible=False))\n",
    "    fig7.add_trace(go.Scatter(mode = 'lines', line= dict(color='blue',width=3),x=sample1.time, y=y_mw_dict['MW Integration W: '+str(N)],\n",
    "                               name = 'Differece Equation',showlegend=True,visible=False))\n",
    "    \n",
    "fig7.data[5].visible = True\n",
    "\n",
    "steps = []\n",
    "start = 0\n",
    "for i in range(0,len(lengths)):\n",
    "    step = dict(\n",
    "        method=\"update\",\n",
    "        args=[{\"visible\": [False] * len(fig7.data)},\n",
    "              {\"title\": 'Moving Window Integration           Window Length: ' + str(lengths[i])}],  # layout attribute\n",
    "    )\n",
    "    step[\"args\"][0][\"visible\"][start] = True # Toggle i'th trace to \"visible\"\n",
    "    step[\"args\"][0][\"visible\"][start+1] = True # Toggle i'th trace to \"visible\"\n",
    "    start = start + 2\n",
    "    steps.append(step)\n",
    "    \n",
    "sliders = [dict(active=5, currentvalue={\"prefix\": \"n: \"}, pad={\"t\": 50}, steps=steps)]\n",
    "fig7.update_layout(sliders=sliders);\n",
    "fig7.update_layout(xaxis_range=[79000,85000],yaxis_range = [0,0.014]);\n",
    "fig7.update_layout(xaxis = dict(tickmode = 'array', tickvals = sample1.ticks_values, ticktext = sample1.time_format_axis),autosize=False,width=1250,height=650); \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c23b1f2b-dd40-4da3-87b7-bbae548334dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig7.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4ad0476c-7783-4693-8805-1b6825c76be1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Squared and Moving Window Integration\n",
    "\n",
    "fig4 = make_subplots(\n",
    "    rows=2, cols=1,\n",
    "    subplot_titles=(\"Squared\",\" Moving Window Integration \"))\n",
    "\n",
    "#fig4.add_trace(go.Scatter(line= dict(color='orange'),x=sample1.time, y = squared,name='Squared',showlegend=False),row=1, col=1)\n",
    "\n",
    "fig4.add_trace(go.Scatter(line= dict(color='#0a4345'),x=sample1.time, y = y_mw_dict['MW Integration W: 25'],name='MWI',showlegend=False),row=2, col=1)\n",
    "fig4.add_trace(go.Scatter(line= dict(color='orange'),x=sample1.time, y = squared,name='Squared',showlegend=False),row=1, col=1)\n",
    "\n",
    "fig4.update_layout(xaxis = dict(tickmode = 'array', tickvals = sample1.ticks_values, ticktext = sample1.time_format_axis),\n",
    "                    xaxis2 = dict(tickmode = 'array', tickvals = sample1.ticks_values, ticktext = sample1.time_format_axis))\n",
    "\n",
    "fig4.update_layout(xaxis_range=[79000,85000], xaxis2_range=[79000,85000], yaxis_range=[-0.001,0.0155], yaxis2_range=[-0.001,0.085])\n",
    "fig4.update_layout(height=800,width = 1300);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "09c229b7-5f9f-40df-bf29-e9f7420273a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Finding the fiducial point\n",
    "\n",
    "x = sample1.time\n",
    "fiducial_point_dict = {}\n",
    "\n",
    "\n",
    "for length in lengths: \n",
    "    \n",
    "    #In live version we would let 10 peaks go by\n",
    "    test_segments = 3\n",
    "    peak_average, first_peaks = first_peaks_height_av(y_mw_dict['MW Integration W: '+str(length)],test_segments,0.8)\n",
    "    \n",
    "    y =  y_mw_dict['MW Integration W: '+str(length)]\n",
    "    fiducial_point = []\n",
    "    peak = 0\n",
    "    found_p = False\n",
    "    mwi_peak = []\n",
    "    look_for_peaks = True\n",
    "    counter = 0\n",
    "\n",
    "    for i in range(1,len(x)-1):\n",
    "        if look_for_peaks:\n",
    "            #print(i)\n",
    "            #print('found_p: '+str(found_p))    \n",
    "            f_derivative = (y[i+1]-y[i])/(x[i+1]-x[i])\n",
    "\n",
    "            if found_p:\n",
    "                if f_derivative > 0: \n",
    "                    found_p = False\n",
    "                    if (y[i]<(0.9)*peak) : \n",
    "                        found_p = True\n",
    "\n",
    "                if (peak/2>y[i]) :\n",
    "                    fiducial_point = np.append(fiducial_point,i-length)\n",
    "                    mwi_peak = np.append(mwi_peak,y[i])\n",
    "                    found_p = False\n",
    "                    peak = 0\n",
    "                    look_for_peaks = False\n",
    "                    if len(fiducial_point)>test_segments:\n",
    "                        peak_average = np.average(mwi_peak)\n",
    "\n",
    "\n",
    "            else: \n",
    "                b_derivative = (y[i]-y[i-1])/(x[i]-x[i-1])\n",
    "                if (f_derivative < 0) and (b_derivative > 0) and y[i]>0.5*peak_average: \n",
    "                    peak = y[i]\n",
    "                    found_p = True\n",
    "        else: \n",
    "            counter = counter + 1\n",
    "            if counter==45 :\n",
    "                counter = 0 \n",
    "                look_for_peaks = True\n",
    "            \n",
    "\n",
    "    fiducial_point = np.asarray(fiducial_point, dtype = 'int')\n",
    "    fiducial_point_dict['Window Length: '+str(length)] = fiducial_point\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3d02d8d9-d206-46db-b059-1dad303539e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving Window Integration and its peaks\n",
    "\n",
    "fig8 = go.Figure()\n",
    "\n",
    "\n",
    "for N in lengths: \n",
    "    fig8.add_trace(go.Scatter(mode = 'lines', line= dict(color='blue'),x=sample1.time, y=y_mw_dict['MW Integration W: '+str(N)],\n",
    "                               name = 'MWI length: '+str(N),showlegend=False,visible=False))\n",
    "    \n",
    "    fig8.add_trace(go.Scatter(mode = 'markers', marker= dict(color='orange'),x=sample1.time[fiducial_point_dict['Window Length: '+str(N)]],\n",
    "                              y=y_mw_dict['MW Integration W: '+str(N)][fiducial_point_dict['Window Length: '+str(N)]],\n",
    "                               name = 'Peaks',showlegend=False,visible=False))\n",
    "    \n",
    "fig8.data[5].visible = True\n",
    "\n",
    "steps = []\n",
    "start = 0\n",
    "for length in lengths:\n",
    "    step = dict(\n",
    "        method=\"update\",\n",
    "        args=[{\"visible\": [False] * len(fig8.data)},\n",
    "              {\"title\": 'Moving Window Integration           Window Length: ' + str(length) + '         Peaks Found: '+str(len(fiducial_point_dict['Window Length: '+str(length)]))}],  # layout attribute\n",
    "    )\n",
    "    step[\"args\"][0][\"visible\"][start] = True # Toggle i'th trace to \"visible\"\n",
    "    step[\"args\"][0][\"visible\"][start+1] = True # Toggle i'th trace to \"visible\"\n",
    "    start = start + 2\n",
    "    steps.append(step)\n",
    "    \n",
    "sliders = [dict(active=5, currentvalue={\"prefix\": \"n: \"}, pad={\"t\": 50}, steps=steps)]\n",
    "fig8.update_layout(sliders=sliders);\n",
    "fig8.update_layout(xaxis_range=[79000,85000]);\n",
    "fig8.update_layout(xaxis = dict(tickmode = 'array', tickvals = sample1.ticks_values, ticktext = sample1.time_format_axis),autosize=False,width=1200,height=600); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5685eb3f-05a1-4e51-bae6-18bea820180c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig8.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a9ae9f18-d640-4d0c-bdaa-248e56a9b5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The algorithm needs to store maybe 5 peaks to learn whats a good height to be consider a peak in the moving window integration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "edd1fef0-c041-45be-b242-c4752464b2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A very simple strategy is to allow for 3 segments of one second or maybe 0.7 seconds to go by and get the maximum value of each segment in \n",
    "# that way we have a sample of what a maximum looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a10d0c09-7d6b-476f-ad6e-7b2dc110bb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving Window Integration and Raw Peaks\n",
    "spline = 4\n",
    "res = 1000\n",
    "max_x, max_y, peaks_x, peaks_y, interpolated_peak_x, interpolated_peak_y,max_ids = interpolation_spline(fiducial_point_dict['Window Length: 25'], \n",
    "                                                                                               sample1.time, sample1.values, spline, res)\n",
    "i = 6\n",
    "fig4 = make_subplots(\n",
    "    rows=3, cols=1,\n",
    "    subplot_titles=(\"Moving Window Integration\",\" Raw Peaks \", 'Mean Subtraction'))\n",
    "\n",
    "#fig4.add_trace(go.Scatter(line= dict(color='orange'),x=sample1.time, y = squared,name='Squared',showlegend=False),row=1, col=1)\n",
    "\n",
    "fig4.add_trace(go.Scatter(line= dict(color='#0a4345'),x=sample1.time, y = y_mw_dict['MW Integration W: 25'],name='MWI',showlegend=False),row=1, col=1)\n",
    "fig4.add_trace(go.Scatter(mode = 'markers',x=sample1.time[fiducial_point_dict['Window Length: 25']], \n",
    "                          y = y_mw_dict['MW Integration W: 25'][fiducial_point_dict['Window Length: 25']],\n",
    "                          name='MWI',showlegend=False),row=1, col=1)\n",
    "fig4.add_trace(go.Scatter(x=x[0:len(x)-cut_pts['Window '+str(i)]], y= prepro_data['Window '+str(i)],\n",
    "                                   name = 'Baseline Removal Window '+str(i), showlegend=False,),row=3, col=1)\n",
    "\n",
    "\n",
    "fig4.add_trace(go.Scatter(line= dict(color='blue'),x=sample1.time, y = sample1.values,name='Peaks in MWI',showlegend=False),row=2, col=1)\n",
    "fig4.add_trace(go.Scatter(mode='markers',marker=dict(color='red'), x=peaks_x, y = peaks_y, name='Peaks In Raw Data',showlegend=False),row=2, col=1)\n",
    "\n",
    "fig4.update_layout(xaxis = dict(tickmode = 'array', tickvals = sample1.ticks_values, ticktext = sample1.time_format_axis),\n",
    "                    xaxis2 = dict(tickmode = 'array', tickvals = sample1.ticks_values, ticktext = sample1.time_format_axis),\n",
    "                    xaxis3 = dict(tickmode = 'array', tickvals = sample1.ticks_values, ticktext = sample1.time_format_axis))\n",
    "\n",
    "fig4.update_layout(xaxis_range=[79000,85000], xaxis2_range=[79000,85000],xaxis3_range=[79000,85000], yaxis_range=[-0.001,0.085], yaxis2_range=[-0.5,0.68])\n",
    "fig4.update_layout(height=1200,width = 1300);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5db523-74b3-4c74-aa62-51e016d8cc78",
   "metadata": {},
   "source": [
    "# Analytical Solution for peaks in interpolation method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a2d27091-ce5a-4bb3-be10-72a54123e13f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nf = go.Figure()\\n\\nf.add_trace(go.Scatter(line = dict(color = \\'blue\\'), x=sample1.time,y=sample1.values, name=\\'Raw Data\\'))\\nf.add_trace(go.Scatter(mode=\\'markers\\',marker=dict(color = \\'#26E31A\\', size = 8), x = max_x,y=max_y,name=\\'Analytical Solution\\'))\\nf.add_trace(go.Scatter(mode=\\'markers\\',marker=dict(color = \\'green\\' ,size = 6), x = peaks_x, y=peaks_y, name=\\' Collected Peak Interpolation \\'+str(res)+\\'Hz\\'))\\n\\nfor h in range(0,len(max_x)):\\n    f.add_trace(go.Scatter(mode=\\'lines\\',line=dict(color=\\'#FE4384\\'), x = interpolated_peak_x[\\'peak: \\'+str(h)], \\n                               y = interpolated_peak_y[\\'peak: \\'+str(h)], showlegend= False))\\n\\n\\nf.update_layout(xaxis = dict(tickmode = \\'array\\', tickvals = sample1.ticks_values, ticktext = sample1.time_format_axis),autosize=False,\\n                     width=1250,height=600)\\n\\nf.update_layout(title=\"Pan Tompkins Interpolated Peaks       Moving Average Window = 14 samples     Analytical Solution \", \\n                         xaxis_title=\"Time\", yaxis_title= \\'Signal\\', font=dict(family=\"Avenir\",size=16,color=\"Black\"));\\n                         '"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "f = go.Figure()\n",
    "\n",
    "f.add_trace(go.Scatter(line = dict(color = 'blue'), x=sample1.time,y=sample1.values, name='Raw Data'))\n",
    "f.add_trace(go.Scatter(mode='markers',marker=dict(color = '#26E31A', size = 8), x = max_x,y=max_y,name='Analytical Solution'))\n",
    "f.add_trace(go.Scatter(mode='markers',marker=dict(color = 'green' ,size = 6), x = peaks_x, y=peaks_y, name=' Collected Peak Interpolation '+str(res)+'Hz'))\n",
    "\n",
    "for h in range(0,len(max_x)):\n",
    "    f.add_trace(go.Scatter(mode='lines',line=dict(color='#FE4384'), x = interpolated_peak_x['peak: '+str(h)], \n",
    "                               y = interpolated_peak_y['peak: '+str(h)], showlegend= False))\n",
    "\n",
    "\n",
    "f.update_layout(xaxis = dict(tickmode = 'array', tickvals = sample1.ticks_values, ticktext = sample1.time_format_axis),autosize=False,\n",
    "                     width=1250,height=600)\n",
    "\n",
    "f.update_layout(title=\"Pan Tompkins Interpolated Peaks       Moving Average Window = 14 samples     Analytical Solution \", \n",
    "                         xaxis_title=\"Time\", yaxis_title= 'Signal', font=dict(family=\"Avenir\",size=16,color=\"Black\"));\n",
    "                         \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "41509f73-a478-4909-bfa2-d129fac2000b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#f.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e0e8e1dd-7eef-4198-b53c-7c791c623988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw Peaks and Third Order Spline Peaks \n",
    "max_x, max_y, peaks_x, peaks_y, interpolated_peak_x, interpolated_peak_y, max_idxs = interpolation_spline(fiducial_point_dict['Window Length: 25'], \n",
    "                                                                                               sample1.time, sample1.values, spline, res)\n",
    "\n",
    "#fig4 = make_subplots(\n",
    "#    rows=2, cols=1,\n",
    "#    subplot_titles=(\"Raw Peaks\",\" Analytical Solution \"))\n",
    "\n",
    "fig4 = go.Figure()\n",
    "\n",
    "#fig4.add_trace(go.Scatter(line= dict(color='orange'),x=sample1.time, y = squared,name='Squared',showlegend=False),row=1, col=1)\n",
    "#fig4.add_trace(go.Scatter(line= dict(color='blue'), x=sample1.time, y = sample1.values,name='Peaks in Raw Data',showlegend=False),row=2, col=1)\n",
    "#fig4.add_trace(go.Scatter(mode='markers',marker=dict(color='red', size=9), x= sample1.time[max_idxs], y = sample1.values[max_idxs], name='Peaks In Raw Data',showlegend=False),row=2, col=1)\n",
    "\n",
    "fig4.add_trace(go.Scatter(line= dict(color='blue'), x=sample1.time, y = sample1.values,name='Peaks in MWI',showlegend=False))\n",
    "\n",
    "\n",
    "for j in range(0,len(interpolated_peak_x)):\n",
    "    fig4.add_trace(go.Scatter(line= dict(color='green'), x=interpolated_peak_x['peak: '+str(j)], y = interpolated_peak_y['peak: '+str(j)], name='Peaks in MWI',showlegend=False))\n",
    "\n",
    "    \n",
    "fig4.add_trace(go.Scatter(mode='markers',marker=dict(color='red', size=9), x=max_x, y = max_y, name='Peaks In Raw Data',showlegend=False))\n",
    "fig4.add_trace(go.Scatter(mode='markers',marker=dict(color='orange', size=7), x=sample1.time[max_idxs], y = sample1.values[max_idxs], name='Raw Peaks',showlegend=False))\n",
    "\n",
    "fig4.update_layout(xaxis = dict(tickmode = 'array', tickvals = sample1.ticks_values, ticktext = sample1.time_format_axis),\n",
    "                    xaxis2 = dict(tickmode = 'array', tickvals = sample1.ticks_values, ticktext = sample1.time_format_axis));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a16a6056-1aee-4975-a356-69245d7591c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig4.update_layout(xaxis_range=[79000,85000], yaxis_range=[-0.5,0.68])\n",
    "fig4.update_layout(height=600,width = 1300);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5503b0a-e42f-4937-8767-cbfa494fe012",
   "metadata": {},
   "source": [
    "#### Time Differences with different amount of control points and re sampling frequency "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8002ceb-f694-42d8-819c-768cd3248e3d",
   "metadata": {},
   "source": [
    "## Interpolation with different window lenghts in the moving window integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5dcc9537-4d99-4d69-8c14-a1aa5ff0c638",
   "metadata": {},
   "outputs": [],
   "source": [
    "interp = go.Figure()\n",
    "spline = 4\n",
    "max_x_dict= {};max_y_dict= {}\n",
    "res = 1000 \n",
    "\n",
    "\n",
    "for N in lengths: \n",
    "    \n",
    "    max_x_dict['Window: '+str(N)], max_y_dict['Window: '+str(N)], peaks_x, peaks_y, interpolated_peak_x, interpolated_peak_y, max_idx = interpolation_spline(\n",
    "        fiducial_point_dict['Window Length: '+str(N)], sample1.time, sample1.values, spline, res)\n",
    "    \n",
    "    interp.add_trace(go.Scatter(mode = 'lines', line= dict(color='blue'),x=sample1.time, y=sample1.values,showlegend=False,visible=False))\n",
    "    interp.add_trace(go.Scatter(mode = 'markers', x= max_x_dict['Window: '+str(N)], y=max_y_dict['Window: '+str(N)],\n",
    "                               name = 'Peaks ',showlegend=False,visible=False))\n",
    "    \n",
    "\n",
    "    \n",
    "interp.data[5].visible = True\n",
    "\n",
    "steps = []\n",
    "start = 0\n",
    "for length in lengths:\n",
    "    step = dict(\n",
    "        method=\"update\",\n",
    "        args=[{\"visible\": [False] * len(interp.data)},\n",
    "              {\"title\": 'Peaks Found           Window Length: ' + str(length)}],  # layout attribute\n",
    "    )\n",
    "    step[\"args\"][0][\"visible\"][start] = True # Toggle i'th trace to \"visible\"\n",
    "    step[\"args\"][0][\"visible\"][start+1] = True # Toggle i'th trace to \"visible\"\n",
    "    start = start + 2\n",
    "    steps.append(step)\n",
    "    \n",
    "sliders = [dict(active=5, currentvalue={\"prefix\": \"n: \"}, pad={\"t\": 50}, steps=steps)]\n",
    "interp.update_layout(sliders=sliders);\n",
    "#interp.update_layout(xaxis_range=[79000,85000]);\n",
    "interp.update_layout(xaxis = dict(tickmode = 'array', tickvals = sample1.ticks_values, ticktext = sample1.time_format_axis),autosize=False,width=1300,height=600);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3fc4a5bc-23dd-4be1-ba38-011ad7f9e829",
   "metadata": {},
   "outputs": [],
   "source": [
    "#interp.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd88fb7-8dd7-479c-a634-38cd744f2b09",
   "metadata": {},
   "source": [
    "## Mean Subtraction and wavelet transform "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4501dcd-c4e3-4caf-9749-485b181c9948",
   "metadata": {},
   "source": [
    "### We do the following just to check how good are the PT results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2ed4895c-0b4e-4b62-9ab6-33f7aa50cc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = average_filter(15,sample1.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cba6325d-ddf7-4241-a82f-6962c0443d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_peaks,_ = find_peaks(sample1.values-mean,distance=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2709f70a-8886-49a2-af9a-4901379a19b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig9 = go.Figure()\n",
    "\n",
    "fig9.add_trace(go.Scatter(mode = 'lines', line= dict(color='blue'),x=sample1.time, y=sample1.values,name='Raw Data',showlegend=True))\n",
    "#fig9.add_trace(go.Scatter(mode = 'lines', x=sample1.time, y=mean, name = 'Mean Average', showlegend = True))\n",
    "fig9.add_trace(go.Scatter(mode = 'lines', x=sample1.time, y=sample1.values-mean, name = 'Mean Subtraction', showlegend = True))\n",
    "fig9.update_layout(xaxis_range=[79000,85000]);\n",
    "fig9.update_layout(xaxis = dict(tickmode = 'array', tickvals = sample1.ticks_values, ticktext = sample1.time_format_axis),autosize=False,width=1200,height=600);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3dba5b-514e-4d55-9702-f5a65d95331b",
   "metadata": {},
   "source": [
    "### Interpolating with the mean subtraction peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "076360e9-0ffb-4c06-91a2-23a4588cc335",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18466/270883639.py:124: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in sqrt\n",
      "\n",
      "/tmp/ipykernel_18466/270883639.py:125: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in sqrt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spline=4;\n",
    "res = 5000\n",
    "max_x_w, max_y_w, peaks_x_w, peaks_y_w, interpolated_peak_x_w, interpolated_peak_y_w,max_idxs_m = interpolation_spline(mean_peaks, sample1.time, sample1.values, 4, res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5fd23c13-c0c1-422f-8470-796739c877ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "amount_of_peaks = len(max_x_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "cb5c27fa-41e5-4b02-a201-0958a34d9077",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Comparing peaks of PT with window N"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99d675e-7ba9-422c-a2a7-b40ec042bdf0",
   "metadata": {},
   "source": [
    "### Comparing Pan Tompkins and mean average substraction + Wavelet Transform with all windows in Moving Window Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "48e8c3ec-368e-491b-aedd-0a7613c5ec35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visually missing peaks\n",
    "\n",
    "fig10 = go.Figure()\n",
    "missing_mean_p_dict ={};  missing_pt_p_dict={};\n",
    "spline=4;\n",
    "res = 5000\n",
    "\n",
    "\n",
    "for N in lengths: \n",
    "    #print(N)\n",
    "    missing_pt_p, missing_mean_p = find_missing_peaks(max_x_dict['Window: '+str(N)], max_x_w, True)\n",
    "    missing_pt_p_dict['window_length_'+str(N)] = missing_pt_p\n",
    "    missing_mean_p_dict['window_length_'+str(N)] = missing_mean_p\n",
    "    \n",
    "    fig10.add_trace(go.Scatter(line= dict(color='blue'),x=sample1.time, y=sample1.values,name='Raw Data',showlegend=True, visible = False))\n",
    "    \n",
    "\n",
    "    fig10.add_trace(go.Scatter(mode='markers',marker=dict(size=12),x=max_x_w, y= max_y_w, name = 'Mean Peaks', \n",
    "                               showlegend=True, visible = False))\n",
    "    fig10.add_trace(go.Scatter(mode='markers',marker=dict(size=10,color='#21B626'), x = max_x_dict['Window: '+str(N)], \n",
    "                              y = max_y_dict['Window: '+str(N)], name = 'P.T. Peaks WL: '+str(N),showlegend=True, \n",
    "                              visible = False))\n",
    "    fig10.add_trace(go.Scatter(mode='markers',marker=dict(size=7,color='orange'), x = max_x_dict['Window: '+str(N)][missing_mean_p], \n",
    "                               y= max_y_dict['Window: '+str(N)][missing_mean_p], name = 'Missing Mean Peaks', showlegend=True, visible = False))\n",
    "    \n",
    "    fig10.add_trace(go.Scatter(mode='markers',marker=dict(size=7,color='#00FCF5'),x = max_x_w[missing_pt_p] , y= max_y_w[missing_pt_p], \n",
    "                              name = 'Missing P.T. Peaks', showlegend=True, visible = False))\n",
    "\n",
    "fig10.data[5].visible = True\n",
    "\n",
    "steps = []\n",
    "start = 0\n",
    "for i in range(0,len(lengths)):\n",
    "    step = dict(\n",
    "        method=\"update\",\n",
    "        args=[{\"visible\": [False] * len(fig10.data)},\n",
    "              {\"title\": \"Peaks identified with PT window length \"+str(lengths[i])+ '   Amount of Mean + Wavelet Missing Peaks: '+\n",
    "               str(len(missing_mean_p_dict['window_length_'+str(lengths[i])])) +'   Amount of PT Missing Peaks: '+ \n",
    "               str(len(missing_pt_p_dict['window_length_'+str(lengths[i])]))}],  # layout attribute\n",
    "    )\n",
    "    step[\"args\"][0][\"visible\"][start] = True  # Toggle i'th trace to \"visible\"\n",
    "    step[\"args\"][0][\"visible\"][start+1] = True\n",
    "    step[\"args\"][0][\"visible\"][start+2] = True\n",
    "    step[\"args\"][0][\"visible\"][start+3] = True\n",
    "    step[\"args\"][0][\"visible\"][start+4] = True\n",
    "    \n",
    "    start = start+5\n",
    "    steps.append(step)\n",
    "    \n",
    "sliders = [dict(active=5, currentvalue={\"prefix\": \"n: \"}, pad={\"t\": 50}, steps=steps)]\n",
    "fig10.update_layout(sliders=sliders);\n",
    "fig10.update_layout(xaxis_range=[79000,85000]);\n",
    "fig10.update_layout(xaxis = dict(tickmode = 'array', tickvals = sample1.ticks_values, ticktext = sample1.time_format_axis),autosize=False,width=1200,height=600); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "296daaca-8e52-4f3e-9732-106369deacc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig10.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102ca022-2e15-479d-aae1-5627567b3e1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a38b93-9af2-4b8a-b456-613d2f249f13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a83036-a5b5-4ba2-b25f-39489dee1b3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5905912f-69cc-4886-a3ad-b3cfe5dec5bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8c2837-db4b-4e79-b702-8b0c85c6d844",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619eb581-34c1-4837-b460-638d5a21bfc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a29207-ace4-4c09-ad06-56695b58c310",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5861fb10-11ca-4bde-8a9a-b0d7d760d2cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679d19c4-9809-470c-9f24-3e9903ac1fd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cf29da-7894-4770-82ba-24da442ce41a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
