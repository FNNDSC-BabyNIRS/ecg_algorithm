{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "290aa860-d2a1-492d-82ec-2d9d127c735e",
   "metadata": {},
   "source": [
    "# Document's Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35d6c0c-3f2a-405d-8553-ef34b88ec6e6",
   "metadata": {},
   "source": [
    "#### · Display raw data from cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb031946-3161-493e-9ec1-04a4741f9e49",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### · Display raw data and located peaks recorded in cluster "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fc7aa9-0dc4-4215-9abf-097d9c171732",
   "metadata": {},
   "source": [
    "#### · Find peaks of recorded raw data with the most updated version of the algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d8be0e4-fdde-4314-81b1-347a2738249e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b991332-290e-4327-83ab-27b2d45b062a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install pymongo==3.13.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f41072d9-9310-4bd7-a3c8-3dbdd8295ee4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1be889b9-72ff-482f-ada7-345a782889d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "my_name = 'braulio.ramirez'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf36577a-f81f-42b0-a956-ec62464acdc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger('jhub')\n",
    "hostname = 'mongos.mongo.svc.cluster.local:27017'\n",
    "pemkeyfile = '/etc/mongo/jhub-keypem.pem'\n",
    "sslca = '/etc/mongo/root-ca.pem'\n",
    "\n",
    "nirscloud_util_meta.init(logger, 'meta', hostname=hostname, ssl=True, cert=pemkeyfile, ca=sslca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "784166a8-3bb9-4462-bdec-d9255df1654c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-07 20:27:38 [INFO ] cfg#_init_hdfs_kinit@79: after hdfs_kinit: the_stdout: b'' the_stderr: b''\n",
      "2023-07-07 20:27:38 [INFO ] client#__init__@192: Instantiated <KerberosClient(url='https://hdfs2.babynirs.org:9870;https://hdfs1.babynirs.org:9870;https://hdfs4.babynirs.org:9870')>.\n"
     ]
    }
   ],
   "source": [
    "spark_kerberos_principal = my_name + '@BABYNIRS.ORG'\n",
    "\n",
    "params = {\n",
    "    'spark_kerberos_principal': spark_kerberos_principal,\n",
    "}\n",
    "nirscloud_util_hdfs.init('/etc/jhub/conf/production.ini', params=params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9682083-9c01-4a9d-bc69-34bb8224669e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Pulling the recorded peaks from the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "829c37dc-48bc-4c72-a51f-47f6488b4a4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hdfs_path = '_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5848ff80-2731-4aff-b3bd-0e26d800f5ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kafka_topics = 'nk_rpeak2_NICU'\n",
    "hdfs_prefix = '/kafka/topics/%s'% (kafka_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9443025f-cfe8-4370-879b-797b1a25bf86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _get_df(hdfs_path, the_id):\n",
    "    hdfs_path = hdfs_path\n",
    "    full_path = nirscloud_util_hdfs.full_path(hdfs_prefix, hdfs_path)\n",
    "    err, df = nirscloud_util_hdfs.from_hdfs_path(full_path)\n",
    "    print(err, df)\n",
    "    is_valid = df['id'] == the_id\n",
    "    df = df[is_valid]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbc7b90a-c015-4b49-9375-b1d854cc8744",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-07 20:27:41 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-07 20:27:42 [INFO ] client#status@320: Fetching status for '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929'.\n",
      "2023-07-07 20:27:43 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-07 20:27:45 [INFO ] client#status@320: Fetching status for '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929'.\n",
      "2023-07-07 20:27:45 [INFO ] client#list@1123: Listing '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929'.\n",
      "2023-07-07 20:27:45 [INFO ] client#list@1123: Listing '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929'.\n",
      "2023-07-07 20:27:45 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-07 20:27:45 [INFO ] client#status@320: Fetching status for '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929/part-00000-3dc1ad61-1e54-40f7-bf0c-9dd31613338c.c000.snappy.parquet'.\n",
      "2023-07-07 20:27:45 [INFO ] client#read@731: Reading file '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929/part-00000-3dc1ad61-1e54-40f7-bf0c-9dd31613338c.c000.snappy.parquet'.\n",
      "2023-07-07 20:27:50 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-07 20:27:52 [INFO ] client#status@320: Fetching status for '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929/part-00000-a7de3d7b-e862-44e6-92e4-3c5f614da7c3.c000.snappy.parquet'.\n",
      "2023-07-07 20:27:52 [INFO ] client#read@731: Reading file '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929/part-00000-a7de3d7b-e862-44e6-92e4-3c5f614da7c3.c000.snappy.parquet'.\n",
      "2023-07-07 20:27:58 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-07 20:27:58 [INFO ] client#status@320: Fetching status for '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929/part-00001-5c9b6e80-d106-4e98-8785-30fac20ce5d9.c000.snappy.parquet'.\n",
      "2023-07-07 20:28:00 [INFO ] client#read@731: Reading file '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929/part-00001-5c9b6e80-d106-4e98-8785-30fac20ce5d9.c000.snappy.parquet'.\n",
      "2023-07-07 20:28:06 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-07 20:28:07 [INFO ] client#status@320: Fetching status for '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929/part-00001-7d8f0b76-fb44-42de-b9b2-c872825e306e.c000.snappy.parquet'.\n",
      "2023-07-07 20:28:08 [INFO ] client#read@731: Reading file '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929/part-00001-7d8f0b76-fb44-42de-b9b2-c872825e306e.c000.snappy.parquet'.\n",
      "2023-07-07 20:28:13 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-07 20:28:14 [INFO ] client#status@320: Fetching status for '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929/part-00001-ffd4be5c-52ca-4aa1-a4e7-ae7835c7b982.c000.snappy.parquet'.\n",
      "2023-07-07 20:28:14 [INFO ] client#read@731: Reading file '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929/part-00001-ffd4be5c-52ca-4aa1-a4e7-ae7835c7b982.c000.snappy.parquet'.\n",
      "2023-07-07 20:28:16 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-07 20:28:18 [INFO ] client#status@320: Fetching status for '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929/part-00002-b1b22d74-6344-4835-a54d-e4f13c127cc5.c000.snappy.parquet'.\n",
      "2023-07-07 20:28:18 [INFO ] client#read@731: Reading file '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929/part-00002-b1b22d74-6344-4835-a54d-e4f13c127cc5.c000.snappy.parquet'.\n",
      "2023-07-07 20:28:20 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-07 20:28:20 [INFO ] client#status@320: Fetching status for '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929/part-00002-d984a888-fd97-424c-ad25-24edaf49eb1f.c000.snappy.parquet'.\n",
      "2023-07-07 20:28:20 [INFO ] client#read@731: Reading file '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929/part-00002-d984a888-fd97-424c-ad25-24edaf49eb1f.c000.snappy.parquet'.\n",
      "2023-07-07 20:28:21 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-07 20:28:22 [INFO ] client#status@320: Fetching status for '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929/part-00003-a9d4f8c2-0090-480d-9297-dbda0f436f70.c000.snappy.parquet'.\n",
      "2023-07-07 20:28:22 [INFO ] client#read@731: Reading file '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929/part-00003-a9d4f8c2-0090-480d-9297-dbda0f436f70.c000.snappy.parquet'.\n",
      "2023-07-07 20:28:25 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-07 20:28:25 [INFO ] client#status@320: Fetching status for '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929/part-00003-f3cdcf06-7be1-43a9-a32a-c6e9decbf73d.c000.snappy.parquet'.\n",
      "2023-07-07 20:28:25 [INFO ] client#read@731: Reading file '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929/part-00003-f3cdcf06-7be1-43a9-a32a-c6e9decbf73d.c000.snappy.parquet'.\n",
      "2023-07-07 20:28:27 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-07 20:28:28 [INFO ] client#status@320: Fetching status for '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929/part-00004-17d15225-8719-4953-ad45-73ed1dd42460.c000.snappy.parquet'.\n",
      "2023-07-07 20:28:28 [INFO ] client#read@731: Reading file '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929/part-00004-17d15225-8719-4953-ad45-73ed1dd42460.c000.snappy.parquet'.\n",
      "2023-07-07 20:28:29 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-07 20:28:29 [INFO ] client#status@320: Fetching status for '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929/part-00004-b112fd52-76d1-4ffd-b27c-fa89fb2c521d.c000.snappy.parquet'.\n",
      "2023-07-07 20:28:29 [INFO ] client#read@731: Reading file '/kafka/topics/nk_rpeak2_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929/part-00004-b112fd52-76d1-4ffd-b27c-fa89fb2c521d.c000.snappy.parquet'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None       id             start_ns          rec_nano_ts       val      ver  \\\n",
      "0     II  1686372038314000000  1686372039283320820  1.149853  v0.0.23   \n",
      "1     II  1686372038826000000  1686372039623391041  0.070611  v0.0.23   \n",
      "2     II  1686372038826000000  1686372039963980267  0.471633  v0.0.23   \n",
      "3     II  1686372039338000000  1686372040304866902  0.387760  v0.0.23   \n",
      "4     II  1686372039850000000  1686372040645622712  0.322574  v0.0.23   \n",
      "...   ..                  ...                  ...       ...      ...   \n",
      "3476  II  1686373175978000000  1686373176977949007 -0.491993  v0.0.23   \n",
      "3477  II  1686373176490000000  1686373177586859349  0.641429  v0.0.23   \n",
      "3478  II  1686373177002000000  1686373178182592895  0.716261  v0.0.23   \n",
      "3479  II  1686373177514000000  1686373178621707140  0.550078  v0.0.23   \n",
      "3480  II  1686373178026000000  1686373179078254610  2.296289  v0.0.23   \n",
      "\n",
      "     _device_id  _bed_id   _the_date _hr _patient_id  \n",
      "0       Procyon  HA11-01  2023-06-10  00     5984929  \n",
      "1       Procyon  HA11-01  2023-06-10  00     5984929  \n",
      "2       Procyon  HA11-01  2023-06-10  00     5984929  \n",
      "3       Procyon  HA11-01  2023-06-10  00     5984929  \n",
      "4       Procyon  HA11-01  2023-06-10  00     5984929  \n",
      "...         ...      ...         ...  ..         ...  \n",
      "3476    Procyon  HA11-01  2023-06-10  00     5984929  \n",
      "3477    Procyon  HA11-01  2023-06-10  00     5984929  \n",
      "3478    Procyon  HA11-01  2023-06-10  00     5984929  \n",
      "3479    Procyon  HA11-01  2023-06-10  00     5984929  \n",
      "3480    Procyon  HA11-01  2023-06-10  00     5984929  \n",
      "\n",
      "[3481 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "df_II_peaks = _get_df(hdfs_path, 'II')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a745a74-9e1b-4c14-a126-7c116801485d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_II_peaks.sort_values(by=['rec_nano_ts'], inplace=True)\n",
    "df_II_peaks.reset_index(drop=True, inplace=True)\n",
    "df_II_peaks['shift_rec_nano_ts'] = df_II_peaks['rec_nano_ts'].shift(-1)\n",
    "df_II_peaks['dif_rec_nano_ts'] = df_II_peaks['shift_rec_nano_ts'] - df_II_peaks['rec_nano_ts']\n",
    "df_II_peaks;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5bc05c0-5f80-49c0-82f5-954c40710c6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "values_p = np.asarray(df_II_peaks['val'].to_numpy())\n",
    "raw_time_p = np.asarray(df_II_peaks['rec_nano_ts'].to_numpy(), dtype = 'int')\n",
    "time_p = [np.datetime64(int(t),'ns') for t in raw_time_p]\n",
    "time_pks = np.array([(pd.Timestamp(t).hour*60*60*1000) + (pd.Timestamp(t).minute*60*1000) + (pd.Timestamp(t).second*1000) + (pd.Timestamp(t).microsecond/1000) for t in time_p]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd620ff-217c-4393-a6f2-ad9e9d181d42",
   "metadata": {},
   "source": [
    "## Pulling continuous signal data from cluster "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "470ad255-978b-484c-b696-300861add7b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kafka_topics_cs = 'nk_waves_NICU'\n",
    "hdfs_prefix_cs = '/nirscloud/agg_by_hr3/%s'% (kafka_topics_cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3983926-1996-4999-b07f-25754dcae52b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _get_df_cs(hdfs_path, the_id):\n",
    "    hdfs_path = hdfs_path + '/id=%s' % (the_id)\n",
    "    full_path = nirscloud_util_hdfs.full_path(hdfs_prefix_cs, hdfs_path)\n",
    "    err, df = nirscloud_util_hdfs.from_hdfs_path(full_path)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14e3758e-2104-470b-b11a-52933a350eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time series need to be concatenated accoording to the amount of time that is going to be analyzed "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ae3443-dbf8-4b7b-af4f-29c8c2d0e749",
   "metadata": {},
   "source": [
    "# Getting a sample from raw data in cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912921c2-2cb5-4caa-ad46-ca4c9fa981ec",
   "metadata": {},
   "source": [
    "##### When getting a sample the first thing to be considered is the amount of time, and this is determined by the stats that are to be done afterwards.\n",
    "##### We cacn think in terms of how many windows do we want to analyze or how much time, the length of the window and their overlap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd2db7a7-4cf1-4c76-b05e-fd6bea63e9d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time length can be in intervals of 15 minutes starting from 30\n",
      "\n",
      "You can either choose the amount of windows or the total amount of time\n"
     ]
    }
   ],
   "source": [
    "# The total time of the interval will be defined by the amount of windows one chooses, the overlap and the length of the windows.\n",
    "time_wind_length = 30; overlap_window = 0.5; \n",
    "print('Total time length can be in intervals of ' +str(int(time_wind_length*overlap_window))+ ' minutes starting from '+str(time_wind_length))\n",
    "print('')\n",
    "print('You can either choose the amount of windows or the total amount of time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ce493a0-3794-4b60-ba07-cfce5602437f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of time is 180 minutes and the amount of windows is 11\n"
     ]
    }
   ],
   "source": [
    "#In this block you can enter the total amount of time to analyze or the amount of windows\n",
    "\n",
    "by_time = True; total_time = 180; windows = 12\n",
    "\n",
    "\n",
    "if by_time: \n",
    "    by_windows = False\n",
    "else: by_windows = True\n",
    "\n",
    "if by_time: \n",
    "    total_time = 180\n",
    "    if total_time%15 != 0: \n",
    "        print('The amount of time entered is not divisible by '+str(time_wind_length*overlap_window))\n",
    "    windows = int(total_time/(time_wind_length*overlap_window)) - 1 \n",
    "    print('The amount of time is '+str(int(total_time))+' minutes and the amount of windows is '+str(windows))\n",
    "\n",
    "    \n",
    "if by_windows: \n",
    "    windows = 12\n",
    "    total_time = (1-overlap_window)*time_wind_length*(windows) + 15\n",
    "    print('The amount of time is '+str(int(total_time))+' minutes and the amount of windows is '+str(windows))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "590fcac4-f843-4072-909d-1ebdc9cf71ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This line is important because it establishes what will be the first hour \n",
    "first_hour = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd3b28e2-61be-42c1-9280-33f42f0399f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-07 20:28:38 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-07 20:28:38 [INFO ] client#status@320: Fetching status for '/nirscloud/agg_by_hr3/nk_waves_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929/id=MDC_ECG_ELEC_POTL_II'.\n",
      "2023-07-07 20:28:38 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-07 20:28:38 [INFO ] client#status@320: Fetching status for '/nirscloud/agg_by_hr3/nk_waves_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929/id=MDC_ECG_ELEC_POTL_II'.\n",
      "2023-07-07 20:28:38 [INFO ] client#list@1123: Listing '/nirscloud/agg_by_hr3/nk_waves_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929/id=MDC_ECG_ELEC_POTL_II'.\n",
      "2023-07-07 20:28:38 [INFO ] client#status@320: Fetching status for '/nirscloud/agg_by_hr3/nk_waves_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929/id=MDC_ECG_ELEC_POTL_II'.\n",
      "2023-07-07 20:28:38 [INFO ] client#list@1123: Listing '/nirscloud/agg_by_hr3/nk_waves_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929/id=MDC_ECG_ELEC_POTL_II'.\n",
      "2023-07-07 20:28:38 [INFO ] client#status@320: Fetching status for '/nirscloud/agg_by_hr3/nk_waves_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929/id=MDC_ECG_ELEC_POTL_II'.\n",
      "2023-07-07 20:28:38 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-07 20:28:38 [INFO ] client#status@320: Fetching status for '/nirscloud/agg_by_hr3/nk_waves_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929/id=MDC_ECG_ELEC_POTL_II/part-00000-1f75843e-e8df-43ac-84d1-1c5b94653a8c.c000.snappy.parquet'.\n",
      "2023-07-07 20:28:38 [INFO ] client#read@731: Reading file '/nirscloud/agg_by_hr3/nk_waves_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=00/_patient_id=5984929/id=MDC_ECG_ELEC_POTL_II/part-00000-1f75843e-e8df-43ac-84d1-1c5b94653a8c.c000.snappy.parquet'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting 3 hours\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-07 20:28:38 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-07 20:28:38 [INFO ] client#status@320: Fetching status for '/nirscloud/agg_by_hr3/nk_waves_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=01/_patient_id=5984929/id=MDC_ECG_ELEC_POTL_II'.\n",
      "2023-07-07 20:28:38 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-07 20:28:38 [INFO ] client#status@320: Fetching status for '/nirscloud/agg_by_hr3/nk_waves_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=01/_patient_id=5984929/id=MDC_ECG_ELEC_POTL_II'.\n",
      "2023-07-07 20:28:38 [INFO ] client#list@1123: Listing '/nirscloud/agg_by_hr3/nk_waves_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=01/_patient_id=5984929/id=MDC_ECG_ELEC_POTL_II'.\n",
      "2023-07-07 20:28:38 [INFO ] client#status@320: Fetching status for '/nirscloud/agg_by_hr3/nk_waves_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=01/_patient_id=5984929/id=MDC_ECG_ELEC_POTL_II'.\n",
      "2023-07-07 20:28:38 [INFO ] client#list@1123: Listing '/nirscloud/agg_by_hr3/nk_waves_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=01/_patient_id=5984929/id=MDC_ECG_ELEC_POTL_II'.\n",
      "2023-07-07 20:28:38 [INFO ] client#status@320: Fetching status for '/nirscloud/agg_by_hr3/nk_waves_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=01/_patient_id=5984929/id=MDC_ECG_ELEC_POTL_II'.\n",
      "2023-07-07 20:28:38 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-07 20:28:38 [INFO ] client#status@320: Fetching status for '/nirscloud/agg_by_hr3/nk_waves_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=01/_patient_id=5984929/id=MDC_ECG_ELEC_POTL_II/part-00001-ac0d3d20-be26-431f-94d2-7fc3a5c37dac.c000.snappy.parquet'.\n",
      "2023-07-07 20:28:38 [INFO ] client#read@731: Reading file '/nirscloud/agg_by_hr3/nk_waves_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=01/_patient_id=5984929/id=MDC_ECG_ELEC_POTL_II/part-00001-ac0d3d20-be26-431f-94d2-7fc3a5c37dac.c000.snappy.parquet'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted hour: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-07 20:28:38 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-07 20:28:38 [INFO ] client#status@320: Fetching status for '/nirscloud/agg_by_hr3/nk_waves_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=02/_patient_id=5984929/id=MDC_ECG_ELEC_POTL_II'.\n",
      "2023-07-07 20:28:38 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-07 20:28:38 [INFO ] client#status@320: Fetching status for '/nirscloud/agg_by_hr3/nk_waves_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=02/_patient_id=5984929/id=MDC_ECG_ELEC_POTL_II'.\n",
      "2023-07-07 20:28:38 [INFO ] client#list@1123: Listing '/nirscloud/agg_by_hr3/nk_waves_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=02/_patient_id=5984929/id=MDC_ECG_ELEC_POTL_II'.\n",
      "2023-07-07 20:28:38 [INFO ] client#status@320: Fetching status for '/nirscloud/agg_by_hr3/nk_waves_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=02/_patient_id=5984929/id=MDC_ECG_ELEC_POTL_II'.\n",
      "2023-07-07 20:28:38 [INFO ] client#list@1123: Listing '/nirscloud/agg_by_hr3/nk_waves_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=02/_patient_id=5984929/id=MDC_ECG_ELEC_POTL_II'.\n",
      "2023-07-07 20:28:38 [INFO ] client#status@320: Fetching status for '/nirscloud/agg_by_hr3/nk_waves_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=02/_patient_id=5984929/id=MDC_ECG_ELEC_POTL_II'.\n",
      "2023-07-07 20:28:38 [INFO ] client#status@320: Fetching status for '/'.\n",
      "2023-07-07 20:28:38 [INFO ] client#status@320: Fetching status for '/nirscloud/agg_by_hr3/nk_waves_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=02/_patient_id=5984929/id=MDC_ECG_ELEC_POTL_II/part-00000-443b5b26-14c4-4b57-9524-e9fd72427ce1.c000.snappy.parquet'.\n",
      "2023-07-07 20:28:38 [INFO ] client#read@731: Reading file '/nirscloud/agg_by_hr3/nk_waves_NICU/_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=02/_patient_id=5984929/id=MDC_ECG_ELEC_POTL_II/part-00000-443b5b26-14c4-4b57-9524-e9fd72427ce1.c000.snappy.parquet'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted hour: 1\n",
      "Extracted hour: 2\n",
      "\n",
      "There is missing data in the following indices\n",
      "\n",
      "Time 96.8, Index 1452031 is missing 260.0 milliseconds ahead\n",
      "The maximum amount of time is180 mins\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "# Extracting and concatenating dataframes according to time. \n",
    "\n",
    "if total_time%60 == 0: \n",
    "    amount_hours = int(total_time/60)\n",
    "else:\n",
    "    amount_hours = int((total_time - total_time%60)/60) + 1 \n",
    "\n",
    "print('Extracting '+str(int(amount_hours))+' hours')\n",
    "\n",
    "df_dict = {}; time_cts =[]; values_cs = [];\n",
    "hours = np.arange(first_hour,first_hour + amount_hours)\n",
    "lead = 'MDC_ECG_ELEC_POTL_II'\n",
    "\n",
    "for h in hours:\n",
    "    if len(str(h)) == 1:\n",
    "        hdfs_path = '_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=0' + str(h)+'/_patient_id=5984929'\n",
    "    else: \n",
    "        hdfs_path = '_device_id=Procyon/_bed_id=HA11-01/_the_date=2023-06-10/_hr=' + str(h)+'/_patient_id=5984929'\n",
    "\n",
    "    df_cs = _get_df_cs(hdfs_path, lead)\n",
    "    print('Extracted hour: '+str(h))\n",
    "    df_dict['hour '+str(h)] = df_cs\n",
    "    \n",
    "final_df_cs = pd.concat(df_dict)\n",
    "\n",
    "\n",
    "final_df_cs.sort_values(by=['_milli_ts'], inplace=True)\n",
    "final_df_cs.reset_index(drop=True, inplace=True)\n",
    "final_df_cs['shift_milli_ts'] = final_df_cs['_milli_ts'].shift(-1)\n",
    "final_df_cs['diff_milli_ts'] = final_df_cs['shift_milli_ts'] - final_df_cs['_milli_ts']\n",
    "\n",
    "values_cs = np.asarray(final_df_cs['val'].to_numpy())\n",
    "raw_time_cs = np.asarray(final_df_cs['_milli_ts'].to_numpy(), dtype = 'int')\n",
    "time_cs = [np.datetime64(int(t),'ms') for t in raw_time_cs]\n",
    "time_cts = np.concatenate([time_cts, np.array([(pd.Timestamp(t).hour*60*60*1000) + (pd.Timestamp(t).minute*60*1000) + \n",
    "                 (pd.Timestamp(t).second*1000) + (pd.Timestamp(t).microsecond/1000) for t in time_cs])]);\n",
    "\n",
    "\n",
    "missing_info = final_df_cs[final_df_cs['diff_milli_ts']>4]\n",
    "missing_ids = missing_info.index.to_list()\n",
    "\n",
    "if len(missing_ids)>0:\n",
    "    print('')\n",
    "    print('There is missing data in the following indices')\n",
    "for missing_idx in missing_ids: \n",
    "    print('')\n",
    "    print('Time '+str(round((missing_idx*4/1000)/60,2))+', Index '+str(missing_idx)+' is missing '+str(final_df_cs['diff_milli_ts'][missing_idx])+' milliseconds ahead')\n",
    "    zeros = np.zeros(int(final_df_cs['diff_milli_ts'][missing_idx]/4))\n",
    "    missing_time = np.arange(time_cts[missing_idx]+4,time_cts[missing_idx+1],4)\n",
    "    time_cts = np.insert(time_cts,missing_idx+1,missing_time)\n",
    "    values_cs = np.insert(values_cs,missing_idx,zeros)\n",
    "    \n",
    "time_cts = time_cts - time_cts[0]\n",
    "\n",
    "print('The maximum amount of time is '+ str(int(total_time))+' mins')\n",
    "print('Finished')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3487a8f8-58f1-4af1-ab32-aa3fc7402382",
   "metadata": {},
   "source": [
    "# Classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a98a6802-808f-41b5-8189-97ae411966a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#time_pks = time_pks - time_cts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c71380b0-934a-495f-8516-cba2ce8850a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class raw_sample_():\n",
    "    \n",
    "    def __init__(self,min_min,min_sec,max_min,max_sec,seconds_per_label):\n",
    "        \n",
    "        self.min_min = min_min\n",
    "        self.min_sec = min_sec\n",
    "        self.max_min = max_min\n",
    "        self.max_sec = max_sec\n",
    "        self.seconds_per_label = seconds_per_label\n",
    "\n",
    "        self.min_time = int((self.min_min*60*1000)/4) + int(self.min_sec*1000/4)\n",
    "        self.max_time = int((self.max_min*60*1000)/4) + int(self.max_sec*1000/4) + 1\n",
    "        self.pks_time_min = (self.min_min*60*1000) + (self.min_sec*1000)\n",
    "        self.pks_time_max = (self.max_min*60*1000) + (self.max_sec*1000)\n",
    "        self.pks_time = time_pks[(self.pks_time_min > time_pks).argmin():(time_pks < self.pks_time_max).argmin()]\n",
    "        self.pks_values = values_p[(self.pks_time_min > time_pks).argmin():(time_pks < self.pks_time_max).argmin()]\n",
    "        \n",
    "        self.time =time_cts[self.min_time:self.max_time]\n",
    "        self.values =values_cs[self.min_time:self.max_time]\n",
    "\n",
    "        self.fig = go.Figure()\n",
    "        self.fig.add_trace(go.Scatter(line= dict(color='blue'),x=self.time, y=self.values,showlegend=False))\n",
    "        self.fig.add_trace(go.Scatter(mode='markers', marker= dict(color='red'),x=self.pks_time, y=self.pks_values,showlegend=False))\n",
    "\n",
    "        self.ticks_values = []\n",
    "        x = self.time[0]\n",
    "        while x < self.time[-1]:\n",
    "            self.ticks_values = np.append(self.ticks_values,x)\n",
    "            x = 1000*self.seconds_per_label + x\n",
    "\n",
    "        self.time_format_axis = time_f(self.ticks_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7c788685-be82-487a-812f-85f74f012b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class sample_():\n",
    "    \n",
    "    def __init__(self,min_min,min_sec,max_min,max_sec,seconds_per_label,find_the_peaks,inverted):\n",
    "        \n",
    "        self.min_min = min_min\n",
    "        self.min_sec = min_sec\n",
    "        self.max_min = max_min\n",
    "        self.max_sec = max_sec\n",
    "        self.seconds_per_label = seconds_per_label\n",
    "\n",
    "        self.min_time = int((self.min_min*60*1000)/4 + int(self.min_sec*1000)/4) \n",
    "        self.max_time = int((self.max_min*60*1000)/4 + int(self.max_sec*1000)/4) + 1\n",
    "\n",
    "        \n",
    "        time_zero = raw_time_cs[0]\n",
    "        self.time = raw_time_cs[self.min_time:self.max_time] - time_zero\n",
    "        if inverted:\n",
    "            self.values = - values_cs[self.min_time:self.max_time]\n",
    "        else: \n",
    "            self.values =  values_cs[self.min_time:self.max_time]\n",
    "\n",
    "        self.fig = go.Figure()\n",
    "        self.fig.add_trace(\n",
    "                      go.Scatter(line= dict(color='blue'),x=self.time, y=self.values,showlegend=False))\n",
    "\n",
    "        self.ticks_values = []\n",
    "        x = self.time[0]\n",
    "        while x < self.time[-1]:\n",
    "            self.ticks_values = np.append(self.ticks_values,x)\n",
    "            x = 1000*self.seconds_per_label + x\n",
    "\n",
    "        self.time_format_axis = time_f(self.ticks_values)\n",
    "        \n",
    "        if find_the_peaks:\n",
    "            self.peaks, _ = find_peaks(self.values, distance=100)\n",
    "            self.fig.add_trace(\n",
    "                      go.Scatter(mode='markers',x=self.time[self.peaks], y=self.values[self.peaks],showlegend=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cdedbac1-5213-4e3d-bbd9-c2b0c3b79870",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bs_r_window = baseline removal window;     #fs = sampling frequency                                      #trans_width = transition width of bandpass \n",
    "#numtaps = size of filter                   # mwi_windoow = moving window integration window\n",
    "\n",
    "\n",
    "class sample_all_included():\n",
    "    \n",
    "    first_time = True\n",
    "    \n",
    "    def __init__(self,min_min,min_sec,max_min,max_sec,seconds_per_label,inverted, bs_r_window,band_start,band_stop,fs,trans_width,numtaps, \n",
    "                 mwi_window, test_segments,spline,res):\n",
    "        \n",
    "        self.min_min = min_min\n",
    "        self.min_sec = min_sec\n",
    "        self.max_min = max_min\n",
    "        self.max_sec = max_sec\n",
    "        self.seconds_per_label = seconds_per_label\n",
    "\n",
    "\n",
    "        self.min_time = int((self.min_min*60*1000)/4 + int(self.min_sec*1000)/4) \n",
    "        self.max_time = int((self.max_min*60*1000)/4 + int(self.max_sec*1000)/4) + 1\n",
    "\n",
    "                \n",
    "        time_zero = raw_time_cs[0]\n",
    "        self.time = raw_time_cs[self.min_time:self.max_time] - time_zero\n",
    "        if inverted:\n",
    "            self.values = - values_cs[self.min_time:self.max_time]\n",
    "        else: \n",
    "            self.values =  values_cs[self.min_time:self.max_time]\n",
    "        \n",
    "       \n",
    "        self.ticks_values = []\n",
    "        x = self.time[0]\n",
    "        while x < self.time[-1]:\n",
    "            self.ticks_values = np.append(self.ticks_values,x)\n",
    "            x = 1000*self.seconds_per_label + x\n",
    "\n",
    "        self.time_format_axis = time_f(self.ticks_values)       \n",
    "        \n",
    "        #Filters' Parameters\n",
    "        self.first_bs_r_window = bs_r_window\n",
    "        self.first_band = [band_start, band_stop]\n",
    "        self.first_mwi_window = mwi_window\n",
    "        self.bs_r_window = bs_r_window\n",
    "        self.trans_width = trans_width\n",
    "        self.numtaps = numtaps\n",
    "        self.fs = fs\n",
    "        self.band = [band_start,band_stop]\n",
    "        self.edges = [0, self.band[0] - trans_width, self.band[0], self.band[1], self.band[1] + self.trans_width, 0.5*fs]\n",
    "        self.test_segments = test_segments\n",
    "        self.segment_duration = 0.8\n",
    "        self.spline = spline \n",
    "        self.res = res\n",
    "         \n",
    "        \n",
    "        #Bandpass\n",
    "        self.taps = signal.remez(self.numtaps, self.edges, [0, 1, 0], fs=self.fs)\n",
    "        self.bp_x_in = np.append(self.prepro_data,np.zeros(len(self.taps)))\n",
    "        self.bp_y = np.zeros(len(self.prepro_data)+len(self.taps))\n",
    "        \n",
    "        for j in range(0,len(self.prepro_data)+len(self.taps)): \n",
    "            sum = 0\n",
    "            for k in range(0,len(self.taps)):\n",
    "                sum = (self.bp_x_in[j-k]*self.taps[k]) + sum\n",
    "            self.bp_y[j] = sum\n",
    "            \n",
    "        self.bp_y=np.delete(self.bp_y,[np.arange(0,int(len(self.taps)/2))])\n",
    "        self.bp_x = self.time[0:len(self.bp_y)]\n",
    "\n",
    "        \n",
    "        #derivative\n",
    "        self.der_y = np.zeros(len(self.bp_y))\n",
    "        self.der_x = self.bp_x\n",
    "        self.der_x_in = np.append(self.bp_y,np.zeros(2))\n",
    "\n",
    "        for i in range(0,len(self.bp_y)):\n",
    "            self.der_y[i] = (1/8) * (-(self.der_x_in[i-2]) - (2*self.der_x_in[i-1]) + (2*self.der_x_in[i+1]) + (self.der_x_in[i+2]))\n",
    "        \n",
    "        #squaring\n",
    "        self.sq_y = (self.der_y) ** 2\n",
    "        self.sq_x = self.der_x\n",
    "        \n",
    "        #Moving Window Integration\n",
    "        self.mwi_window = mwi_window\n",
    "\n",
    "        \n",
    "        \n",
    "    \n",
    "    @property\n",
    "    def bs_r_window(self): \n",
    "        return self._bs_r_window\n",
    "\n",
    "    @bs_r_window.setter\n",
    "    def bs_r_window(self,new_window_value):\n",
    "        self._bs_r_window = new_window_value\n",
    "        self.bs_re, self.cut_pts = moving_average(self._bs_r_window,self.values)\n",
    "        self.prepro_data = self.values[0:len(self.time)-self.cut_pts] - self.bs_re\n",
    "        self.prepro_x = self.time[0:len(self.time)-self.cut_pts]\n",
    "        \n",
    "        if (new_window_value != self.first_bs_r_window): \n",
    "            self.first_bs_r_window = 300\n",
    "            self.bs_re, self.cut_pts = moving_average(self._bs_r_window,self.values)\n",
    "            self.prepro_data = self.values[0:len(self.time)-self.cut_pts] - self.bs_re\n",
    "            self.prepro_x = self.time[0:len(self.time)-self.cut_pts]\n",
    "            \n",
    "            self.edges = [0, self.band[0] - self.trans_width, self.band[0], self.band[1], self.band[1] + self.trans_width, 0.5*self.fs]\n",
    "            self.taps = signal.remez(self.numtaps, self.edges, [0, 1, 0], fs=self.fs)\n",
    "            self.bp_x_in = np.append(self.prepro_data,np.zeros(len(self.taps)))\n",
    "            self.bp_y = np.zeros(len(self.prepro_data)+len(self.taps))\n",
    "            \n",
    "            for j in range(0,len(self.prepro_data)+len(self.taps)): \n",
    "                sum = 0\n",
    "                for k in range(0,len(self.taps)):\n",
    "                    sum = (self.bp_x_in[j-k]*self.taps[k]) + sum\n",
    "                self.bp_y[j] = sum\n",
    "\n",
    "            self.bp_y=np.delete(self.bp_y,[np.arange(0,int(len(self.taps)/2))])\n",
    "            self.bp_x = self.time[0:len(self.bp_y)]\n",
    "            \n",
    "            #Derivative when bandpass is updated\n",
    "            self.der_y = np.zeros(len(self.bp_y))\n",
    "            self.der_x_in = np.append(self.bp_y,np.zeros(2))\n",
    "            for i in range(0,len(self.bp_y)):\n",
    "                self.der_y[i] = (1/8) * (-(self.der_x_in[i-2]) - (2*self.der_x_in[i-1]) + (2*self.der_x_in[i+1]) + (self.der_x_in[i+2]))\n",
    "\n",
    "            self.der_x = self.bp_x\n",
    "\n",
    "            #Squaring when bandpass is updatd\n",
    "            self.sq_y = self.der_y ** 2\n",
    "            self.sq_x = self.der_x\n",
    "\n",
    "            #Movig window integgration when bandpass is updated \n",
    "            self.mwi_y = dif_eq_window_integration(self.sq_y,self.mwi_window,False)\n",
    "            self.mwi_x = self.der_x\n",
    "\n",
    "            #Fiducial points when bandpass is updated\n",
    "            self.fiducial_points = find_fiducial_point(self.mwi_y,self.mwi_x,self.test_segments,self.segment_duration,self.mwi_window)\n",
    "            self.max_x, self.max_y, self.peaks_x, self.peaks_y, self.interpolated_peak_x, self.interpolated_peak_y,self.max_ids = interpolation_spline(\n",
    "                self.fiducial_points, self.time, self.values, self.spline, self.res)\n",
    "\n",
    "            \n",
    "        \n",
    "    @property\n",
    "    def band(self):\n",
    "        return self._band\n",
    "    \n",
    "    @band.setter\n",
    "    def band(self,new_band):\n",
    "        self.band_start = new_band[0]; self.band_stop = new_band[1]\n",
    "        self._band = [new_band[0],new_band[1]]\n",
    "        if (new_band != self.first_band): \n",
    "            self.first_band = 0.01\n",
    "            self.edges = [0, self._band[0] - self.trans_width, self._band[0], self._band[1], self._band[1] + self.trans_width, 0.5*self.fs]\n",
    "            self.taps = signal.remez(self.numtaps, self.edges, [0, 1, 0], fs=self.fs)\n",
    "            self.bp_x_in = np.append(self.prepro_data,np.zeros(len(self.taps)))\n",
    "            self.bp_y = np.zeros(len(self.prepro_data)+len(self.taps))\n",
    "\n",
    "            for j in range(0,len(self.prepro_data)+len(self.taps)): \n",
    "                sum = 0\n",
    "                for k in range(0,len(self.taps)):\n",
    "                    sum = (self.bp_x_in[j-k]*self.taps[k]) + sum\n",
    "                self.bp_y[j] = sum\n",
    "\n",
    "            self.bp_y=np.delete(self.bp_y,[np.arange(0,int(len(self.taps)/2))])\n",
    "            self.bp_x = self.time[0:len(self.bp_y)]\n",
    "\n",
    "\n",
    "            #Derivative when bandpass is updated\n",
    "            self.der_y = np.zeros(len(self.bp_y))\n",
    "            self.der_x_in = np.append(self.bp_y,np.zeros(2))\n",
    "            for i in range(0,len(self.bp_y)):\n",
    "                self.der_y[i] = (1/8) * (-(self.der_x_in[i-2]) - (2*self.der_x_in[i-1]) + (2*self.der_x_in[i+1]) + (self.der_x_in[i+2]))\n",
    "\n",
    "            self.der_x = self.bp_x\n",
    "\n",
    "            #Squaring when bandpass is updatd\n",
    "            self.sq_y = self.der_y ** 2\n",
    "            self.sq_x = self.der_x\n",
    "\n",
    "            #Movig window integgration when bandpass is updated \n",
    "            self.mwi_y = dif_eq_window_integration(self.sq_y,self.mwi_window,False)\n",
    "            self.mwi_x = self.der_x\n",
    "\n",
    "            #Fiducial points when bandpass is updated\n",
    "            self.fiducial_points = find_fiducial_point(self.mwi_y,self.mwi_x,self.test_segments,self.segment_duration,self.mwi_window)\n",
    "            self.max_x, self.max_y, self.peaks_x, self.peaks_y, self.interpolated_peak_x, self.interpolated_peak_y,self.max_ids = interpolation_spline(\n",
    "                self.fiducial_points, self.time, self.values, self.spline, self.res)\n",
    "                    \n",
    "    @property\n",
    "    def mwi_window(self):\n",
    "        return self._mwi_window\n",
    "    \n",
    "    @mwi_window.setter\n",
    "    def mwi_window(self,new_window):\n",
    "        self._mwi_window = new_window\n",
    "        self.mwi_y = dif_eq_window_integration(self.sq_y,self.mwi_window,False)\n",
    "        self.mwi_x = self.der_x\n",
    "        self.fiducial_points = find_fiducial_point(self.mwi_y,self.mwi_x,self.test_segments,self.segment_duration,self.mwi_window)\n",
    "        self.max_x, self.max_y, self.peaks_x, self.peaks_y, self.interpolated_peak_x, self.interpolated_peak_y,self.max_ids = interpolation_spline(\n",
    "                self.fiducial_points, self.time, self.values, self.spline, self.res)\n",
    "    \n",
    "    \n",
    "\n",
    "        \n",
    "    \n",
    "        #self.prepro_fig = go.Figure()\n",
    "        #self.prepro_fig.add_trace(go.Scatter(line=dict(color='orange'),x = self.prepro_x, y = self.prepro_data),showlegend = show_legend)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0551947f-9752-4262-a7e8-73b8fdb639d6",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8ba35c-8863-41a4-885c-61f31f7afa7d",
   "metadata": {},
   "source": [
    "## Cluster Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fad5b3dd-87de-419d-8c94-16395dcb7c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_sample = raw_sample_(1,30,3,0,1)\n",
    "fig_raw = cluster_sample.fig\n",
    "fig_raw.update_layout(xaxis = dict(tickmode = 'array', tickvals = cluster_sample.ticks_values, ticktext = cluster_sample.time_format_axis),autosize=False,width=1400,\n",
    "                  height=600,showlegend=False,title=\"Raw Data \", xaxis_title=\"Time\", yaxis_title= 'Signal', \n",
    "                  font=dict(family=\"Avenir\",size=14,color=\"Black\"));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da63f0a8-ad47-4cdd-a3e4-5562c446829a",
   "metadata": {},
   "source": [
    "## Pan Tompkins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "56e0d82f-6663-4921-8a4c-42037f6dddc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample One: sample_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b6095732-f898-405b-8694-1443a5e1d588",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shared/braulio/ecg_algorithm/functions.py:232: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in sqrt\n",
      "\n",
      "/home/shared/braulio/ecg_algorithm/functions.py:233: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in sqrt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "min_min_t = 0; min_sec_t = 0; max_min_t= 20; max_sec_t = 0; seconds_per_label_t = 15; inverted_t = False;   bs_r_window_t = 6; \n",
    "band_start_t = 3; band_stop_t = 100; fs_t= 250;  trans_width_t = 2.88; numtaps_t = 152; show_legend_t = False; mwi_window_t = 25 ;\n",
    "test_segments_t =3;            spline_t = 4;       res_t = 5000;\n",
    "\n",
    "sample_test = sample_all_included(min_min_t,min_sec_t,max_min_t,max_sec_t,seconds_per_label_t,inverted_t, bs_r_window_t,band_start_t,band_stop_t,fs_t,\n",
    "                       trans_width_t,numtaps_t, mwi_window_t, test_segments_t, spline_t,res_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "680a65c5-4789-4db5-bad0-0b3aaac8b414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Two: sample_test_dif_wl    this sample will have different window length for the mean average subtraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ce32dae9-39c2-4edb-b832-bdda0582d866",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_min_t = 1; min_sec_t = 30; max_min_t= 3; max_sec_t = 0; seconds_per_label_t = 1; inverted_t = False;   bs_r_window_t = 10; \n",
    "band_start_t = 3; band_stop_t = 100; fs_t= 250;  trans_width_t = 2.88; numtaps_t = 152; show_legend_t = False; mwi_window_t = 25 ;\n",
    "test_segments_t =3;            spline_t = 4;       res_t = 5000;\n",
    "\n",
    "sample_test_dif_wl = sample_all_included(min_min_t,min_sec_t,max_min_t,max_sec_t,seconds_per_label_t,inverted_t, bs_r_window_t,band_start_t,band_stop_t,fs_t,\n",
    "                       trans_width_t,numtaps_t, mwi_window_t, test_segments_t, spline_t,res_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6b1549fd-859a-4323-bee2-aba19c40f824",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_raw = make_subplots(rows=3, cols=1, subplot_titles=(\"Peaks \", 'Mean Subtraction', 'Moving Window Integration'))\n",
    "\n",
    "fig_raw.add_trace(go.Scatter(line = dict(color = 'blue'), x = sample_test.time,y = sample_test.values,showlegend=False),row=1, col=1)\n",
    "fig_raw.add_trace(go.Scatter(mode = 'markers', x = sample_test.max_x,y = sample_test.max_y,showlegend=False),row=1, col=1)\n",
    "fig_raw.add_trace(go.Scatter(x = sample_test.prepro_x,y = sample_test.prepro_data,showlegend=False),row=2,col=1)\n",
    "fig_raw.add_trace(go.Scatter(line=dict(color='#0a4345'),x = sample_test.mwi_x,y = sample_test.mwi_y,showlegend=False),row=3,col=1)\n",
    "fig_raw.add_trace(go.Scatter(marker=dict(color='red'),mode ='markers',x = sample_test.mwi_x[sample_test.fiducial_points],y = sample_test.mwi_y[sample_test.fiducial_points],\n",
    "                              showlegend=False),row=3,col=1)\n",
    "\n",
    "\n",
    "\n",
    "fig_raw.update_layout(xaxis = dict(tickmode = 'array', tickvals = sample_test.ticks_values, ticktext = sample_test.time_format_axis),\n",
    "                    xaxis2 = dict(tickmode = 'array', tickvals = sample_test.ticks_values, ticktext = sample_test.time_format_axis),\n",
    "                    xaxis3 = dict(tickmode = 'array', tickvals = sample_test.ticks_values, ticktext = sample_test.time_format_axis))\n",
    "\n",
    "fig_raw.update_layout(xaxis_range=[79000,85000], xaxis2_range=[79000,85000],xaxis3_range=[79000,85000],yaxis_range=[-1.5,1.3],\n",
    "                       yaxis2_range=[-0.4,0.4], yaxis3_range=[-0.001,0.05])\n",
    "fig_raw.update_layout(height=1200,width = 1200);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3d285c0e-283e-4f9a-8910-ba32f27c0f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig_raw.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d762ff-4e8c-4c71-8e3b-39c43950eb30",
   "metadata": {},
   "source": [
    "## Mising Peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "78881a8f-7283-41b7-83f5-8fe1c97e8d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_pt_p, missing_cluster_p = find_missing_peaks(sample_test.max_x, cluster_sample.pks_time, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b12bdaa8-25bc-44f6-93e6-a94967e67606",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_c_vs_s =go.Figure()\n",
    "\n",
    "fig_c_vs_s.add_trace(go.Scatter(line= dict(color='blue'),x=cluster_sample.time, y=cluster_sample.values,name='Raw Data',showlegend=True))\n",
    "    \n",
    "\n",
    "fig_c_vs_s.add_trace(go.Scatter(mode='markers',marker=dict(size=12),x=cluster_sample.pks_time, y= cluster_sample.pks_values, name = 'Cluster', \n",
    "                           showlegend=True,))\n",
    "\n",
    "fig_c_vs_s.add_trace(go.Scatter(mode='markers',marker=dict(size=10,color='#21B626'), x = sample_test.max_x, \n",
    "                          y = sample_test.max_y, name = 'Current Version', showlegend=True))\n",
    "\n",
    "fig_c_vs_s.add_trace(go.Scatter(mode='markers',marker=dict(size=7,color='orange'), x = sample_test.max_x[missing_cluster_p], \n",
    "                           y= sample_test.max_y[missing_cluster_p], name = 'Missing Cluster Peaks', showlegend=True))\n",
    "\n",
    "fig_c_vs_s.add_trace(go.Scatter(mode='markers',marker=dict(size=7,color='#00FCF5'),x = cluster_sample.pks_time[missing_pt_p] , y= cluster_sample.pks_values[missing_pt_p], \n",
    "                          name = 'Missing Current Version Peaks', showlegend=True))\n",
    "\n",
    "\n",
    "fig_c_vs_s.update_layout(xaxis = dict(tickmode = 'array', tickvals = cluster_sample.ticks_values, ticktext = cluster_sample.time_format_axis),autosize=False,width=1200,height=630,\n",
    "                    title='Missing Cluster Peaks: '+str(len(missing_cluster_p))+'           Missing Current Version Peaks: '+str(len(missing_pt_p)) + \n",
    "                   '            MAW: '+str(sample_test.bs_r_window) + '         Band: '+str(sample_test.band_start)+' - '+str(sample_test.band_stop));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dd54aec7-f562-494f-bdcb-c5b635d1017f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig_c_vs_s.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a248db9c-6eb9-4cf8-b4ce-664d094b0c10",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18743fb4-d683-4530-bbe1-35e7b607fcf5",
   "metadata": {},
   "source": [
    "## Comparing different window lengths against 6 window length in mean average subtraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cb48c9b8-7b7f-4fb8-bfe8-41d8c11d2453",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shared/braulio/ecg_algorithm/functions.py:232: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in sqrt\n",
      "\n",
      "/home/shared/braulio/ecg_algorithm/functions.py:233: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in sqrt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Visually missing peaks\n",
    "\n",
    "fig_ms_p = go.Figure()\n",
    "missing_6_dict ={};  missing_dif_wl_dict={};\n",
    "spline=4;\n",
    "res = 5000\n",
    "lengths = np.arange(7,20,1)\n",
    "\n",
    "\n",
    "for N in lengths: \n",
    "    sample_test_dif_wl.bs_r_window = N\n",
    "    missing_6_p, missing_dif_wl_p = find_missing_peaks(sample_test.max_x, sample_test_dif_wl.max_x, True)\n",
    "    missing_6_dict['window_length_'+str(N)] = missing_6_p\n",
    "    missing_dif_wl_dict['window_length_'+str(N)] = missing_dif_wl_p\n",
    "    \n",
    "    fig_ms_p.add_trace(go.Scatter(line= dict(color='blue'),x=sample_test.time, y=sample_test.values,name='Raw Data',showlegend=True, visible = False))\n",
    "    \n",
    "\n",
    "    fig_ms_p.add_trace(go.Scatter(mode='markers',marker=dict(size=12),x=sample_test.max_x, y= sample_test.max_y, name = '6 WL Peaks', \n",
    "                               showlegend=True, visible = False))\n",
    "    fig_ms_p.add_trace(go.Scatter(mode='markers',marker=dict(size=10,color='#21B626'), x = sample_test_dif_wl.max_x, y = sample_test_dif_wl.max_y,\n",
    "                               name = str(N)+' WL Peaks',showlegend=True, \n",
    "                              visible = False))\n",
    "    fig_ms_p.add_trace(go.Scatter(mode='markers',marker=dict(size=7,color='orange'), x = sample_test_dif_wl.max_x[missing_6_p], \n",
    "                               y= sample_test_dif_wl.max_y[missing_6_p], name = '6 WL Missing Peaks', showlegend=True, visible = False))\n",
    "    \n",
    "    fig_ms_p.add_trace(go.Scatter(mode='markers',marker=dict(size=7,color='#00FCF5'),x = sample_test.max_x[missing_dif_wl_p] , y= sample_test.max_y[missing_dif_wl_p], \n",
    "                              name = str(N)+' WL Missing  Peaks', showlegend=True, visible = False))\n",
    "\n",
    "fig_ms_p.data[5].visible = True\n",
    "\n",
    "steps = []\n",
    "start = 0\n",
    "for i in range(0,len(lengths)):\n",
    "    step = dict(\n",
    "        method=\"update\",\n",
    "        args=[{\"visible\": [False] * len(fig_ms_p.data)},\n",
    "              {\"title\": \"Peaks identified with window length \"+str(lengths[i])+ '   Amount of 6 WL Missing Peaks: '+\n",
    "               str(len(missing_6_dict['window_length_'+str(lengths[i])])) +'    Amount of ' + str(lengths[i]) + ' WL Missing Peaks: '+ \n",
    "               str(len(missing_dif_wl_dict['window_length_'+str(lengths[i])]))}],  # layout attribute\n",
    "    )\n",
    "    step[\"args\"][0][\"visible\"][start] = True  # Toggle i'th trace to \"visible\"\n",
    "    step[\"args\"][0][\"visible\"][start+1] = True\n",
    "    step[\"args\"][0][\"visible\"][start+2] = True\n",
    "    step[\"args\"][0][\"visible\"][start+3] = True\n",
    "    step[\"args\"][0][\"visible\"][start+4] = True\n",
    "    \n",
    "    start = start+5\n",
    "    steps.append(step)\n",
    "    \n",
    "sliders = [dict(active=5, currentvalue={\"prefix\": \"n: \"}, pad={\"t\": 50}, steps=steps)]\n",
    "fig_ms_p.update_layout(sliders=sliders);\n",
    "fig_ms_p.update_layout(xaxis_range=[79000,85000]);\n",
    "fig_ms_p.update_layout(xaxis = dict(tickmode = 'array', tickvals = cluster_sample.ticks_values, ticktext = cluster_sample.time_format_axis),autosize=False,width=1200,height=600); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3fdf083f-7b4a-4624-8ed6-265d753dadeb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#fig_ms_p.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248d0fc7-7cba-4e64-97a8-f5215d200dcd",
   "metadata": {},
   "source": [
    "## Pre Processed data with different window lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "edef054b-324a-474e-9236-31e38f23d8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig_prepro = go.Figure()\n",
    "missing_6_dict ={};  missing_dif_wl_dict={};\n",
    "spline=4;\n",
    "res = 5000\n",
    "lengths = np.arange(7,20,1)\n",
    "\n",
    "\n",
    "for N in lengths: \n",
    "    sample_test_dif_wl.bs_r_window = N\n",
    "    \n",
    "    fig_prepro.add_trace(go.Scatter(x = sample_test_dif_wl.prepro_x , \n",
    "                              y= sample_test_dif_wl.prepro_data, name = str(N)+' WL Prepro Data', showlegend=True, visible = False))\n",
    "\n",
    "fig_prepro.data[3].visible = True\n",
    "\n",
    "steps = []\n",
    "start = 0\n",
    "for i in range(0,len(lengths)):\n",
    "    step = dict(\n",
    "        method=\"update\",\n",
    "        args=[{\"visible\": [False] * len(fig_prepro.data)},\n",
    "              {\"title\": 'Preprocessed data, window length: '+str(lengths[i])}],  # layout attribute\n",
    "    )\n",
    "    step[\"args\"][0][\"visible\"][i] = True  # Toggle i'th trace to \"visible\"\n",
    "    steps.append(step)\n",
    "    \n",
    "sliders = [dict(active=5, currentvalue={\"prefix\": \"n: \"}, pad={\"t\": 50}, steps=steps)]\n",
    "fig_prepro.update_layout(sliders=sliders);\n",
    "fig_prepro.update_layout(xaxis = dict(tickmode = 'array', tickvals = cluster_sample.ticks_values, ticktext = cluster_sample.time_format_axis),autosize=False,width=1200,height=600); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "056897b3-9adc-441d-a568-831d548176fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig_prepro.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7ea9a1-1eaa-4855-8664-d6ce94bf7be6",
   "metadata": {},
   "source": [
    "## Bandpass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1d7dc82e-2341-4119-85c3-173fbea3c6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "figbp = go.Figure()\n",
    "missing_6_dict ={};  missing_dif_wl_dict={};\n",
    "spline=4;\n",
    "res = 5000\n",
    "lengths = np.arange(7,20,1)\n",
    "\n",
    "\n",
    "for N in lengths: \n",
    "    sample_test_dif_wl.bs_r_window = N\n",
    "    \n",
    "    figbp.add_trace(go.Scatter(x = sample_test_dif_wl.bp_x , \n",
    "                              y= sample_test_dif_wl.bp_y, name = str(N)+' WL in MS, Bandpass', showlegend=True, visible = False))\n",
    "\n",
    "figbp.data[3].visible = True\n",
    "\n",
    "steps = []\n",
    "start = 0\n",
    "for i in range(0,len(lengths)):\n",
    "    step = dict(\n",
    "        method=\"update\",\n",
    "        args=[{\"visible\": [False] * len(figbp.data)},\n",
    "              {\"title\": 'Bandpass , window length in mean subtraction: '+str(lengths[i])}],  # layout attribute\n",
    "    )\n",
    "    step[\"args\"][0][\"visible\"][i] = True  # Toggle i'th trace to \"visible\"\n",
    "    steps.append(step)\n",
    "    \n",
    "sliders = [dict(active=5, currentvalue={\"prefix\": \"n: \"}, pad={\"t\": 50}, steps=steps)]\n",
    "figbp.update_layout(sliders=sliders);\n",
    "figbp.update_layout(xaxis = dict(tickmode = 'array', tickvals = cluster_sample.ticks_values, ticktext = cluster_sample.time_format_axis),autosize=False,width=1200,height=600); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c39c296c-7d4b-4615-84c5-93ec43a3ea6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#figbp.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e001ed80-19d1-4388-bc4b-ac7ffe04d12d",
   "metadata": {},
   "source": [
    "## Derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "08499230-dddf-4366-bc1e-0091ba68d1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig_der = go.Figure()\n",
    "missing_6_dict ={};\n",
    "spline=4;\n",
    "res = 5000\n",
    "lengths = np.arange(7,20,1)\n",
    "\n",
    "\n",
    "for N in lengths: \n",
    "    sample_test_dif_wl.bs_r_window = N\n",
    "    \n",
    "    fig_der.add_trace(go.Scatter(x = sample_test_dif_wl.der_x , \n",
    "                              y= sample_test_dif_wl.der_y, name = str(N)+' WL in MS, Derivative', showlegend=True, visible = False))\n",
    "\n",
    "fig_der.data[3].visible = True\n",
    "\n",
    "steps = []\n",
    "start = 0\n",
    "for i in range(0,len(lengths)):\n",
    "    step = dict(\n",
    "        method=\"update\",\n",
    "        args=[{\"visible\": [False] * len(fig_der.data)},\n",
    "              {\"title\": 'Derivative , window length in mean subtraction: '+str(lengths[i])}],  # layout attribute\n",
    "    )\n",
    "    step[\"args\"][0][\"visible\"][i] = True  # Toggle i'th trace to \"visible\"\n",
    "    steps.append(step)\n",
    "    \n",
    "sliders = [dict(active=5, currentvalue={\"prefix\": \"n: \"}, pad={\"t\": 50}, steps=steps)]\n",
    "fig_der.update_layout(sliders=sliders);\n",
    "fig_der.update_layout(xaxis = dict(tickmode = 'array', tickvals = sample_test.ticks_values, ticktext = sample_test.time_format_axis),autosize=False,width=1200,height=600); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "59ab676f-8a4f-4312-9c8f-54a2827600d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig_der.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d054c4b5-6ea7-45e4-82d7-fb716d8defe2",
   "metadata": {},
   "source": [
    "## Moving Window Integration + Fiducial Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7e316c10-db67-4b40-9201-cadd24ada458",
   "metadata": {},
   "outputs": [],
   "source": [
    "mwi_fp = go.Figure()\n",
    "missing_6_dict ={};  missing_dif_wl_dict={};\n",
    "spline=4;\n",
    "res = 5000\n",
    "lengths = np.arange(7,20,1)\n",
    "\n",
    "\n",
    "for N in lengths: \n",
    "    sample_test_dif_wl.bs_r_window = N\n",
    "    \n",
    "    mwi_fp.add_trace(go.Scatter(x = sample_test_dif_wl.mwi_x , \n",
    "                              y= sample_test_dif_wl.mwi_y, name = str(N)+' Bandpass WL: '+str(N), showlegend=True, visible = False))\n",
    "    mwi_fp.add_trace(go.Scatter(mode = 'markers', x = sample_test_dif_wl.mwi_x[sample_test_dif_wl.fiducial_points] , \n",
    "                              y= sample_test_dif_wl.mwi_y[sample_test_dif_wl.fiducial_points], name = str(N)+' Bandpass WL: '+str(N), \n",
    "                              showlegend=True, visible = False))\n",
    "\n",
    "mwi_fp.data[3].visible = True\n",
    "\n",
    "steps = []\n",
    "start = 0\n",
    "for i in range(0,len(lengths)):\n",
    "    step = dict(\n",
    "        method=\"update\",\n",
    "        args=[{\"visible\": [False] * len(mwi_fp.data)},\n",
    "              {\"title\": 'Bandpass data, window length: '+str(lengths[i])}],  # layout attribute\n",
    "    )\n",
    "    step[\"args\"][0][\"visible\"][start] = True  # Toggle i'th trace to \"visible\"\n",
    "    step[\"args\"][0][\"visible\"][start + 1] = True  # Toggle i'th trace to \"visible\"\n",
    "    start = start + 2\n",
    "    steps.append(step)\n",
    "    \n",
    "sliders = [dict(active=5, currentvalue={\"prefix\": \"n: \"}, pad={\"t\": 50}, steps=steps)]\n",
    "mwi_fp.update_layout(sliders=sliders);\n",
    "mwi_fp.update_layout(xaxis = dict(tickmode = 'array', tickvals = cluster_sample.ticks_values, ticktext = cluster_sample.time_format_axis),autosize=False,width=1200,height=600); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "88e49217-277c-458b-96cf-2e3fe4b48f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mwi_fp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5905912f-69cc-4886-a3ad-b3cfe5dec5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_min_t = 1; min_sec_t = 30; max_min_t= 3; max_sec_t = 0; seconds_per_label_t = 1; inverted_t = False;   bs_r_window_t = 15; \n",
    "band_start_t = 3; band_stop_t = 100; fs_t= 250;  trans_width_t = 2.88; numtaps_t = 152; show_legend_t = False; mwi_window_t = 25 ;\n",
    "test_segments_t =3;            spline_t = 4;       res_t = 5000;\n",
    "\n",
    "recreated_cluster = sample_all_included(min_min_t,min_sec_t,max_min_t,max_sec_t,seconds_per_label_t,inverted_t, bs_r_window_t,band_start_t,band_stop_t,fs_t,\n",
    "                       trans_width_t,numtaps_t, mwi_window_t, test_segments_t, spline_t,res_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdd0721-90cc-4d6d-a71b-ca8c3adf40a3",
   "metadata": {},
   "source": [
    "### Recreating cluster sample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fa8c2837-db4b-4e79-b702-8b0c85c6d844",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_prepro = make_subplots(rows=2, cols=1, subplot_titles=(\"Cluster \", 'MWI: '+str(sample_test.bs_r_window)))\n",
    "comp_prepro.add_trace(go.Scatter(x = recreated_cluster.prepro_x,y = recreated_cluster.prepro_data,showlegend=False),row=1, col=1)\n",
    "comp_prepro.add_trace(go.Scatter(x = sample_test.prepro_x,y = sample_test.prepro_data,showlegend=False),row=2, col=1)\n",
    "\n",
    "comp_prepro.update_layout(xaxis = dict(tickmode = 'array', tickvals = sample_test.ticks_values, ticktext = sample_test.time_format_axis),\n",
    "                          xaxis2 = dict(tickmode = 'array', tickvals = recreated_cluster.ticks_values, ticktext = recreated_cluster.time_format_axis))\n",
    "comp_prepro.update_layout(yaxis_range=[-1.2,1.2],yaxis2_range=[-0.45,0.4])\n",
    "comp_prepro.update_layout(height=900,width = 1200);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "619eb581-34c1-4837-b460-638d5a21bfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_test.band=[4,100]\n",
    "missing_pt_p, missing_cluster_p = find_missing_peaks(sample_test.max_x, cluster_sample.pks_time, True)\n",
    "comp_bandpass = make_subplots(rows=3, cols=1, subplot_titles=('Peaks','MWI: '+str(sample_test.bs_r_window) , 'Cluster'))\n",
    "comp_bandpass.add_trace(go.Scatter(x=cluster_sample.time, y= cluster_sample.values, name = 'Cluster', showlegend=True,),row = 1, col=1)\n",
    "comp_bandpass.add_trace(go.Scatter(mode='markers',marker=dict(size=12),x=cluster_sample.pks_time, y= cluster_sample.pks_values, name = 'Cluster', \n",
    "                           showlegend=True,),row = 1, col=1)\n",
    "\n",
    "comp_bandpass.add_trace(go.Scatter(mode='markers',marker=dict(size=10,color='#21B626'), x = sample_test.max_x, \n",
    "                          y = sample_test.max_y, name = 'Current Version', showlegend=True),row = 1, col=1)\n",
    "\n",
    "comp_bandpass.add_trace(go.Scatter(mode='markers',marker=dict(size=7,color='orange'), x = sample_test.max_x[missing_cluster_p], \n",
    "                           y= sample_test.max_y[missing_cluster_p], name = 'Missing Cluster Peaks', showlegend=True),row = 1, col=1)\n",
    "\n",
    "comp_bandpass.add_trace(go.Scatter(mode='markers',marker=dict(size=7,color='#00FCF5'),x = cluster_sample.pks_time[missing_pt_p] , y= cluster_sample.pks_values[missing_pt_p], \n",
    "                          name = 'Missing Current Version Peaks', showlegend=True),row = 1, col=1)\n",
    "\n",
    "comp_bandpass.add_trace(go.Scatter(x = sample_test.bp_x,y = sample_test.bp_y,showlegend=False),row=2, col=1)\n",
    "comp_bandpass.add_trace(go.Scatter(x = recreated_cluster.bp_x,y = recreated_cluster.bp_y,showlegend=False),row=3, col=1)\n",
    "\n",
    "comp_bandpass.update_layout(xaxis = dict(tickmode = 'array', tickvals = cluster_sample.ticks_values, ticktext = cluster_sample.time_format_axis),\n",
    "                            xaxis2 = dict(tickmode = 'array', tickvals = sample_test.ticks_values, ticktext = sample_test.time_format_axis),\n",
    "                            xaxis3 = dict(tickmode = 'array', tickvals = recreated_cluster.ticks_values, ticktext = recreated_cluster.time_format_axis))\n",
    "comp_bandpass.update_layout(xaxis_range=[141300,142900],xaxis2_range=[141300,142900],yaxis_range=[-2.8,3],yaxis2_range=[-0.2,0.2])\n",
    "comp_bandpass.update_layout(height=1200,width = 1200);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a29207-ace4-4c09-ad06-56695b58c310",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5861fb10-11ca-4bde-8a9a-b0d7d760d2cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cf29da-7894-4770-82ba-24da442ce41a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
